


---


- フォルダ名: .
- ファイル名: config.py
- 内容:
# --- ファイル: config.py ---
"""
スクリプト全体で使用する設定値と定数を定義します。
"""

# --- Playwright 関連設定 ---
DEFAULT_ACTION_TIMEOUT = 10000  # 10000 デフォルトのアクションタイムアウト (ミリ秒)
IFRAME_LOCATOR_TIMEOUT = 5000   #  5000 iframe存在確認のタイムアウト (ミリ秒)
PDF_DOWNLOAD_TIMEOUT   = 60000  # 60000 PDFダウンロードのタイムアウト (ミリ秒)
NEW_PAGE_EVENT_TIMEOUT = 4000   #  4000 新しいページが開くのを待つタイムアウト (ミリ秒)(クリック後常に待つので長くすると常にクリック後遅い)

# --- 動的探索関連設定 ---
DYNAMIC_SEARCH_MAX_DEPTH = 2    # iframe探索の最大深度

# --- ファイルパス・ディレクトリ名 ---
LOG_FILE               = 'output_web_runner.log'
DEFAULT_INPUT_FILE     = 'input.json'
DEFAULT_SCREENSHOT_DIR = 'screenshots'
RESULTS_OUTPUT_FILE    = 'output_results.txt'

# --- その他 ---
# 必要に応じて他の設定値を追加
MCP_SERVER_LOG_FILE    = 'output/web_runner_mcp.log' # MCPサーバー用ログファイル名 (例)
MCP_CLIENT_OUTPUT_FILE = 'output/web_runner_mcp.txt' # MCPクライアントのデフォルト出力ファイル名


---


- フォルダ名: .
- ファイル名: json_generator.html
- 内容:
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Playwright 入力データ ジェネレーター (JSON)</title>
    <style>
        /* --- スタイルは変更なし --- */
        body { font-family: sans-serif; line-height: 1.6; padding: 20px; max-width: 800px; margin: auto; }
        h1, h2 { border-bottom: 1px solid #ccc; padding-bottom: 5px; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        input[type="text"], input[type="url"], input[type="number"], select, textarea {
            width: 95%;
            padding: 8px;
            margin-bottom: 15px;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box; /* paddingを含めて幅計算 */
        }
        button { padding: 10px 15px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; margin-top: 10px; }
        button:hover { background-color: #0056b3; }
        button:disabled { background-color: #cccccc; cursor: not-allowed;}
        button.remove-step { background-color: #dc3545; margin-left: 10px; }
        button.remove-step:hover { background-color: #c82333; }
        .step { border: 1px solid #eee; padding: 15px; margin-bottom: 20px; border-radius: 5px; background-color: #f9f9f9; position: relative; }
        .step h3 { margin-top: 0; }
        .step .remove-step { position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 0.8em;}
        .form-group { margin-bottom: 15px; }
        .hidden { display: none; }
        .option-group label { display: inline-block; margin-right: 10px; font-weight: normal;}
        .option-group input[type="radio"] { margin-right: 5px;}
        #generated-json-container { margin-top: 20px; border: 1px solid #ddd; padding: 15px; background-color: #f0f0f0; border-radius: 5px;}
        #generated-json { display: block; white-space: pre-wrap; word-wrap: break-word; font-family: monospace; max-height: 500px; overflow-y: auto; }
        #error-message { color: red; font-weight: bold; margin-top: 10px; white-space: pre-wrap;}
        .loader { border: 4px solid #f3f3f3; border-radius: 50%; border-top: 4px solid #3498db; width: 20px; height: 20px; animation: spin 1s linear infinite; display: inline-block; vertical-align: middle; margin-left: 10px;}
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        .button-container { display: flex; align-items: center; flex-wrap: wrap; margin-top: 20px; gap: 10px; }
        #copy-json-button { background-color: #28a745; }
        #copy-json-button:hover { background-color: #218838; }
        #download-json-button { background-color: #17a2b8; }
        #download-json-button:hover { background-color: #117a8b; }
         /* ▼▼▼ 追加: 属性名フィールド用の補足説明スタイル ▼▼▼ */
        .attribute-hint { font-size: 0.9em; color: #555; margin-top: -10px; margin-bottom: 10px;}
        /* ▲▲▲ 追加 ▲▲▲ */
    </style>
</head>
<body>

    <h1>Playwright 入力データ ジェネレーター (JSON)</h1>
    <p>Webサイトの自動化手順を入力し、Web-Runner 用の入力データ (<code>input.json</code>) を生成・ダウンロードします。</p>

    <form id="mcp-form">

        <h2>1. 開始URL</h2>
        <div class="form-group">
            <label for="start_url">自動化を開始するURL:</label>
            <input type="url" id="start_url" name="start_url" placeholder="https://example.com" required>
        </div>

        <h2>2. 操作ステップ</h2>
        <div id="steps-container">
            <!-- ステップ1 (初期表示用) -->
            <div class="step" data-step-index="0">
                <h3>ステップ 1 <button type="button" class="remove-step" onclick="removeStep(this)">削除</button></h3>
                 <!-- ▼▼▼ メモ欄を追加 ▼▼▼ -->
                <div class="form-group">
                    <label for="memo_0">メモ:</label>
                    <input type="text" id="memo_0" name="memo_0" placeholder="例: クリックする, contentを取得する, URLを取得する">
                    <small>※ このメモはJSONに保存されますが、実行時には無視されます。</small>
                </div>
                <!-- ▲▲▲ メモ欄を追加 ▲▲▲ -->
                <div class="form-group">
                    <label for="action_0">操作:</label>
                    <select id="action_0" name="action_0" required onchange="toggleActionFields(this)">
                        <option value="">-- 選択してください --</option>
                        <option value="click">要素をクリック (Click)</option>
                        <option value="input">要素に入力 (Input Text)</option>
                        <option value="hover">要素にマウスオーバー (Hover)</option>
                        <option value="get_inner_text">テキスト取得 (単一: innerText)</option>
                        <option value="get_text_content">テキスト取得 (単一: textContent)</option>
                        <option value="get_inner_html">HTML取得 (単一: innerHTML)</option>
                        <option value="get_attribute">属性値を取得 (単一: Get Attribute)</option>
                        <option value="get_all_attributes">属性値/コンテンツ取得 (複数: Get All Attribute)</option> <!-- 名称変更 -->
                        <option value="get_all_text_contents">テキストリストを取得 (複数: Get All textContents)</option>
                        <option value="wait_visible">要素が表示されるまで待つ (Wait Visible)</option>
                        <option value="select_option">ドロップダウンを選択 (Select Option)</option>
                        <option value="screenshot">スクリーンショットを撮る (Screenshot)</option>
                        <option value="scroll_page_to_bottom">ページ最下部へスクロール (Scroll Page Bottom)</option>
                        <option value="scroll_to_element">要素までスクロール (Scroll To Element)</option>
                        <option value="wait_page_load">ページ読み込み完了を待つ (Wait Page Load)</option>
                        <option value="sleep">指定時間待機 (Sleep)</option>
                        <option value="switch_to_iframe">iframe に切り替える (Switch to iframe)</option>
                        <option value="switch_to_parent_frame">親フレームに戻る (Switch to Parent Frame)</option>
                    </select>
                </div>
                <div class="form-group selector-group">
                    <label for="selector_0">対象要素のCSSセレクター:</label>
                    <input type="text" id="selector_0" name="selector_0" placeholder="#id, .class, tag[attribute=value]">
                    <small><br/>※ ページ全体操作(スクロール, 読み込み待機, sleep, 親フレームへ戻る)では不要</small>
                </div>
                 <!-- --- 各アクションの付加情報フィールド --- -->
                 <div class="form-group action-field iframe_selector-group hidden">
                    <label for="iframe_selector_0">iframeのCSSセレクター:</label>
                    <input type="text" id="iframe_selector_0" name="iframe_selector_0" placeholder="#frame-id, iframe[name=frame-name]">
                    <small>※ <code>switch_to_iframe</code> を選択した場合に必須</small>
                </div>
                <div class="form-group action-field input-field hidden">
                    <label for="value_0">入力するテキスト:</label>
                    <input type="text" id="value_0" name="value_0" placeholder="入力する値">
                </div>
                 <!-- ▼▼▼ get_attribute / get_all_attributes 用フィールド ▼▼▼ -->
                <div class="form-group action-field get_attribute-field hidden">
                    <label for="attribute_name_0">取得する属性名:</label>
                    <input type="text" id="attribute_name_0" name="attribute_name_0" placeholder="通常の属性名 (例: value, src, class)">
                     <!-- ▼▼▼ 補足説明を追加 ▼▼▼ -->
                    <small class="attribute-hint">
                        ※ <code>get_all_attributes</code> の場合、特別な値も指定可能:<br/>
                           ・ <strong><code>href</code></strong>: リンク先のURLリストを取得<br/>
                           ・ <strong><code>pdf</code></strong>: リンク先のPDFファイルの内容（テキスト）を取得<br/>
                           ・ <strong><code>content</code></strong>: リンク先ページの内容（innerText）を取得 (PDF以外)
                    </small>
                    <!-- ▲▲▲ 補足説明を追加 ▲▲▲ -->
                </div>
                <!-- ▲▲▲ get_attribute / get_all_attributes 用フィールド ▲▲▲ -->
                <div class="form-group action-field select_option-field hidden">
                    <label>ドロップダウン選択方法:</label>
                    <div class="option-group">
                         <label><input type="radio" name="option_type_0" value="value" checked> 値 (Value)</label>
                         <label><input type="radio" name="option_type_0" value="index"> インデックス (Index)</label>
                         <label><input type="radio" name="option_type_0" value="label"> 表示ラベル (Label)</label>
                    </div>
                    <label for="option_value_0">選択する値/インデックス/ラベル:</label>
                    <input type="text" id="option_value_0" name="option_value_0" placeholder="選択する項目">
                    <small>※ インデックスは0から始まる数値</small>
                </div>
                <div class="form-group action-field sleep-field hidden">
                    <label for="sleep_seconds_0">待機時間 (秒):</label>
                    <input type="number" id="sleep_seconds_0" name="sleep_seconds_0" placeholder="例: 3" step="0.1" min="0">
                </div>
                 <div class="form-group action-field screenshot-field hidden">
                    <label for="screenshot_filename_0">ファイル名 (任意):</label>
                    <input type="text" id="screenshot_filename_0" name="screenshot_filename_0" placeholder="例: screenshot_step1.png">
                 </div>
                 <div class="form-group action-field wait-field hidden">
                    <label for="wait_time_ms_0">最大待機時間 (ミリ秒、任意):</label>
                    <input type="number" id="wait_time_ms_0" name="wait_time_ms_0" placeholder="デフォルト値はサーバー設定" value="3000" min="1"> <!-- デフォルト値を更新 -->
                </div>
            </div>
        </div>
        <button type="button" id="add-step" onclick="addStep()">ステップを追加</button>

        <div class="button-container">
            <button type="button" id="generate-json-button" onclick="generateJsonData()">
                 入力データ生成 (JSON)
                 <span id="loading-indicator" class="loader hidden"></span>
            </button>
            <button type="button" id="copy-json-button" onclick="copyJson()" class="hidden">JSONをコピー</button>
            <button type="button" id="download-json-button" onclick="downloadJson()" class="hidden">input.json をダウンロード</button>
        </div>
    </form>

    <div id="generated-json-container" class="hidden">
        <h2>生成された入力データ (JSON):</h2>
        <pre><code id="generated-json"></code></pre>
    </div>
    <div id="error-message"></div>

    <script>
        function toggleActionFields(selectElement) {
            const stepDiv = selectElement.closest('.step');
            const action = selectElement.value;
            const stepIndex = stepDiv.dataset.stepIndex;

            stepDiv.querySelectorAll('.action-field').forEach(el => el.classList.add('hidden'));

            const selectorGroup = stepDiv.querySelector('.selector-group');
            const selectorInput = stepDiv.querySelector(`input[name="selector_${stepIndex}"]`);
            const iframeSelectorGroup = stepDiv.querySelector('.iframe_selector-group');
            const iframeSelectorInput = stepDiv.querySelector(`input[name="iframe_selector_${stepIndex}"]`);

            const noSelectorNeeded = ['scroll_page_to_bottom', 'wait_page_load', 'sleep', 'switch_to_parent_frame'];
            const iframeSelectorNeeded = ['switch_to_iframe'];
            const elementSelectorNeeded = !noSelectorNeeded.includes(action) && !iframeSelectorNeeded.includes(action);

            if (selectorGroup && selectorInput) {
                selectorGroup.classList.toggle('hidden', !elementSelectorNeeded);
                selectorInput.required = elementSelectorNeeded;
                selectorInput.disabled = !elementSelectorNeeded;
                if (!elementSelectorNeeded) selectorInput.value = '';
            }
            if (iframeSelectorGroup && iframeSelectorInput) {
                iframeSelectorGroup.classList.toggle('hidden', !iframeSelectorNeeded.includes(action));
                iframeSelectorInput.required = iframeSelectorNeeded.includes(action);
                iframeSelectorInput.disabled = !iframeSelectorNeeded.includes(action);
                if (!iframeSelectorNeeded.includes(action)) iframeSelectorInput.value = '';
            }

            const fieldsToShow = {
                'input': '.input-field',
                'get_attribute': '.get_attribute-field',
                'get_all_attributes': '.get_attribute-field', // 属性名入力フィールドを共用
                'select_option': '.select_option-field',
                'sleep': '.sleep-field',
                'screenshot': '.screenshot-field'
            };
             if (fieldsToShow[action]) {
                const fieldDiv = stepDiv.querySelector(fieldsToShow[action]);
                if (fieldDiv) fieldDiv.classList.remove('hidden');
            }

            const waitField = stepDiv.querySelector('.wait-field');
            if (waitField) {
                const showWait = elementSelectorNeeded || iframeSelectorNeeded.includes(action) || action === 'wait_page_load' || action === 'get_all_attributes'; // get_all_attributesでも待機時間表示
                waitField.classList.toggle('hidden', !showWait);
            }
        }

        // --- ステップ追加 (変更なし) ---
        function addStep() {
            const stepsContainer = document.getElementById('steps-container');
            const stepIndex = stepsContainer.children.length;
            const newStep = document.createElement('div');
            newStep.classList.add('step');
            newStep.dataset.stepIndex = stepIndex;
            const firstStepHtml = document.querySelector('.step[data-step-index="0"]').innerHTML;
            const stepContentHtml = firstStepHtml.replace(/<h3.*?<\/h3>/s, '');
            newStep.innerHTML = `<h3>ステップ ${stepIndex + 1} <button type="button" class="remove-step" onclick="removeStep(this)">削除</button></h3>` +
                                stepContentHtml.replace(/_0"/g, `_${stepIndex}"`).replace(/_0'/g, `_${stepIndex}'`).replace(/_0</g, `_${stepIndex}<`);
            stepsContainer.appendChild(newStep);
            newStep.querySelectorAll('input[type="text"], input[type="number"], input[type="url"]').forEach(input => input.value = '');
            newStep.querySelectorAll('select').forEach(select => select.selectedIndex = 0);
            newStep.querySelectorAll('input[type="radio"]').forEach((radio, idx) => radio.checked = (idx === 0));
            toggleActionFields(newStep.querySelector('select'));
            updateStepNumbers();
        }

        // --- ステップ削除 (変更なし) ---
        function removeStep(button) {
            const stepDiv = button.closest('.step');
            const stepsContainer = document.getElementById('steps-container');
            if (stepsContainer.children.length > 1) {
                stepDiv.remove();
                updateStepNumbers();
            } else {
                alert('最初のステップは削除できません。');
            }
        }

        // --- ステップ番号更新 (変更なし) ---
        function updateStepNumbers() {
            const steps = document.querySelectorAll('#steps-container .step');
            steps.forEach((step, index) => {
                step.dataset.stepIndex = index;
                step.querySelector('h3').firstChild.textContent = `ステップ ${index + 1} `;
                step.querySelectorAll('[id]').forEach(el => { el.id = el.id.replace(/_\d+$/, `_${index}`); });
                step.querySelectorAll('[name]').forEach(el => { el.name = el.name.replace(/_\d+$/, `_${index}`); });
                step.querySelectorAll('label[for]').forEach(el => { el.htmlFor = el.htmlFor.replace(/_\d+$/, `_${index}`); });
            });
        }

        // --- JSONデータ生成 (変更) ---
        function generateJsonData() {
            const form = document.getElementById('mcp-form');
            const generateButton = document.getElementById('generate-json-button');
            const loadingIndicator = document.getElementById('loading-indicator');
            const jsonContainer = document.getElementById('generated-json-container');
            const jsonElement = document.getElementById('generated-json');
            const errorElement = document.getElementById('error-message');
            const copyButton = document.getElementById('copy-json-button');
            const downloadButton = document.getElementById('download-json-button');

            generateButton.disabled = true;
            loadingIndicator.classList.remove('hidden');
            jsonElement.textContent = 'JSONデータ生成中...';
            errorElement.textContent = '';
            jsonContainer.classList.remove('hidden');
            copyButton?.classList.add('hidden');
            downloadButton?.classList.add('hidden');

            const outputData = {
                target_url: form.querySelector('#start_url')?.value,
                actions: []
            };

            let formIsValid = true;
            if (!outputData.target_url || !isValidHttpUrl(outputData.target_url)) {
                errorElement.textContent = '有効な開始URL (http:// または https://) を入力してください。';
                formIsValid = false;
            }

            const steps = document.querySelectorAll('#steps-container .step');
            steps.forEach((step, index) => {
                if (!formIsValid) return;
                const stepIndex = index;
                const actionSelect = step.querySelector(`select[name="action_${stepIndex}"]`);
                const action = actionSelect ? actionSelect.value : '';
                if (!action) { errorElement.textContent = `ステップ ${index + 1}: 操作を選択してください。`; formIsValid = false; return; }
                const actionData = { action: action };

                 // --- メモを追加 ---
                const memoInput = step.querySelector(`input[name="memo_${stepIndex}"]`);
                const memo = memoInput ? memoInput.value.trim() : '';
                if (memo) { actionData.memo = memo; }

                const noSelectorNeeded = ['scroll_page_to_bottom', 'wait_page_load', 'sleep', 'switch_to_parent_frame'];
                const iframeSelectorNeeded = ['switch_to_iframe'];
                const elementSelectorNeeded = !noSelectorNeeded.includes(action) && !iframeSelectorNeeded.includes(action);

                if (elementSelectorNeeded) {
                    const selectorInput = step.querySelector(`input[name="selector_${stepIndex}"]`);
                    const selector = selectorInput ? selectorInput.value.trim() : null;
                    if (!selector) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' には要素のCSSセレクターが必要です。`; formIsValid = false; return; }
                    actionData.selector = selector;
                }
                if (iframeSelectorNeeded.includes(action)) {
                    const iframeSelectorInput = step.querySelector(`input[name="iframe_selector_${stepIndex}"]`);
                    const iframeSelector = iframeSelectorInput ? iframeSelectorInput.value.trim() : null;
                    if (!iframeSelector) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' にはiframeのCSSセレクターが必要です。`; formIsValid = false; return; }
                    actionData.iframe_selector = iframeSelector;
                }

                const waitTimeoutInput = step.querySelector(`input[name="wait_time_ms_${stepIndex}"]`);
                if (waitTimeoutInput && waitTimeoutInput.value.trim() !== '') {
                    const timeout = parseInt(waitTimeoutInput.value.trim(), 10);
                    if (!isNaN(timeout) && timeout >= 1) { actionData.wait_time_ms = timeout; }
                    else { errorElement.textContent = `ステップ ${index + 1}: 待機時間は1以上の数値をミリ秒で入力してください。`; formIsValid = false; return; }
                }

                if (action === 'input') {
                    actionData.value = step.querySelector(`input[name="value_${stepIndex}"]`)?.value ?? '';
                } else if (action === 'get_attribute' || action === 'get_all_attributes') {
                    const attrName = step.querySelector(`input[name="attribute_name_${stepIndex}"]`)?.value.trim();
                    if (!attrName) { errorElement.textContent = `ステップ ${index + 1}: アクション '${action}' には取得する属性名が必要です。`; formIsValid = false; return; }
                    actionData.attribute_name = attrName;
                } else if (action === 'select_option') {
                    const optionType = step.querySelector(`input[name="option_type_${stepIndex}"]:checked`)?.value;
                    let optionValue = step.querySelector(`input[name="option_value_${stepIndex}"]`)?.value;
                    if (!optionType || optionValue === null || optionValue === undefined) { errorElement.textContent = `ステップ ${index + 1}: ドロップダウン選択方法と値を入力してください。`; formIsValid = false; return; }
                    actionData.option_type = optionType;
                    if (optionType === 'index') {
                        const indexVal = parseInt(optionValue, 10);
                        if (isNaN(indexVal) || indexVal < 0) { errorElement.textContent = `ステップ ${index + 1}: インデックスは0以上の数値を入力してください。`; formIsValid = false; return; }
                        actionData.option_value = indexVal;
                    } else { actionData.option_value = optionValue; }
                } else if (action === 'sleep') {
                    const secondsInput = step.querySelector(`input[name="sleep_seconds_${stepIndex}"]`);
                    if (!secondsInput || secondsInput.value.trim() === '') { errorElement.textContent = `ステップ ${index + 1}: sleep アクションには待機時間 (秒) が必要です。`; formIsValid = false; return; }
                    const seconds = parseFloat(secondsInput.value);
                    if (isNaN(seconds) || seconds < 0) { errorElement.textContent = `ステップ ${index + 1}: 待機時間は0以上の数値を秒で入力してください。`; formIsValid = false; return; }
                    actionData.value = seconds;
                } else if (action === 'screenshot') {
                    const filename = step.querySelector(`input[name="screenshot_filename_${stepIndex}"]`)?.value.trim();
                    actionData.value = filename || null;
                }
                outputData.actions.push(actionData);
            });

            if (!formIsValid) {
                jsonElement.textContent = '入力エラーがあります。フォームを確認してください。';
                generateButton.disabled = false;
                loadingIndicator.classList.add('hidden');
                copyButton?.classList.add('hidden');
                downloadButton?.classList.add('hidden');
                return;
            }

            const jsonString = JSON.stringify(outputData, null, 2);
            jsonElement.textContent = jsonString;
            errorElement.textContent = '';
            copyButton?.classList.remove('hidden');
            downloadButton?.classList.remove('hidden');
            generateButton.disabled = false;
            loadingIndicator.classList.add('hidden');
        }

        // URL簡易バリデーション
        function isValidHttpUrl(string) { try { const url = new URL(string); return url.protocol === "http:" || url.protocol === "https:"; } catch (_) { return false; } }

        // JSONコピー
        function copyJson() {
            const jsonElement = document.getElementById('generated-json');
            if (!jsonElement || !jsonElement.textContent || jsonElement.textContent.startsWith('JSON') || jsonElement.textContent.startsWith('入力エラー')) { alert('コピーする有効なJSONデータがありません。'); return; }
            navigator.clipboard.writeText(jsonElement.textContent).then(() => alert('JSONデータがクリップボードにコピーされました！')).catch(err => { alert('コピーに失敗しました。コンソールを確認してください。'); console.error('Copy failed:', err); });
        }

        // JSONダウンロード
        function downloadJson() {
            const jsonElement = document.getElementById('generated-json');
            const jsonString = jsonElement.textContent;
            if (!jsonString || jsonString.startsWith('JSON') || jsonString.startsWith('入力エラー')) { alert('ダウンロードする有効なJSONデータがありません。'); return; }
            try {
                const blob = new Blob([jsonString], { type: 'application/json' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'input.json'; // ファイル名を input.json に固定
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            } catch (error) { alert('ダウンロードに失敗しました。'); console.error('Download failed', error); }
        }

        // 初期表示時のフィールド更新
        document.addEventListener('DOMContentLoaded', () => {
             document.querySelectorAll('.step').forEach(step => {
                 const select = step.querySelector('select');
                 if (select) toggleActionFields(select);
             });
         });
    </script>

</body>
</html>


---


- フォルダ名: .
- ファイル名: main.py
- 内容:
# --- ファイル: main.py (修正版) ---
"""
スクリプトのエントリーポイント。引数解析、初期化、実行、結果出力を行う。
MCPサーバーとは独立して、このファイル単体でも実行可能。
"""
import argparse
import asyncio
import logging
import os
import sys
import pprint

# --- 各モジュールをインポート ---
import config
import utils
# --- ▼▼▼ 修正 ▼▼▼ ---
# import playwright_handler -> playwright_launcher をインポート
import playwright_launcher
# --- ▲▲▲ 修正 ▲▲▲ ---

# --- エントリーポイント ---
if __name__ == "__main__":
    # --- 1. ロギング設定 (単体実行用) ---
    utils.setup_logging_for_standalone(config.LOG_FILE)

    # --- 2. コマンドライン引数解析 ---
    parser = argparse.ArgumentParser(
        description="JSON入力に基づき Playwright 自動化を実行 (iframe動的探索対応)。",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--input",
        default=config.DEFAULT_INPUT_FILE,
        metavar="FILE",
        help="URL とアクションを含む JSON ファイルのパス。"
    )
    parser.add_argument(
        '--headless',
        action=argparse.BooleanOptionalAction, # --headless / --no-headless を使えるように
        default=False, # デフォルトは表示 (False)
        help="ブラウザをヘッドレスモードで実行 (--no-headless で表示)。"
    )
    parser.add_argument(
        '--slowmo',
        type=int,
        default=100,
        metavar="MS",
        help="各操作間の待機時間(ms)。"
    )
    args = parser.parse_args()

    # --- 3. 入力ファイルパス解決 ---
    input_arg = args.input
    json_file_path = input_arg
    # 入力がファイル名のみで、json/ ディレクトリに存在する場合、そちらを優先
    if not os.path.isabs(input_arg) and \
       not os.path.dirname(input_arg) and \
       os.path.exists(os.path.join('json', input_arg)):
        json_file_path = os.path.join('json', input_arg)
        logging.info(f"--input でファイル名のみ指定され、'json' ディレクトリ内に '{input_arg}' が見つかったため、'{json_file_path}' を使用します。")
    elif not os.path.exists(input_arg):
        logging.critical(f"指定された入力ファイル '{input_arg}' が見つかりません。") # criticalに変更
        sys.exit(1) # 単体実行時は見つからなければ終了

    # スクリーンショットディレクトリ作成
    os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)

    # --- 4. メイン処理実行 ---
    try:
        input_data = utils.load_input_from_json(json_file_path)
        target_url = input_data.get("target_url")
        actions = input_data.get("actions")

        # JSONファイル内のタイムアウト指定を優先、なければconfigの値
        effective_default_timeout = input_data.get("default_timeout_ms", config.DEFAULT_ACTION_TIMEOUT)
        logging.info(f"実行に使用するデフォルトアクションタイムアウト: {effective_default_timeout}ms")

        if not target_url or not actions:
            logging.critical(f"エラー: JSON '{json_file_path}' から target_url または actions を取得できませんでした。")
            sys.exit(1)

        # --- ▼▼▼ 修正 ▼▼▼ ---
        # Playwrightハンドラ -> ランチャー を呼び出し
        success, results = asyncio.run(playwright_launcher.run_playwright_automation_async(
            target_url=str(target_url), # URLは文字列として渡す
            actions=actions,
            headless_mode=args.headless, # BooleanOptionalAction の結果を渡す
            slow_motion=args.slowmo,
            default_timeout=effective_default_timeout
        ))
        # --- ▲▲▲ 修正 ▲▲▲ ---

        # --- 5. 結果表示・出力 ---
        print("\n--- 最終実行結果 ---")
        # pprintで見やすく整形して表示
        pprint.pprint(results)
        logging.info(f"最終実行結果(詳細):\n{pprint.pformat(results)}")

        # 結果ファイル書き込み (utils内の関数を使用)
        utils.write_results_to_file(results, config.RESULTS_OUTPUT_FILE) # 単体実行用出力ファイル

        sys.exit(0 if success else 1)

    except FileNotFoundError as e:
         logging.critical(f"入力ファイル処理中にエラー: {e}")
         sys.exit(1)
    except Exception as e:
        logging.critical(f"スクリプト実行の最上位で予期せぬエラーが発生: {e}", exc_info=True)
        sys.exit(1)


---


- フォルダ名: .
- ファイル名: playwright_actions.py
- 内容:
# --- ファイル: playwright_actions.py ---
"""
Playwrightの各アクション（クリック、入力、取得など）を実行するコアロジック。
"""
import asyncio
import logging
import os
import time
import pprint
import traceback
from urllib.parse import urljoin
from typing import List, Tuple, Optional, Union, Dict, Any

from playwright.async_api import (
    Page,
    Frame,
    Locator,
    FrameLocator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
    APIRequestContext
)

import config
import utils # PDF処理などで使用
from playwright_finders import find_element_dynamically, find_all_elements_dynamically
from playwright_helper_funcs import get_page_inner_text

logger = logging.getLogger(__name__)

async def execute_actions_async(
    initial_page: Page,
    actions: List[Dict[str, Any]],
    api_request_context: APIRequestContext,
    default_timeout: int
) -> Tuple[bool, List[Dict[str, Any]]]:
    """
    指定されたページを起点として、定義されたアクションリストを順に実行します。
    iframeの探索や切り替え、データ取得、エラーハンドリングなどを行います。
    実行全体の成否 (bool) と、各ステップの結果詳細のリスト (List[dict]) を返します。
    """
    results: List[Dict[str, Any]] = []
    current_target: Union[Page, FrameLocator] = initial_page # 現在の操作対象スコープ
    root_page: Page = initial_page # ルートとなるページオブジェクト (ページ遷移後も更新)
    current_context: BrowserContext = root_page.context # 現在のブラウザコンテキスト
    iframe_stack: List[Union[Page, FrameLocator]] = [] # iframe切り替えのためのスタック

    for i, step_data in enumerate(actions):
        step_num = i + 1
        action = step_data.get("action", "").lower()
        selector = step_data.get("selector")
        iframe_selector_input = step_data.get("iframe_selector")
        value = step_data.get("value")
        attribute_name = step_data.get("attribute_name")
        option_type = step_data.get("option_type")
        option_value = step_data.get("option_value")
        # アクション固有タイムアウト > 全体デフォルトタイムアウト > configデフォルト
        action_wait_time = step_data.get("wait_time_ms", default_timeout)

        logger.info(f"--- ステップ {step_num}/{len(actions)}: Action='{action}' ---")
        step_info = {"selector": selector, "value": value, "iframe(指定)": iframe_selector_input,
                     "option_type": option_type, "option_value": option_value, "attribute_name": attribute_name}
        # Noneでない値だけをログに出力
        step_info_str = ", ".join([f"{k}='{str(v)[:50]}{'...' if len(str(v)) > 50 else ''}'" # 値が長い場合は省略
                                   for k, v in step_info.items() if v is not None])
        logger.info(f"詳細: {step_info_str} (timeout: {action_wait_time}ms)")

        try:
            # 各ステップ開始前にページが閉じられていないか確認
            if root_page.is_closed():
                raise PlaywrightError(f"Root page was closed before step {step_num}.")
            # 現在の状態をログ出力
            current_base_url = root_page.url
            root_page_title = await root_page.title()
            current_target_type = type(current_target).__name__
            logger.info(f"現在のルートページ: URL='{current_base_url}', Title='{root_page_title}'")
            logger.info(f"現在の探索スコープ: {current_target_type}")
        except Exception as e:
            logger.error(f"ステップ {step_num} 開始前の状態取得中にエラー: {e}", exc_info=True)
            results.append({"step": step_num, "status": "error", "action": action, "message": f"Failed to get target info before step: {e}"})
            return False, results # 状態取得失敗は致命的として中断

        try:
            # --- Iframe/Parent Frame 切替 ---
            if action == "switch_to_iframe":
                if not iframe_selector_input:
                    raise ValueError("Action 'switch_to_iframe' requires 'iframe_selector'")
                logger.info(f"[ユーザー指定] Iframe '{iframe_selector_input}' に切り替えます...")
                target_frame_locator: Optional[FrameLocator] = None
                try:
                    # 現在のターゲットから iframe を探す
                    target_frame_locator = current_target.frame_locator(iframe_selector_input)
                    # iframeが存在し、アクセス可能か確認 (ルート要素の存在確認)
                    await target_frame_locator.locator(':root').wait_for(state='attached', timeout=action_wait_time)
                except PlaywrightTimeoutError:
                    # 見つからない場合は明確なエラーとする
                    raise PlaywrightTimeoutError(f"指定されたiframe '{iframe_selector_input}' が現在のスコープ '{type(current_target).__name__}' で見つからないか、タイムアウト({action_wait_time}ms)しました。")
                except Exception as e:
                    raise PlaywrightError(f"Iframe '{iframe_selector_input}' への切り替え中に予期せぬエラーが発生しました: {e}")

                # 切り替え成功
                if id(current_target) not in [id(s) for s in iframe_stack]: # 現在のターゲットがまだスタックになければ追加
                    iframe_stack.append(current_target)
                current_target = target_frame_locator # ターゲットを新しい FrameLocator に更新
                logger.info(f"FrameLocator '{iframe_selector_input}' への切り替え成功。")
                results.append({"step": step_num, "status": "success", "action": action, "selector": iframe_selector_input})
                continue # 次のステップへ

            elif action == "switch_to_parent_frame":
                if not iframe_stack:
                    logger.warning("既にトップレベルフレームか、iframeスタックが空です。操作はスキップされます。")
                    # FrameLocatorの場合のみルートページに戻す安全策は維持
                    if isinstance(current_target, FrameLocator):
                        logger.info("現在のターゲットがFrameLocatorのため、ルートページに戻します。")
                        current_target = root_page
                    results.append({"step": step_num, "status": "warning", "action": action, "message": "Already at top-level or stack empty."})
                else:
                    logger.info("[ユーザー指定] 親ターゲットに戻ります...")
                    current_target = iframe_stack.pop() # スタックから親ターゲットを取り出す
                    target_type = type(current_target).__name__
                    logger.info(f"親ターゲットへの切り替え成功。現在の探索スコープ: {target_type}")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- ページ全体操作 ---
            if action in ["wait_page_load", "sleep", "scroll_page_to_bottom"]:
                if action == "wait_page_load":
                    logger.info("ページの読み込み完了 (load) を待ちます...")
                    await root_page.wait_for_load_state("load", timeout=action_wait_time)
                    logger.info("ページの読み込みが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                elif action == "sleep":
                    try:
                        seconds = float(value) if value is not None else 1.0 # デフォルト1秒
                        if seconds < 0: raise ValueError("Sleep time cannot be negative.")
                    except (TypeError, ValueError):
                        raise ValueError("Invalid value for sleep action. Must be a non-negative number (seconds).")
                    logger.info(f"{seconds:.1f} 秒待機します...")
                    await asyncio.sleep(seconds)
                    results.append({"step": step_num, "status": "success", "action": action, "duration_sec": seconds})
                elif action == "scroll_page_to_bottom":
                    logger.info("ページ最下部へスクロールします...")
                    # JavaScriptを実行してスクロール
                    await root_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                    await asyncio.sleep(0.5) # スクロール後の描画やイベント発生を少し待つ
                    logger.info("ページ最下部へのスクロールが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- 要素操作のための準備 ---
            element: Optional[Locator] = None # 単一要素操作用
            found_elements_list: List[Tuple[Locator, Union[Page, FrameLocator]]] = [] # 複数要素操作用
            found_scope: Optional[Union[Page, FrameLocator]] = None # 要素が見つかったスコープ

            # アクションが単一要素を必要とするか、複数要素を対象とするか
            single_element_required_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "wait_visible", "select_option", "scroll_to_element"]
            multiple_elements_actions = ["get_all_attributes", "get_all_text_contents"]
            # スクリーンショットはセレクターがあれば単一要素、なければページ全体
            is_screenshot_element = action == "screenshot" and selector is not None

            if action in single_element_required_actions or action in multiple_elements_actions or is_screenshot_element:
                if not selector:
                    raise ValueError(f"Action '{action}' requires a 'selector'.")

                # --- 要素探索 ---
                if action in single_element_required_actions or is_screenshot_element:
                    # 探索する要素の状態を決定
                    required_state = 'visible' if action in ['click', 'hover', 'screenshot', 'select_option', 'input', 'wait_visible', 'scroll_to_element'] else 'attached'
                    logger.info(f"単一要素 '{selector}' (状態: {required_state}) を動的に探索します...")
                    element, found_scope = await find_element_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time, target_state=required_state
                    )
                    if not element or not found_scope:
                        # 要素が見つからない場合は明確なエラーとして処理を中断
                        error_msg = f"要素 '{selector}' (状態: {required_state}) が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。"
                        logger.error(error_msg)
                        results.append({"step": step_num, "status": "error", "action": action, "selector": selector, "required_state": required_state, "message": error_msg})
                        return False, results # Falseを返して処理中断

                    # 要素が見つかったスコープが現在の探索スコープと異なる場合、ターゲットを更新
                    if id(found_scope) != id(current_target):
                        found_scope_type = type(found_scope).__name__
                        logger.info(f"要素発見スコープ({found_scope_type})が現在のスコープ({type(current_target).__name__})と異なるため、探索スコープを更新します。")
                        # スタック管理: 現在のターゲットをスタックに追加 (重複回避)
                        if id(current_target) not in [id(s) for s in iframe_stack]:
                            iframe_stack.append(current_target)
                        current_target = found_scope
                    logger.info(f"最終的な単一操作対象スコープ: {type(current_target).__name__}")

                elif action in multiple_elements_actions:
                    logger.info(f"複数要素 '{selector}' を動的に探索します...")
                    found_elements_list = await find_all_elements_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time
                    )
                    if not found_elements_list:
                        # 複数要素が見つからなくてもエラーとはせず、警告ログに留め、後続処理で空リストとして扱う
                        logger.warning(f"要素 '{selector}' が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。")
                    # 複数要素の場合、見つかった各要素のスコープは異なる可能性があるため、current_target は更新しない


            # --- 各アクション実行 ---
            action_result_details = {"selector": selector} if selector else {} # 結果にセレクター情報を含める

            if action == "click":
                if not element: raise ValueError("Click action requires an element, but it was not found.")
                logger.info("要素をクリックします...")
                context_for_click = root_page.context # 新しいページが開くイベントはルートページのコンテキストで捕捉
                new_page: Optional[Page] = None
                try:
                    # 新しいページが開く可能性を考慮して待機 (タイムアウトは短めに設定)
                    async with context_for_click.expect_page(timeout=config.NEW_PAGE_EVENT_TIMEOUT) as new_page_info:
                        await element.click(timeout=action_wait_time)
                    # タイムアウト内に新しいページが開いた場合
                    new_page = await new_page_info.value
                    new_page_url = new_page.url
                    logger.info(f"クリックにより新しいページが開きました: URL={new_page_url}")
                    try:
                        # 新しいページのロード完了を待つ (タイムアウトはアクション固有時間)
                        await new_page.wait_for_load_state("load", timeout=action_wait_time)
                        logger.info("新しいページのロードが完了しました。")
                    except PlaywrightTimeoutError:
                        logger.warning(f"新しいページのロード待機がタイムアウトしました ({action_wait_time}ms)。処理は続行します。")
                    # 操作対象を新しいページに切り替え、iframeスタックをクリア
                    root_page = new_page
                    current_target = new_page
                    current_context = new_page.context
                    iframe_stack.clear()
                    logger.info("スコープを新しいページにリセットしました。iframeスタックもクリアされました。")
                    action_result_details.update({"new_page_opened": True, "new_page_url": new_page_url})
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})
                except PlaywrightTimeoutError:
                    # expect_pageがタイムアウトした場合 (新しいページが開かなかった場合)
                    logger.info(f"クリックは完了しましたが、{config.NEW_PAGE_EVENT_TIMEOUT}ms 以内に新しいページは開きませんでした。")
                    action_result_details["new_page_opened"] = False
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})
                except Exception as click_err:
                    # クリック自体が失敗した場合など
                    logger.error(f"クリック操作中に予期せぬエラーが発生しました: {click_err}", exc_info=True)
                    raise click_err # エラーを再送出してステップ全体のエラーハンドリングに任せる

            elif action == "input":
                 if not element: raise ValueError("Input action requires an element.")
                 if value is None: raise ValueError("Input action requires 'value'.")
                 input_value_str = str(value)
                 logger.info(f"要素に '{input_value_str[:50]}{'...' if len(input_value_str) > 50 else ''}' を入力します...")
                 # fill: 要素の内容をクリアしてから入力する
                 await element.fill(input_value_str, timeout=action_wait_time)
                 logger.info("入力が成功しました。")
                 action_result_details["value"] = value # 結果には元の値を保持
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "hover":
                 if not element: raise ValueError("Hover action requires an element.")
                 logger.info("要素にマウスオーバーします...")
                 await element.hover(timeout=action_wait_time)
                 logger.info("ホバーが成功しました。")
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_text":
                 if not element: raise ValueError("Get innerText action requires an element.")
                 logger.info("要素の innerText を取得します...")
                 text = await element.inner_text(timeout=action_wait_time)
                 text = text.strip() if text else "" # 前後の空白除去
                 logger.info(f"取得テキスト(innerText): '{text[:100]}{'...' if len(text) > 100 else ''}'") # 長いテキストは省略
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_text_content":
                 if not element: raise ValueError("Get textContent action requires an element.")
                 logger.info("要素の textContent を取得します...")
                 text = await element.text_content(timeout=action_wait_time)
                 text = text.strip() if text else "" # 前後の空白を除去
                 logger.info(f"取得テキスト(textContent): '{text[:100]}{'...' if len(text) > 100 else ''}'")
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_html":
                 if not element: raise ValueError("Get innerHTML action requires an element.")
                 logger.info("要素の innerHTML を取得します...")
                 html_content = await element.inner_html(timeout=action_wait_time)
                 logger.info(f"取得HTML(innerHTML):\n{html_content[:500]}{'...' if len(html_content) > 500 else ''}") # 先頭のみ表示
                 action_result_details["html"] = html_content
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_attribute":
                if not element: raise ValueError("Get attribute action requires an element.")
                if not attribute_name: raise ValueError("Action 'get_attribute' requires 'attribute_name'.")
                logger.info(f"要素の属性 '{attribute_name}' を取得します...")
                attr_value = await element.get_attribute(attribute_name, timeout=action_wait_time)
                pdf_text_content = None
                processed_value = attr_value # 結果に含める値（URL変換やPDFテキストが入る可能性）

                # --- href属性の場合の特別処理 ---
                if attribute_name.lower() == 'href' and attr_value is not None:
                    original_url = attr_value
                    try:
                        # 絶対URLに変換
                        absolute_url = urljoin(current_base_url, original_url)
                        if original_url != absolute_url:
                            logger.info(f"  href属性値を絶対URLに変換: '{original_url}' -> '{absolute_url}'")
                        processed_value = absolute_url # 結果には絶対URLを

                        # PDFかどうかを判定して処理
                        if isinstance(absolute_url, str) and absolute_url.lower().endswith('.pdf'):
                            logger.info(f"  リンク先がPDFファイルです。ダウンロードとテキスト抽出を試みます: {absolute_url}")
                            # PDFダウンロード (utilsを使用)
                            pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                            if pdf_bytes:
                                # PDFテキスト抽出 (utilsを使用, 同期関数を非同期実行)
                                pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                if isinstance(pdf_text_content, str) and pdf_text_content.startswith("Error:"):
                                     logger.error(f"  PDFテキスト抽出エラー: {pdf_text_content}")
                                else:
                                     log_text = pdf_text_content[:200] + '...' if pdf_text_content and len(pdf_text_content) > 200 else pdf_text_content
                                     logger.info(f"  PDFテキスト抽出完了 (先頭200文字): {log_text if log_text else 'None'}")
                            else:
                                pdf_text_content = "Error: PDF download failed or returned no data."
                                logger.error(f"  PDFダウンロード失敗: {absolute_url}")
                        else:
                             logger.debug(f"  リンク先はPDFではありません ({absolute_url})。")
                    except Exception as url_e:
                        error_detail = f"Error processing URL or PDF: {url_e}"
                        logger.error(f"  URL処理またはPDF処理中にエラーが発生しました (URL: '{original_url}'): {url_e}", exc_info=True)
                        pdf_text_content = error_detail # エラー情報を結果に含める

                logger.info(f"取得した属性値 ({attribute_name}): '{processed_value}'")
                action_result_details.update({"attribute": attribute_name, "value": processed_value}) # 結果には処理後の値を保存
                if pdf_text_content is not None:
                    action_result_details["pdf_text"] = pdf_text_content # PDFテキストも結果に含める
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_all_attributes":
                if not selector: raise ValueError("Action 'get_all_attributes' requires 'selector'.")
                if not attribute_name: raise ValueError("Action 'get_all_attributes' requires 'attribute_name'.")

                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、属性取得をスキップします。")
                    action_result_details["attribute_list"] = [] # 空リストを結果として設定
                    # href, pdf, content モードの場合も空リストを設定
                    if attribute_name.lower() in ['href', 'pdf', 'content']:
                        action_result_details["url_list"] = []
                    if attribute_name.lower() == 'pdf':
                        action_result_details["pdf_texts"] = []
                    if attribute_name.lower() == 'content':
                        action_result_details["scraped_texts"] = []
                else:
                    num_found = len(found_elements_list)
                    logger.info(f"動的探索で見つかった {num_found} 個の要素から属性/コンテンツ '{attribute_name}' を取得します。")

                    # 結果格納用リスト
                    url_list_for_file: List[Optional[str]] = []
                    pdf_texts_list_for_file: List[Optional[str]] = []
                    scraped_texts_list_for_file: List[Optional[str]] = []
                    generic_attribute_list_for_file: List[Optional[str]] = []

                    # --- 属性名に応じて処理を分岐 ---
                    if attribute_name.lower() in ['href', 'pdf', 'content']:
                        logger.info("href属性を取得し、絶対URLに変換、必要に応じてコンテンツを取得します...")

                        # 同時実行数を制御するためのセマフォを作成 (同時実行数5)
                        CONCURRENT_LIMIT = 5
                        semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)
                        logger.info(f"URLアクセス/コンテンツ取得の同時実行数を {CONCURRENT_LIMIT} に制限します。")

                        # 個々の要素から属性/コンテンツを取得する内部関数 (セマフォを受け取るように変更)
                        async def process_single_element_for_href_content(
                            locator: Locator, index: int, base_url: str, attr_mode: str, sem: asyncio.Semaphore # セマフォ引数を追加
                        ) -> Tuple[Optional[str], Optional[str], Optional[str]]:
                            """ 1要素のhrefを取得し、モードに応じてPDF/コンテンツも取得 (セマフォで同時実行制御) """
                            original_href: Optional[str] = None
                            absolute_url: Optional[str] = None
                            pdf_text: Optional[str] = None
                            scraped_text: Optional[str] = None

                            # セマフォを取得するまで待機し、処理ブロックを実行
                            async with sem:
                                try:
                                    logger.debug(f"  [{index+1}/{num_found}] Processing started (Semaphore acquired)...")
                                    # href属性取得 (個々のタイムアウトは短めに調整)
                                    href_timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)

                                    original_href = await locator.get_attribute("href", timeout=href_timeout)
                                    if original_href is None:
                                        logger.debug(f"  [{index+1}/{num_found}] href属性が見つかりません。")
                                        return None, None, None # この要素の処理は終了

                                    # 絶対URL変換
                                    try:
                                        absolute_url = urljoin(base_url, original_href)
                                    except Exception as url_conv_e:
                                         logger.warning(f"  [{index+1}/{num_found}] 絶対URL変換エラー ({original_href}): {url_conv_e}")
                                         absolute_url = f"Error converting URL: {original_href}" # エラー情報を含める

                                    # pdf モードの場合
                                    if attr_mode == 'pdf' and isinstance(absolute_url, str) and absolute_url.lower().endswith('.pdf'):
                                        pdf_start = time.monotonic()
                                        pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                                        if pdf_bytes:
                                            pdf_text = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                        else:
                                            pdf_text = "Error: PDF download failed or returned no data."
                                        pdf_elapsed = (time.monotonic() - pdf_start) * 1000
                                        logger.info(f"  [{index+1}/{num_found}] PDF処理完了 ({pdf_elapsed:.0f}ms) URL: {absolute_url}")

                                    # content モードの場合 (PDF以外)
                                    elif attr_mode == 'content' and isinstance(absolute_url, str) and not absolute_url.lower().endswith('.pdf'):
                                        content_start = time.monotonic()
                                        # ページテキスト取得 (get_page_inner_textを使用, タイムアウトはアクション全体時間)
                                        success, content_or_error = await get_page_inner_text(current_context, absolute_url, action_wait_time)
                                        scraped_text = content_or_error
                                        content_elapsed = (time.monotonic() - content_start) * 1000
                                        logger.info(f"  [{index+1}/{num_found}] Content取得試行完了 ({content_elapsed:.0f}ms) URL: {absolute_url} Success: {success}")

                                    logger.debug(f"  [{index+1}/{num_found}] Processing finished (Semaphore released). URL: {absolute_url}")
                                    return absolute_url, pdf_text, scraped_text

                                except PlaywrightTimeoutError:
                                    logger.warning(f"  [{index+1}/{num_found}] href属性取得タイムアウト ({href_timeout}ms)。")
                                    return f"Error: Timeout getting href", None, None
                                except Exception as e:
                                    logger.warning(f"  [{index+1}/{num_found}] href/コンテンツ取得中に予期せぬエラー: {type(e).__name__} - {e}", exc_info=True)
                                    return f"Error: {type(e).__name__} - {e}", None, None
                            # 'async with sem:' を抜けるとセマフォは自動的に解放される

                        # --- 見つかった全要素に対して並行処理 (タスク作成時にセマフォを渡す) ---
                        process_tasks = [
                            process_single_element_for_href_content(loc, idx, current_base_url, attribute_name.lower(), semaphore)
                            for idx, (loc, _) in enumerate(found_elements_list)
                        ]
                        # asyncio.gather は全てのタスクが完了するのを待つ
                        results_tuples = await asyncio.gather(*process_tasks)

                        # 結果をリストに格納
                        for abs_url, pdf_content, scraped_content in results_tuples:
                            url_list_for_file.append(abs_url)
                            pdf_texts_list_for_file.append(pdf_content)
                            scraped_texts_list_for_file.append(scraped_content)

                        logger.info(f"全 {num_found} 要素の href/コンテンツ処理が完了しました。")

                        # 結果を action_result_details に格納
                        action_result_details["attribute"] = attribute_name
                        action_result_details["url_list"] = url_list_for_file # 常にURLリストを含める
                        if attribute_name.lower() == 'pdf':
                             action_result_details["pdf_texts"] = pdf_texts_list_for_file
                        if attribute_name.lower() == 'content':
                             action_result_details["scraped_texts"] = scraped_texts_list_for_file
                        # hrefモードの場合は url_list が主要な結果

                    else: # href, pdf, content 以外の通常の属性取得
                        logger.info(f"指定された属性 '{attribute_name}' を取得します...")
                        # 属性値を取得する内部関数
                        async def get_single_attr(locator: Locator, attr_name: str, index: int) -> Optional[str]:
                            try:
                                attr_timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)
                                return await locator.get_attribute(attr_name, timeout=attr_timeout)
                            except PlaywrightTimeoutError:
                                logger.warning(f"  [{index+1}/{num_found}] 属性 '{attr_name}' 取得タイムアウト ({attr_timeout}ms)。")
                                return f"Error: Timeout getting attribute '{attr_name}'"
                            except Exception as e:
                                logger.warning(f"  [{index+1}/{num_found}] 属性 '{attr_name}' 取得中にエラー: {type(e).__name__}")
                                return f"Error: {type(e).__name__} getting attribute '{attr_name}'"

                        # 並行処理で属性を取得
                        attr_tasks = [
                            get_single_attr(loc, attribute_name, idx)
                            for idx, (loc, _) in enumerate(found_elements_list)
                        ]
                        generic_attribute_list_for_file = await asyncio.gather(*attr_tasks)

                        action_result_details.update({"attribute": attribute_name, "attribute_list": generic_attribute_list_for_file})
                        logger.info(f"取得した属性値リスト ({len(generic_attribute_list_for_file)}件)")

                # 最後に結果を追加
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})


            elif action == "get_all_text_contents":
                if not selector: raise ValueError("Action 'get_all_text_contents' requires 'selector'.")
                text_list: List[Optional[str]] = []
                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、テキスト取得をスキップします。")
                else:
                    num_found = len(found_elements_list)
                    logger.info(f"動的探索で見つかった {num_found} 個の要素から textContent を取得します。")
                    # textContent を取得する内部関数
                    async def get_single_text(locator: Locator, index: int) -> Optional[str]:
                        try:
                            text_timeout = max(500, action_wait_time // num_found if num_found > 5 else action_wait_time // 3)
                            text = await locator.text_content(timeout=text_timeout)
                            return text.strip() if text else "" # 前後空白除去
                        except PlaywrightTimeoutError:
                             logger.warning(f"  [{index+1}/{num_found}] textContent取得タイムアウト ({text_timeout}ms)。")
                             return "Error: Timeout getting textContent"
                        except Exception as e:
                            logger.warning(f"  [{index+1}/{num_found}] textContent 取得中にエラー: {type(e).__name__}")
                            return f"Error: {type(e).__name__} getting textContent"

                    # 並行処理でテキストを取得
                    get_text_tasks = [
                        get_single_text(loc, idx) for idx, (loc, _) in enumerate(found_elements_list)
                    ]
                    text_list = await asyncio.gather(*get_text_tasks)
                    logger.info(f"取得したテキストリスト ({len(text_list)}件)")

                action_result_details["text_list"] = text_list
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "wait_visible":
                # 要素探索自体が required_state='visible' で行われているため、
                # ここに到達した時点で要素は可視のはず。ログのみ。
                if not element: raise ValueError("Wait visible action requires an element.")
                logger.info("要素が表示されていることを確認しました (動的探索時に確認済み)。")
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "select_option":
                  if not element: raise ValueError("Select option action requires an element.")
                  if option_type not in ['value', 'index', 'label'] or option_value is None:
                       raise ValueError("Invalid 'option_type' or 'option_value' for select_option action.")
                  logger.info(f"ドロップダウンを選択します (Type: {option_type}, Value: '{option_value}')...")
                  # select_option は内部で要素が選択可能になるのを待つ
                  if option_type == 'value':
                      await element.select_option(value=str(option_value), timeout=action_wait_time)
                  elif option_type == 'index':
                      try: index_val = int(option_value)
                      except (ValueError, TypeError): raise ValueError("Option type 'index' requires an integer value.")
                      await element.select_option(index=index_val, timeout=action_wait_time)
                  elif option_type == 'label':
                      await element.select_option(label=str(option_value), timeout=action_wait_time)
                  logger.info("ドロップダウンの選択が成功しました。")
                  action_result_details.update({"option_type": option_type, "option_value": option_value})
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "scroll_to_element":
                   if not element: raise ValueError("Scroll action requires an element.")
                   logger.info("要素が表示されるまでスクロールします...")
                   # scroll_into_view_if_needed は要素がビューポートに入るようにスクロールする
                   await element.scroll_into_view_if_needed(timeout=action_wait_time)
                   await asyncio.sleep(0.3) # スクロール後の安定待ち
                   logger.info("要素へのスクロールが成功しました。")
                   results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "screenshot":
                  # ファイル名の決定 (valueがあればそれ、なければデフォルト名)
                  filename_base = str(value).strip() if value else f"screenshot_step{step_num}"
                  # 拡張子がなければ .png を追加
                  filename = f"{filename_base}.png" if not filename_base.lower().endswith(('.png', '.jpg', '.jpeg')) else filename_base
                  screenshot_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, filename)
                  # ディレクトリが存在しない場合は作成
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  logger.info(f"スクリーンショットを '{screenshot_path}' に保存します...")
                  if element: # 要素が指定されていれば要素のスクリーンショット
                       logger.info("要素のスクリーンショットを取得します...")
                       await element.screenshot(path=screenshot_path, timeout=action_wait_time)
                       logger.info("要素のスクリーンショットを保存しました。")
                  else: # 要素が指定されていなければページ全体
                       logger.info("ページ全体のスクリーンショットを取得します...")
                       # ページ全体は時間がかかる可能性があるのでタイムアウトを少し長くする
                       await root_page.screenshot(path=screenshot_path, full_page=True, timeout=action_wait_time*2)
                       logger.info("ページ全体のスクリーンショットを保存しました。")
                  action_result_details["filename"] = screenshot_path # 結果にファイルパスを含める
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            else:
                  known_actions = [
                      "click", "input", "hover", "get_inner_text", "get_text_content",
                      "get_inner_html", "get_attribute", "get_all_attributes", "get_all_text_contents",
                      "wait_visible", "select_option", "screenshot", "scroll_page_to_bottom",
                      "scroll_to_element", "wait_page_load", "sleep", "switch_to_iframe",
                      "switch_to_parent_frame"
                  ]
                  if action not in known_actions:
                     logger.warning(f"未定義または不明なアクション '{action}' です。このステップはスキップされます。")
                     results.append({"step": step_num, "status": "skipped", "action": action, "message": f"Undefined action: {action}"})

        # --- ステップごとのエラーハンドリング ---
        except (PlaywrightTimeoutError, PlaywrightError, ValueError, Exception) as e:
            error_message = f"ステップ {step_num} ({action}) の実行中にエラーが発生しました: {type(e).__name__} - {e}"
            logger.error(error_message, exc_info=True) # スタックトレース付きでログ出力
            error_screenshot_path = None
            # エラー発生時のスクリーンショットを試みる
            if root_page and not root_page.is_closed():
                 timestamp = time.strftime("%Y%m%d_%H%M%S")
                 error_ss_filename = f"error_step{step_num}_{timestamp}.png"
                 error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, error_ss_filename)
                 try:
                     os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                     # エラー時のスクショはタイムアウト短め、フルページで試す
                     await root_page.screenshot(path=error_ss_path, full_page=True, timeout=10000)
                     logger.info(f"エラー発生時のスクリーンショットを保存しました: {error_ss_path}")
                     error_screenshot_path = error_ss_path
                 except Exception as ss_e:
                     logger.error(f"エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
            elif root_page and root_page.is_closed():
                 # ページが閉じられている場合、エラーメッセージに追記
                 error_message += " (Note: Root page was closed during execution, possibly due to an unexpected navigation or crash)"
                 logger.warning("根本原因: ルートページが閉じられた可能性があります。")

            # エラー情報を結果リストに追加
            error_details = {
                "step": step_num,
                "status": "error",
                "action": action,
                "selector": selector, # エラー発生時のセレクターも記録
                "message": str(e), # エラーメッセージ本文
                "full_error": error_message, # より詳細なエラー情報 (スタックトレースはログのみ)
                "traceback": traceback.format_exc() # スタックトレースも結果に含める（デバッグ用）
            }
            if error_screenshot_path:
                error_details["error_screenshot"] = error_screenshot_path
            results.append(error_details)
            return False, results # Falseを返して処理中断

    # 全てのステップが正常に完了した場合
    return True, results


---


- フォルダ名: .
- ファイル名: playwright_finders.py
- 内容:
# --- ファイル: playwright_finders.py ---
"""
Playwrightを使った動的な要素探索機能を提供します。
"""
import asyncio
import logging
import time
from collections import deque
from playwright.async_api import (
    Page,
    FrameLocator,
    Locator,
    TimeoutError as PlaywrightTimeoutError,
)
from typing import List, Tuple, Optional, Union, Deque

import config

logger = logging.getLogger(__name__)

# --- 動的要素探索ヘルパー関数 (単一要素用) ---
async def find_element_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
    target_state: str = "attached"
) -> Tuple[Optional[Locator], Optional[Union[Page, FrameLocator]]]:
    """
    指定された起点からiframe内を含めて動的に単一の要素を探索します。
    見つかった要素のLocatorと、それが見つかったスコープ (Page or FrameLocator) を返します。
    タイムアウトするか見つからない場合は (None, None) を返します。
    """
    logger.info(f"動的探索(単一)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 状態='{target_state}', 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    element_wait_timeout = 2000  # 要素存在確認のタイムアウト（短め）
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT # iframe有効性確認のタイムアウト
    logger.debug(f"  要素待機タイムアウト: {element_wait_timeout}ms, フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            return None, None
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100: # 残り時間が少なすぎる場合は探索打ち切り
             logger.warning(f"動的探索(単一)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             return None, None

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(単一): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            element = current_scope.locator(target_selector).first
            # 要素の待機タイムアウトは、全体タイムアウトの残り時間と設定値の小さい方、かつ最低50msを確保
            effective_element_timeout = max(50, min(element_wait_timeout, int(remaining_time_ms - 50))) # 50msのマージン
            await element.wait_for(state=target_state, timeout=effective_element_timeout)
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.info(f"要素 '{target_selector}' をスコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で発見。({step_elapsed:.0f}ms)")
            return element, current_scope
        except PlaywrightTimeoutError:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では見つからず (タイムアウト {effective_element_timeout}ms)。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        # --- iframe探索 ---
        if current_depth < max_depth:
            # 再度時間チェック
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue # 時間切れなら次のキューへ
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue # 残り時間が少なすぎる場合

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible' # 可視iframeのみを対象
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    # ループ内でも時間チェック
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - iframeループ中")
                         break # このスコープのiframe探索を打ち切り
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break # 残り時間が少なすぎる場合

                    iframe_step_start_time = time.monotonic()
                    try:
                        # nth=i で i番目の可視iframeを特定
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        # iframeが有効かどうかのチェックタイムアウト
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        # iframe内のルート要素が存在するかで有効性を判断
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        # 訪問済みでなければキューに追加
                        scope_id = id(next_frame_locator) # FrameLocatorオブジェクトのIDで訪問管理
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(単一): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                        else:
                            logger.debug(f"        スキップ(単一): FrameLocator(nth={i}) は訪問済み")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.warning(f"動的探索(単一)完了: 要素 '{target_selector}' が最大深度 {max_depth} までで見つかりませんでした。({final_elapsed_time:.0f}ms)")
    return None, None

# --- 動的要素探索ヘルパー関数 (複数要素用) ---
async def find_all_elements_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
) -> List[Tuple[Locator, Union[Page, FrameLocator]]]:
    """
    指定された起点からiframe内を含めて動的に複数の要素を探索します。
    見つかったすべての要素のLocatorとそのスコープのタプルのリストを返します。
    タイムアウトした場合は、それまでに見つかった要素のリストを返します。
    """
    logger.info(f"動的探索(複数)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    found_elements: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT # iframe有効性確認のタイムアウト
    logger.debug(f"  フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            break # 時間切れの場合はループを抜ける
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100: # 残り時間が少なすぎる場合は探索打ち切り
             logger.warning(f"動的探索(複数)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             break

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(複数): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            # 要素が表示されているかに関わらず、スコープ内のすべての要素を取得
            # all() は要素がなくてもエラーにならない（空リストを返す）
            elements_in_scope = await current_scope.locator(target_selector).all()
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            if elements_in_scope:
                logger.info(f"  スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で {len(elements_in_scope)} 個の要素を発見。({step_elapsed:.0f}ms)")
                for elem in elements_in_scope:
                    found_elements.append((elem, current_scope))
            else:
                logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では要素が見つからず。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 複数探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        # --- iframe探索 ---
        if current_depth < max_depth:
            # 再度時間チェック
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue # 時間切れなら次のキューへ
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue # 残り時間が少なすぎる場合

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible' # 可視iframeのみを対象
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    # ループ内でも時間チェック
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - iframeループ中")
                         break # このスコープのiframe探索を打ち切り
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break # 残り時間が少なすぎる場合

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        # iframeが有効かどうかのチェックタイムアウト
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        # 訪問済みでなければキューに追加
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(複数): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                        else:
                             logger.debug(f"        スキップ(複数): FrameLocator(nth={i}) は訪問済み")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.info(f"動的探索(複数)完了: 合計 {len(found_elements)} 個の要素が見つかりました。({final_elapsed_time:.0f}ms)")
    return found_elements


---


- フォルダ名: .
- ファイル名: playwright_handler-bup.py
- 内容:
# --- ファイル: playwright_handler.py ---
"""
Playwrightを使ったブラウザ操作とアクション実行のコアロジック。
"""
import asyncio
import logging
import os
import time
import pprint
import traceback
import warnings
from collections import deque
from playwright.async_api import (
    async_playwright,
    Page,
    Frame,
    Locator,
    FrameLocator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
    APIRequestContext
)
from playwright_stealth import stealth_async
from typing import List, Tuple, Optional, Union, Any, Deque, Dict
from urllib.parse import urljoin

import config
import utils

logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", category=ResourceWarning, message="unclosed transport")


# --- 動的要素探索ヘルパー関数 (単一要素用 - 変更なし) ---
async def find_element_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
    target_state: str = "attached"
) -> Tuple[Optional[Locator], Optional[Union[Page, FrameLocator]]]:
    logger.info(f"動的探索(単一)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 状態='{target_state}', 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    element_wait_timeout = 2000
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT
    logger.debug(f"  要素待機タイムアウト: {element_wait_timeout}ms, フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            return None, None
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100:
             logger.warning(f"動的探索(単一)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             return None, None

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(単一): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            element = current_scope.locator(target_selector).first
            effective_element_timeout = max(50, min(element_wait_timeout, int(remaining_time_ms - 50)))
            await element.wait_for(state=target_state, timeout=effective_element_timeout)
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.info(f"要素 '{target_selector}' をスコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で発見。({step_elapsed:.0f}ms)")
            return element, current_scope
        except PlaywrightTimeoutError:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では見つからず (タイムアウト {effective_element_timeout}ms)。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        if current_depth < max_depth:
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                iframe_base_selector = 'iframe:visible'
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(単一)タイムアウト ({timeout}ms) - iframeループ中")
                         break
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(単一): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.warning(f"動的探索(単一)完了: 要素 '{target_selector}' が最大深度 {max_depth} までで見つかりませんでした。({final_elapsed_time:.0f}ms)")
    return None, None

# --- 動的要素探索ヘルパー関数 (複数要素用 - 変更なし) ---
async def find_all_elements_dynamically(
    base_locator: Union[Page, FrameLocator],
    target_selector: str,
    max_depth: int = config.DYNAMIC_SEARCH_MAX_DEPTH,
    timeout: int = config.DEFAULT_ACTION_TIMEOUT,
) -> List[Tuple[Locator, Union[Page, FrameLocator]]]:
    logger.info(f"動的探索(複数)開始: 起点={type(base_locator).__name__}, セレクター='{target_selector}', 最大深度={max_depth}, 全体タイムアウト={timeout}ms")
    start_time = time.monotonic()
    found_elements: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
    queue: Deque[Tuple[Union[Page, FrameLocator], int]] = deque([(base_locator, 0)])
    visited_scope_ids = {id(base_locator)}
    iframe_check_timeout = config.IFRAME_LOCATOR_TIMEOUT
    logger.debug(f"  フレーム確認タイムアウト: {iframe_check_timeout}ms")

    while queue:
        current_monotonic_time = time.monotonic()
        elapsed_time_ms = (current_monotonic_time - start_time) * 1000
        if elapsed_time_ms >= timeout:
            logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - 経過時間: {elapsed_time_ms:.0f}ms")
            break
        remaining_time_ms = timeout - elapsed_time_ms
        if remaining_time_ms < 100:
             logger.warning(f"動的探索(複数)の残り時間がわずかなため ({remaining_time_ms:.0f}ms)、探索を打ち切ります。")
             break

        current_scope, current_depth = queue.popleft()
        scope_type_name = type(current_scope).__name__
        scope_identifier = f" ({repr(current_scope)})" if isinstance(current_scope, FrameLocator) else ""
        logger.debug(f"  探索中(複数): スコープ={scope_type_name}{scope_identifier}, 深度={current_depth}, 残り時間: {remaining_time_ms:.0f}ms")

        step_start_time = time.monotonic()
        try:
            # 要素が表示されているかに関わらず全て取得する
            elements_in_scope = await current_scope.locator(target_selector).all()
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            if elements_in_scope:
                logger.info(f"  スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) で {len(elements_in_scope)} 個の要素を発見。({step_elapsed:.0f}ms)")
                for elem in elements_in_scope:
                    found_elements.append((elem, current_scope))
            else:
                logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' 直下では要素が見つからず。({step_elapsed:.0f}ms)")
        except Exception as e:
            step_elapsed = (time.monotonic() - step_start_time) * 1000
            logger.warning(f"    スコープ '{scope_type_name}{scope_identifier}' での要素 '{target_selector}' 複数探索中にエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)")

        if current_depth < max_depth:
            current_monotonic_time = time.monotonic()
            elapsed_time_ms = (current_monotonic_time - start_time) * 1000
            if elapsed_time_ms >= timeout: continue
            remaining_time_ms = timeout - elapsed_time_ms
            if remaining_time_ms < 100: continue

            step_start_time = time.monotonic()
            logger.debug(f"    スコープ '{scope_type_name}{scope_identifier}' (深度 {current_depth}) 内の可視iframeを探索...")
            try:
                # iframe自体は可視である必要がある
                iframe_base_selector = 'iframe:visible'
                visible_iframe_locators = current_scope.locator(iframe_base_selector)
                count = await visible_iframe_locators.count()
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                if count > 0: logger.debug(f"      発見した可視iframe候補数: {count} ({step_elapsed:.0f}ms)")

                for i in range(count):
                    current_monotonic_time_inner = time.monotonic()
                    elapsed_time_ms_inner = (current_monotonic_time_inner - start_time) * 1000
                    if elapsed_time_ms_inner >= timeout:
                         logger.warning(f"動的探索(複数)タイムアウト ({timeout}ms) - iframeループ中")
                         break
                    remaining_time_ms_inner = timeout - elapsed_time_ms_inner
                    if remaining_time_ms_inner < 50: break

                    iframe_step_start_time = time.monotonic()
                    try:
                        nth_iframe_selector = f"{iframe_base_selector} >> nth={i}"
                        next_frame_locator = current_scope.frame_locator(nth_iframe_selector)
                        effective_iframe_check_timeout = max(50, min(iframe_check_timeout, int(remaining_time_ms_inner - 50)))
                        # iframe内のルート要素が存在するかどうかを確認
                        await next_frame_locator.locator(':root').wait_for(state='attached', timeout=effective_iframe_check_timeout)
                        scope_id = id(next_frame_locator)
                        if scope_id not in visited_scope_ids:
                            visited_scope_ids.add(scope_id)
                            queue.append((next_frame_locator, current_depth + 1))
                            iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                            logger.debug(f"        キューに追加(複数): スコープ=FrameLocator(nth={i}), 新深度={current_depth + 1} ({iframe_step_elapsed:.0f}ms)")
                    except PlaywrightTimeoutError:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.debug(f"      iframe {i} ('{nth_iframe_selector}') は有効でないかタイムアウト ({effective_iframe_check_timeout}ms)。({iframe_step_elapsed:.0f}ms)")
                    except Exception as e:
                         iframe_step_elapsed = (time.monotonic() - iframe_step_start_time) * 1000
                         logger.warning(f"      iframe {i} ('{nth_iframe_selector}') の処理中にエラー: {type(e).__name__} - {e} ({iframe_step_elapsed:.0f}ms)")
            except Exception as e:
                step_elapsed = (time.monotonic() - step_start_time) * 1000
                logger.error(f"    スコープ '{scope_type_name}{scope_identifier}' でのiframe探索中に予期せぬエラー: {type(e).__name__} - {e} ({step_elapsed:.0f}ms)", exc_info=True)

    final_elapsed_time = (time.monotonic() - start_time) * 1000
    logger.info(f"動的探索(複数)完了: 合計 {len(found_elements)} 個の要素が見つかりました。({final_elapsed_time:.0f}ms)")
    return found_elements


# --- ページ内テキスト取得ヘルパー関数 (変更なし) ---
async def get_page_inner_text(context: BrowserContext, url: str, timeout: int) -> Tuple[bool, Optional[str]]:
    """
    指定されたURLにアクセスし、ページのinnerTextを取得する。
    成功したかどうかとテキスト内容（またはエラーメッセージ）のタプルを返す。
    """
    page = None
    start_time = time.monotonic()
    # ページ遷移自体のタイムアウトも考慮
    page_access_timeout = max(int(timeout * 0.8), 15000) # アクションタイムアウトの80%か15秒の大きい方
    logger.info(f"URLからテキスト取得開始: {url} (タイムアウト: {page_access_timeout}ms)")
    try:
        page = await context.new_page()
        # ナビゲーションタイムアウトを設定
        nav_timeout = max(int(page_access_timeout * 0.9), 10000)
        logger.debug(f"  Navigating to {url} with timeout {nav_timeout}ms")
        await page.goto(url, wait_until="load", timeout=nav_timeout)
        logger.debug(f"  Navigation to {url} successful.")

        # <body>要素が表示されるまで待機
        remaining_time_for_body = page_access_timeout - (time.monotonic() - start_time) * 1000
        body_wait_timeout = max(int(remaining_time_for_body * 0.5), 2000)
        if remaining_time_for_body <= 0:
            raise PlaywrightTimeoutError(f"No time left to wait for body after navigation to {url}")
        logger.debug(f"  Waiting for body element with timeout {body_wait_timeout}ms")
        body_locator = page.locator('body')
        await body_locator.wait_for(state='visible', timeout=body_wait_timeout)
        logger.debug("  Body element is visible.")

        # innerText取得タイムアウト
        remaining_time_for_text = page_access_timeout - (time.monotonic() - start_time) * 1000
        text_timeout = max(int(remaining_time_for_text * 0.8), 1000)
        if remaining_time_for_text <= 0:
            raise PlaywrightTimeoutError(f"No time left to get innerText from {url}")

        logger.debug(f"  Getting innerText with timeout {text_timeout}ms")
        text = await body_locator.inner_text(timeout=text_timeout)
        elapsed = (time.monotonic() - start_time) * 1000
        logger.info(f"テキスト取得成功 ({url})。文字数: {len(text)} ({elapsed:.0f}ms)")
        # 取得したテキストを返す
        return True, text.strip() if text else ""
    except PlaywrightTimeoutError as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Timeout during processing {url} ({elapsed:.0f}ms). {e}"
        logger.warning(error_msg)
        # エラーメッセージを返す
        return False, error_msg
    except Exception as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Failed to get text from {url} ({elapsed:.0f}ms) - {type(e).__name__}: {e}"
        logger.error(error_msg, exc_info=False)
        logger.debug(f"Detailed error getting text from {url}:", exc_info=True)
        # エラーメッセージを返す
        return False, error_msg
    finally:
        if page and not page.is_closed():
            try:
                await page.close()
                logger.debug(f"一時ページ ({url}) を閉じました。")
            except Exception as close_e:
                logger.warning(f"一時ページ ({url}) クローズ中にエラー (無視): {close_e}")


# --- Playwright アクション実行コア (変更なし) ---
async def execute_actions_async(initial_page: Page, actions: List[dict], api_request_context: APIRequestContext, default_timeout: int) -> Tuple[bool, List[dict]]:
    """Playwright アクションを非同期で実行する。iframe探索を動的に行う。"""
    results: List[dict] = []
    current_target: Union[Page, FrameLocator] = initial_page
    root_page: Page = initial_page
    current_context: BrowserContext = root_page.context
    iframe_stack: List[Union[Page, FrameLocator]] = []

    for i, step_data in enumerate(actions):
        step_num = i + 1
        action = step_data.get("action", "").lower()
        selector = step_data.get("selector")
        iframe_selector_input = step_data.get("iframe_selector")
        value = step_data.get("value")
        attribute_name = step_data.get("attribute_name")
        option_type = step_data.get("option_type")
        option_value = step_data.get("option_value")
        # アクション固有のタイムアウト > JSON全体のデフォルト > configのデフォルト
        action_wait_time = step_data.get("wait_time_ms", default_timeout)

        logger.info(f"--- ステップ {step_num}/{len(actions)}: Action='{action}' ---")
        step_info = {"selector": selector, "value": value, "iframe(指定)": iframe_selector_input,
                     "option_type": option_type, "option_value": option_value, "attribute_name": attribute_name}
        step_info_str = ", ".join([f"{k}='{v}'" for k, v in step_info.items() if v is not None])
        logger.info(f"詳細: {step_info_str} (timeout: {action_wait_time}ms)")

        try:
            if root_page.is_closed():
                raise PlaywrightError("Root page is closed.")
            current_base_url = root_page.url # 現在のページのベースURLを取得
            root_page_title = await root_page.title()
            current_target_type = type(current_target).__name__
            logger.info(f"現在のルートページ: URL='{current_base_url}', Title='{root_page_title}'")
            logger.info(f"現在の探索スコープ: {current_target_type}")
        except Exception as e:
            logger.error(f"現在のターゲット情報取得中にエラー: {e}", exc_info=True)
            results.append({"step": step_num, "status": "error", "action": action, "message": f"Failed to get target info: {e}"})
            return False, results

        try:
            # --- Iframe/Parent Frame 切替 (変更なし) ---
            if action == "switch_to_iframe":
                if not iframe_selector_input:
                    raise ValueError("Action 'switch_to_iframe' requires 'iframe_selector'")
                logger.info(f"[ユーザー指定] Iframe '{iframe_selector_input}' に切り替えます...")
                target_frame_locator: Optional[FrameLocator] = None
                try:
                    # 現在のターゲットから iframe を探す
                    target_frame_locator = current_target.frame_locator(iframe_selector_input)
                    # iframeが存在し、アクセス可能か確認 (ルート要素の存在確認)
                    await target_frame_locator.locator(':root').wait_for(state='attached', timeout=action_wait_time)
                except PlaywrightTimeoutError:
                    # logger.debug(f"現在のスコープ({type(current_target).__name__})に指定iframeなし。ルートページから再検索...")
                    # try:
                    #     target_frame_locator = root_page.frame_locator(iframe_selector_input)
                    #     await target_frame_locator.locator(':root').wait_for(state='attached', timeout=max(1000, action_wait_time // 2))
                    # except PlaywrightTimeoutError:
                        raise PlaywrightTimeoutError(f"指定されたiframe '{iframe_selector_input}' が見つからないか、タイムアウト({action_wait_time}ms)しました。")
                except Exception as e:
                    raise PlaywrightError(f"Iframe '{iframe_selector_input}' への切り替え中に予期せぬエラーが発生しました: {e}")

                # 切り替え成功
                if id(current_target) not in [id(s) for s in iframe_stack]: # 重複を避ける
                    iframe_stack.append(current_target) # 現在のターゲットをスタックに追加
                current_target = target_frame_locator # ターゲットを新しい FrameLocator に更新
                logger.info("FrameLocator への切り替え成功。")
                results.append({"step": step_num, "status": "success", "action": action, "selector": iframe_selector_input})
                continue # 次のステップへ

            elif action == "switch_to_parent_frame":
                if not iframe_stack:
                    logger.warning("既にトップレベルフレームか、iframeスタックが空です。")
                    # FrameLocatorの場合のみルートページに戻す（安全策）
                    if isinstance(current_target, FrameLocator):
                        logger.info("現在のターゲットがFrameLocatorのため、ルートページに戻します。")
                        current_target = root_page
                    results.append({"step": step_num, "status": "warning", "action": action, "message": "Already at top-level or stack empty."})
                else:
                    logger.info("[ユーザー指定] 親ターゲットに戻ります...")
                    current_target = iframe_stack.pop() # スタックから親ターゲットを取り出す
                    target_type = type(current_target).__name__
                    logger.info(f"親ターゲットへの切り替え成功。現在の探索スコープ: {target_type}")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- ページ全体操作 (変更なし) ---
            if action in ["wait_page_load", "sleep", "scroll_page_to_bottom"]:
                if action == "wait_page_load":
                    logger.info("ページの読み込み完了 (load) を待ちます...")
                    await root_page.wait_for_load_state("load", timeout=action_wait_time)
                    logger.info("ページの読み込みが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                elif action == "sleep":
                    try:
                        seconds = float(value) if value is not None else 1.0
                        if seconds < 0: raise ValueError("Sleep time cannot be negative.")
                    except (TypeError, ValueError):
                        raise ValueError("Invalid value for sleep action. Must be a non-negative number (seconds).")
                    logger.info(f"{seconds:.1f} 秒待機します...")
                    await asyncio.sleep(seconds)
                    results.append({"step": step_num, "status": "success", "action": action, "duration_sec": seconds})
                elif action == "scroll_page_to_bottom":
                    logger.info("ページ最下部へスクロールします...")
                    await root_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                    await asyncio.sleep(0.5) # スクロール後の描画待ち
                    logger.info("ページ最下部へのスクロールが完了しました。")
                    results.append({"step": step_num, "status": "success", "action": action})
                continue # 次のステップへ


            # --- 要素操作のための準備 ---
            element: Optional[Locator] = None
            found_elements_list: List[Tuple[Locator, Union[Page, FrameLocator]]] = []
            found_scope: Optional[Union[Page, FrameLocator]] = None

            # アクションが単一要素を必要とするか、複数要素を対象とするか
            single_element_required_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "wait_visible", "select_option", "scroll_to_element"]
            multiple_elements_actions = ["get_all_attributes", "get_all_text_contents"]
            is_single_element_required = action in single_element_required_actions
            is_multiple_elements_action = action in multiple_elements_actions
            # スクリーンショットは要素指定がある場合のみ要素探索が必要
            is_screenshot_element = action == "screenshot" and selector is not None

            if is_single_element_required or is_multiple_elements_action or is_screenshot_element:
                if not selector:
                    raise ValueError(f"Action '{action}' requires a 'selector'.")

                # --- 要素探索 ---
                if is_single_element_required or is_screenshot_element:
                    # 探索する要素の状態を決定
                    required_state = 'visible' if action in ['click', 'hover', 'screenshot', 'select_option', 'input', 'get_inner_text', 'wait_visible', 'scroll_to_element'] else 'attached'
                    element, found_scope = await find_element_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time, target_state=required_state
                    )
                    if not element or not found_scope:
                        error_msg = f"要素 '{selector}' (状態: {required_state}) が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。"
                        logger.error(error_msg)
                        # エラー結果を追加して終了
                        results.append({"step": step_num, "status": "error", "action": action, "selector": selector, "message": error_msg})
                        return False, results # Falseを返して処理中断

                    # 要素が見つかったスコープが現在のスコープと異なる場合、ターゲットを更新
                    if id(found_scope) != id(current_target):
                        logger.info(f"探索スコープを要素が見つかった '{type(found_scope).__name__}' に更新します。")
                        if id(current_target) not in [id(s) for s in iframe_stack]:
                            iframe_stack.append(current_target) # 元のターゲットをスタックに追加
                        current_target = found_scope
                    logger.info(f"最終的な単一操作対象スコープ: {type(current_target).__name__}")

                elif is_multiple_elements_action:
                    found_elements_list = await find_all_elements_dynamically(
                        current_target, selector, max_depth=config.DYNAMIC_SEARCH_MAX_DEPTH, timeout=action_wait_time
                    )
                    if not found_elements_list:
                        # 要素が見つからなくてもエラーとはせず、警告ログのみ（後続処理で空リストとして扱う）
                        logger.warning(f"要素 '{selector}' が現在のスコープおよび探索可能なiframe (深さ{config.DYNAMIC_SEARCH_MAX_DEPTH}まで) 内で見つかりませんでした。")
                    # 複数要素の場合、見つかった各要素のスコープは異なる可能性があるため、current_target は更新しない


            # --- 各アクション実行 ---
            action_result_details = {"selector": selector} if selector else {} # 結果にセレクター情報を含める

            if action == "click":
                if not element: raise ValueError("Click action requires an element, but it was not found or assigned.")
                logger.info("要素をクリックします...")
                context = root_page.context # クリックによるページ遷移を検知するためルートページのコンテキストを使用
                new_page: Optional[Page] = None
                try:
                    # 新しいページが開く可能性を考慮して待機
                    async with context.expect_page(timeout=config.NEW_PAGE_EVENT_TIMEOUT) as new_page_info:
                        await element.click(timeout=action_wait_time)
                    # タイムアウト内に新しいページが開いた場合
                    new_page = await new_page_info.value
                    new_page_url = new_page.url
                    logger.info(f"新しいページが開きました: URL={new_page_url}")
                    try:
                        # 新しいページのロード完了を待つ
                        await new_page.wait_for_load_state("load", timeout=action_wait_time)
                    except PlaywrightTimeoutError:
                        logger.warning(f"新しいページのロード待機がタイムアウトしました ({action_wait_time}ms)。")
                    # 操作対象を新しいページに切り替え、iframeスタックをクリア
                    root_page = new_page
                    current_target = new_page
                    current_context = new_page.context
                    iframe_stack.clear()
                    logger.info("スコープを新しいページにリセットしました。")
                    action_result_details.update({"new_page_opened": True, "new_page_url": new_page_url})
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})
                except PlaywrightTimeoutError:
                    # expect_pageがタイムアウトした場合 (新しいページが開かなかった場合)
                    logger.info(f"クリックは完了しましたが、{config.NEW_PAGE_EVENT_TIMEOUT}ms 以内に新しいページは開きませんでした。")
                    action_result_details["new_page_opened"] = False
                    results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "input":
                 if not element: raise ValueError("Input action requires an element.")
                 if value is None: raise ValueError("Input action requires 'value'.")
                 logger.info(f"要素に '{str(value)[:50]}{'...' if len(str(value)) > 50 else ''}' を入力します...") # 長い値は省略してログ表示
                 await element.fill(str(value), timeout=action_wait_time)
                 logger.info("入力が成功しました。")
                 action_result_details["value"] = value # 結果には元の値を保持
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "hover":
                 if not element: raise ValueError("Hover action requires an element.")
                 logger.info("要素にマウスオーバーします...")
                 await element.hover(timeout=action_wait_time)
                 logger.info("ホバーが成功しました。")
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_text":
                 if not element: raise ValueError("Get text action requires an element.")
                 logger.info("要素の innerText を取得します...")
                 text = await element.inner_text(timeout=action_wait_time)
                 logger.info(f"取得テキスト(innerText): '{text[:100]}{'...' if len(text) > 100 else ''}'") # 長いテキストは省略
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_text_content":
                 if not element: raise ValueError("Get text action requires an element.")
                 logger.info("要素の textContent を取得します...")
                 text = await element.text_content(timeout=action_wait_time)
                 text = text.strip() if text else "" # 前後の空白を除去
                 logger.info(f"取得テキスト(textContent): '{text[:100]}{'...' if len(text) > 100 else ''}'")
                 action_result_details["text"] = text
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_inner_html":
                 if not element: raise ValueError("Get HTML action requires an element.")
                 logger.info("要素の innerHTML を取得します...")
                 html_content = await element.inner_html(timeout=action_wait_time)
                 logger.info(f"取得HTML(innerHTML):\n{html_content[:500]}{'...' if len(html_content) > 500 else ''}") # 先頭のみ表示
                 action_result_details["html"] = html_content
                 results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_attribute":
                if not element: raise ValueError("Get attribute action requires an element.")
                if not attribute_name: raise ValueError("Action 'get_attribute' requires 'attribute_name'.")
                logger.info(f"要素の属性 '{attribute_name}' を取得します...")
                attr_value = await element.get_attribute(attribute_name, timeout=action_wait_time)
                pdf_text_content = None
                processed_url = attr_value # 変換後のURLも保持

                # href属性の場合、絶対URLに変換し、PDFなら内容を取得
                if attribute_name.lower() == 'href' and attr_value is not None:
                    original_url = attr_value
                    try:
                        absolute_url = urljoin(current_base_url, original_url) # 相対URLを絶対URLに
                        if original_url != absolute_url:
                            logger.info(f"  href属性値を絶対URLに変換: '{original_url}' -> '{absolute_url}'")
                        processed_url = absolute_url # 変換後のURLを保持

                        # PDFかどうかを判定して処理
                        if isinstance(absolute_url, str) and absolute_url.lower().endswith('.pdf'):
                            logger.info(f"  リンク先がPDFファイルです。ダウンロードとテキスト抽出を試みます: {absolute_url}")
                            pdf_bytes = await utils.download_pdf_async(api_request_context, absolute_url)
                            if pdf_bytes:
                                # 同期関数を非同期で実行
                                pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                logger.info(f"  PDFテキスト抽出完了 (先頭200文字): {pdf_text_content[:200] if pdf_text_content else 'None'}...")
                            else:
                                pdf_text_content = "Error: PDF download failed or returned no data."
                                logger.error(f"  PDFダウンロード失敗: {absolute_url}")
                        else:
                             logger.debug(f"  リンク先はPDFではありません ({absolute_url})。")
                    except Exception as url_e:
                        logger.error(f"  URL処理またはPDF処理中にエラーが発生しました (URL: '{original_url}'): {url_e}")
                        pdf_text_content = f"Error processing URL or PDF: {url_e}"

                logger.info(f"取得した属性値 ({attribute_name}): '{processed_url}'") # 変換後のURLを表示
                action_result_details.update({"attribute": attribute_name, "value": processed_url}) # 結果には処理後のURLを保存
                if pdf_text_content is not None:
                    action_result_details["pdf_text"] = pdf_text_content # PDFテキストも結果に含める
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})


            # --- get_all_attributes (変更なし) ---
            elif action == "get_all_attributes":
                if not selector: raise ValueError("Action 'get_all_attributes' requires 'selector'.")
                if not attribute_name: raise ValueError("Action 'get_all_attributes' requires 'attribute_name'.")

                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、属性取得をスキップします。")
                    action_result_details["attribute_list"] = [] # 空リストを結果として設定
                else:
                    logger.info(f"動的探索で見つかった {len(found_elements_list)} 個の要素から属性 '{attribute_name}' を取得します。")

                    # --- 結果格納用のリスト ---
                    url_list_for_file: List[Optional[str]] = []       # 最終的な結果ファイル用 (絶対URL)
                    pdf_texts_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用
                    scraped_texts_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用
                    generic_attribute_list_for_file: List[Optional[str]] = [] # 最終的な結果ファイル用

                    # --- href属性を取得する内部関数 ---
                    async def get_single_href(locator: Locator, index: int) -> Optional[str]:
                         try:
                             href = await locator.get_attribute("href", timeout=max(500, action_wait_time // 5)) # 個々のタイムアウトは短めに
                             return href
                         except Exception as e:
                             logger.warning(f"  要素 {index+1} の href 属性取得中にエラー: {type(e).__name__}")
                             return None

                    # --- 属性名に応じて処理 ---
                    if attribute_name.lower() in ['href', 'pdf', 'content']:
                        logger.info("href属性を取得し、絶対URLに変換します...")
                        # まず全要素からhref属性(元URL)を取得
                        original_href_list: List[Optional[str]] = []
                        for idx, (loc, _) in enumerate(found_elements_list):
                             original_href = await get_single_href(loc, idx)
                             original_href_list.append(original_href)

                        # 逐次処理のための準備
                        absolute_urls_processed: List[Optional[str]] = [None] * len(original_href_list)

                        logger.info(f"--- Processing {len(original_href_list)} URLs for '{attribute_name.lower()}' ---")
                        process_start_time = time.monotonic()

                        for idx, original_url in enumerate(original_href_list):
                            item_start_time = time.monotonic()
                            if original_url is None:
                                logger.info(f"[{idx+1}/{len(original_href_list)}] URL: None (Skipping)")
                                url_list_for_file.append(None)
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)
                                continue

                            abs_url: Optional[str] = None
                            try:
                                abs_url = urljoin(current_base_url, original_url)
                                logger.info(f"[{idx+1}/{len(original_href_list)}] URL: {abs_url} (Original: {original_url})")
                                absolute_urls_processed[idx] = abs_url # 処理済みURLを保持
                            except Exception as url_e:
                                logger.error(f"  [{idx+1}] URL変換エラー ({original_url}): {url_e}")
                                url_list_for_file.append(f"Error converting URL: {original_url}")
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)
                                continue

                            # --- pdf モードの場合 ---
                            if attribute_name.lower() == 'pdf':
                                if isinstance(abs_url, str) and abs_url.lower().endswith('.pdf'):
                                    pdf_text_content = "Error: PDF download or extraction failed." # デフォルトエラーメッセージ
                                    try:
                                        pdf_bytes = await utils.download_pdf_async(api_request_context, abs_url)
                                        if pdf_bytes:
                                            pdf_text_content = await asyncio.to_thread(utils.extract_text_from_pdf_sync, pdf_bytes)
                                            logger.info(f"  [{idx+1}] PDF Text Extracted (Length: {len(pdf_text_content or '')})")
                                            logger.debug(f"    Text: {pdf_text_content[:200] if pdf_text_content else 'None'}...")
                                        else:
                                            pdf_text_content = "Error: PDF download failed or returned no data."
                                            logger.error(f"  [{idx+1}] PDF download failed.")
                                    except Exception as pdf_err:
                                        logger.error(f"  [{idx+1}] PDF processing error: {pdf_err}")
                                        pdf_text_content = f"Error: {pdf_err}"
                                    pdf_texts_list_for_file.append(pdf_text_content)
                                    # 他のリストはこのURLでは関係ないのでNoneを追加
                                    url_list_for_file.append(abs_url)
                                    scraped_texts_list_for_file.append(None)
                                else:
                                    logger.info(f"  [{idx+1}] Not a PDF link. Skipping PDF processing.")
                                    url_list_for_file.append(abs_url) # URLは記録
                                    pdf_texts_list_for_file.append(None) # PDFテキストはない
                                    scraped_texts_list_for_file.append(None)

                            # --- content モードの場合 ---
                            elif attribute_name.lower() == 'content':
                                if isinstance(abs_url, str) and not abs_url.lower().endswith('.pdf'):
                                    content_success, scraped_text_or_error = await get_page_inner_text(current_context, abs_url, action_wait_time)
                                    if content_success:
                                        logger.info(f"  [{idx+1}] Page Content Scraped (Length: {len(scraped_text_or_error or '')})")
                                        logger.debug(f"    Content: {scraped_text_or_error[:200] if scraped_text_or_error else ''}...")
                                        scraped_texts_list_for_file.append(scraped_text_or_error)
                                    else:
                                        logger.error(f"  [{idx+1}] Page Content Scraping Failed: {scraped_text_or_error}")
                                        scraped_texts_list_for_file.append(f"Error scraping content: {scraped_text_or_error}")
                                    # 他のリストはこのURLでは関係ないのでNoneを追加
                                    url_list_for_file.append(abs_url)
                                    pdf_texts_list_for_file.append(None)
                                else:
                                    logger.info(f"  [{idx+1}] Is PDF or invalid URL. Skipping content scraping.")
                                    url_list_for_file.append(abs_url) # URLは記録
                                    scraped_texts_list_for_file.append(None) # スクレイプテキストはない
                                    pdf_texts_list_for_file.append(None)

                            # --- href モードの場合 ---
                            elif attribute_name.lower() == 'href':
                                url_list_for_file.append(abs_url)
                                # 他のリストはこのモードでは関係ないのでNoneを追加
                                pdf_texts_list_for_file.append(None)
                                scraped_texts_list_for_file.append(None)

                            item_elapsed = (time.monotonic() - item_start_time) * 1000
                            logger.debug(f"  [{idx+1}] Item processing time: {item_elapsed:.0f}ms")

                        process_elapsed = (time.monotonic() - process_start_time) * 1000
                        logger.info(f"--- Finished processing {len(original_href_list)} URLs ({process_elapsed:.0f}ms) ---")

                        # 結果を action_result_details に格納
                        action_result_details["attribute"] = attribute_name # 元の要求属性名を記録
                        action_result_details["url_list"] = url_list_for_file # 常にURLリストを含める
                        if attribute_name.lower() == 'pdf':
                             action_result_details["pdf_texts"] = pdf_texts_list_for_file
                        elif attribute_name.lower() == 'content':
                             action_result_details["scraped_texts"] = scraped_texts_list_for_file
                        # hrefの場合は url_list のみが主要な結果

                    else: # href, pdf, content 以外の場合 (通常の属性取得)
                        logger.info(f"指定された属性 '{attribute_name}' を取得します...")
                        generic_attribute_list_for_file = [None] * len(found_elements_list)
                        # --- 属性値を取得する内部関数 ---
                        async def get_single_attr(locator: Locator, attr_name: str, index: int) -> Optional[str]:
                            try:
                                return await locator.get_attribute(attr_name, timeout=max(500, action_wait_time // 5))
                            except Exception as e:
                                logger.warning(f"  要素 {index+1} の属性 '{attr_name}' 取得中にエラー: {type(e).__name__}")
                                return None

                        # 逐次処理で属性を取得
                        for idx, (loc, _) in enumerate(found_elements_list):
                             attr_val = await get_single_attr(loc, attribute_name, idx)
                             logger.info(f"  [{idx+1}/{len(found_elements_list)}] Attribute '{attribute_name}': {attr_val}")
                             generic_attribute_list_for_file[idx] = attr_val

                        action_result_details.update({"attribute": attribute_name, "attribute_list": generic_attribute_list_for_file})
                        logger.info(f"取得した属性値リスト ({len(generic_attribute_list_for_file)}件)")
                        # pprint はログが冗長になるので logger.info で十分か

                # 最後に結果を追加
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "get_all_text_contents":
                 # ... (変更なし) ...
                if not selector: raise ValueError("Action 'get_all_text_contents' requires 'selector'.")
                text_list: List[Optional[str]] = []
                if not found_elements_list:
                    logger.warning(f"動的探索で要素 '{selector}' が見つからなかったため、テキスト取得をスキップします。")
                else:
                    logger.info(f"動的探索で見つかった {len(found_elements_list)} 個の要素から textContent を取得します。")
                    get_text_tasks = []
                    # --- textContent を取得する内部関数 ---
                    async def get_single_text(locator: Locator, index: int) -> Optional[str]:
                        try:
                            text = await locator.text_content(timeout=max(500, action_wait_time // 5))
                            return text.strip() if text else "" # 前後空白除去
                        except Exception as e:
                            logger.warning(f"  要素 {index+1} の textContent 取得中にエラー: {type(e).__name__}")
                            return None

                    for loc_index, (loc, _) in enumerate(found_elements_list):
                         get_text_tasks.append(get_single_text(loc, loc_index))

                    text_list = await asyncio.gather(*get_text_tasks)
                    logger.info(f"取得したテキストリスト ({len(text_list)}件)")

                action_result_details["text_list"] = text_list
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "wait_visible":
                 # ... (変更なし) ...
                if not element: raise ValueError("Wait visible action requires an element.")
                logger.info("要素が表示されるのを待ちます...")
                await element.wait_for(state='visible', timeout=action_wait_time)
                logger.info("要素が表示されていることを確認しました。")
                results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "select_option":
                 # ... (変更なし) ...
                  if not element: raise ValueError("Select option action requires an element.")
                  if option_type not in ['value', 'index', 'label'] or option_value is None:
                       raise ValueError("Invalid 'option_type' or 'option_value' for select_option action.")
                  logger.info(f"ドロップダウンを選択します (Type: {option_type}, Value: '{option_value}')...")
                  if option_type == 'value':
                      await element.select_option(value=str(option_value), timeout=action_wait_time)
                  elif option_type == 'index':
                      try: index_val = int(option_value)
                      except (ValueError, TypeError): raise ValueError("Option type 'index' requires an integer value.")
                      await element.select_option(index=index_val, timeout=action_wait_time)
                  elif option_type == 'label':
                      await element.select_option(label=str(option_value), timeout=action_wait_time)
                  logger.info("ドロップダウンの選択が成功しました。")
                  action_result_details.update({"option_type": option_type, "option_value": option_value})
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "scroll_to_element":
                 # ... (変更なし) ...
                   if not element: raise ValueError("Scroll action requires an element.")
                   logger.info("要素が表示されるまでスクロールします...")
                   await element.scroll_into_view_if_needed(timeout=action_wait_time)
                   await asyncio.sleep(0.3) # スクロール後の安定待ち
                   logger.info("要素へのスクロールが成功しました。")
                   results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            elif action == "screenshot":
                 # ... (変更なし) ...
                  # ファイル名の決定 (valueがあればそれ、なければデフォルト名)
                  filename_base = str(value) if value else f"screenshot_step{step_num}"
                  # 拡張子がなければ .png を追加
                  filename = f"{filename_base}.png" if not filename_base.lower().endswith(('.png', '.jpg', '.jpeg')) else filename_base
                  screenshot_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, filename)
                  # ディレクトリが存在しない場合は作成
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  logger.info(f"スクリーンショットを '{screenshot_path}' に保存します...")
                  if element: # 要素が指定されていれば要素のスクリーンショット
                       await element.screenshot(path=screenshot_path, timeout=action_wait_time)
                       logger.info("要素のスクリーンショットを保存しました。")
                  else: # 要素が指定されていなければページ全体
                       await root_page.screenshot(path=screenshot_path, full_page=True)
                       logger.info("ページ全体のスクリーンショットを保存しました。")
                  action_result_details["filename"] = screenshot_path # 結果にファイルパスを含める
                  results.append({"step": step_num, "status": "success", "action": action, **action_result_details})

            else:
                 # ... (変更なし) ...
                  known_actions = ["click", "input", "hover", "get_inner_text", "get_text_content", "get_inner_html", "get_attribute", "get_all_attributes", "get_all_text_contents", "wait_visible", "select_option", "screenshot", "scroll_page_to_bottom", "scroll_to_element", "wait_page_load", "sleep", "switch_to_iframe", "switch_to_parent_frame"]
                  if action not in known_actions:
                     logger.warning(f"未定義または不明なアクション '{action}' です。このステップはスキップされます。")
                     results.append({"step": step_num, "status": "skipped", "action": action, "message": f"Undefined action: {action}"})

        # --- エラーハンドリング (変更なし) ---
        except (PlaywrightTimeoutError, PlaywrightError, ValueError, Exception) as e:
            error_message = f"ステップ {step_num} ({action}) の実行中にエラーが発生しました: {type(e).__name__} - {e}"
            logger.error(error_message, exc_info=True) # スタックトレース付きでログ出力
            error_screenshot_path = None
            # エラー発生時のスクリーンショットを試みる
            if root_page and not root_page.is_closed():
                 timestamp = time.strftime("%Y%m%d_%H%M%S")
                 error_ss_filename = f"error_step{step_num}_{timestamp}.png"
                 error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, error_ss_filename)
                 try:
                     os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                     await root_page.screenshot(path=error_ss_path, full_page=True)
                     logger.info(f"エラー発生時のスクリーンショットを保存しました: {error_ss_path}")
                     error_screenshot_path = error_ss_path
                 except Exception as ss_e:
                     logger.error(f"エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
            elif root_page and root_page.is_closed():
                 # ページが閉じられている場合、エラーメッセージに追記
                 error_message += " (Root page was closed during execution)"
                 logger.warning("根本原因: ルートページが閉じられた可能性があります。")

            # エラー情報を結果リストに追加
            error_details = {
                "step": step_num,
                "status": "error",
                "action": action,
                "selector": selector,
                "message": str(e), # エラーメッセージ本文
                "full_error": error_message # より詳細なエラー情報
            }
            if error_screenshot_path:
                error_details["error_screenshot"] = error_screenshot_path
            results.append(error_details)
            return False, results # Falseを返して処理中断

    # 全てのステップが正常に完了した場合
    return True, results


# --- Playwright 実行メイン関数 (修正: クリーンアップ処理) ---
async def run_playwright_automation_async(
        target_url: str,
        actions: List[dict],
        headless_mode: bool = False,
        slow_motion: int = 100,
        default_timeout: int = config.DEFAULT_ACTION_TIMEOUT
    ) -> Tuple[bool, List[dict]]:
    """Playwright を非同期で初期化、アクション実行、終了処理を行う。"""
    logger.info("--- Playwright 自動化開始 (非同期) ---")
    all_success = False
    final_results: List[dict] = []
    playwright = None; browser = None; context = None; page = None
    try:
        playwright = await async_playwright().start()
        logger.info(f"ブラウザ起動 (Chromium, Headless: {headless_mode}, SlowMo: {slow_motion}ms)...")
        browser = await playwright.chromium.launch(headless=headless_mode, slow_mo=slow_motion)
        logger.info("新しいブラウザコンテキストを作成します...")
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36', # 一般的なUA
            viewport={'width': 1920, 'height': 1080}, # 一般的な解像度
            locale='ja-JP', # 日本語ロケール
            timezone_id='Asia/Tokyo', # 日本時間
            # accept_downloads=True, # PDFダウンロード等に必要なら有効化
            extra_http_headers={'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'} # Accept-Languageヘッダ
        )
        # デフォルトタイムアウト設定
        effective_default_timeout = default_timeout if default_timeout else config.DEFAULT_ACTION_TIMEOUT
        context.set_default_timeout(effective_default_timeout)
        logger.info(f"コンテキストのデフォルトタイムアウトを {effective_default_timeout}ms に設定しました。")
        # APIリクエスト用のコンテキスト (PDFダウンロード等で使用)
        api_request_context = context.request

        ## --- Stealth モード (必要であればコメント解除) ---
        logger.info("Applying stealth mode to the context...")
        try:
            await stealth_async(context)
            logger.info("Stealth mode applied successfully.")
        except Exception as stealth_err:
             logger.warning(f"Failed to apply stealth mode: {stealth_err}")

        logger.info("新しいページを作成します...")
        page = await context.new_page()

        # 最初のページへのナビゲーション (タイムアウトを長めに設定)
        initial_nav_timeout = max(effective_default_timeout * 3, 30000) # デフォルトの3倍か30秒の長い方
        logger.info(f"最初のナビゲーション: {target_url} (タイムアウト: {initial_nav_timeout}ms)...")
        await page.goto(target_url, wait_until="load", timeout=initial_nav_timeout)
        logger.info("最初のナビゲーション成功。アクションの実行を開始します...")

        # アクション実行
        all_success, final_results = await execute_actions_async(page, actions, api_request_context, effective_default_timeout)

        if all_success:
            logger.info("すべてのステップが正常に完了しました。")
        else:
            logger.error("自動化タスクの途中でエラーが発生しました。")

    # --- 全体的なエラーハンドリング ---
    except (PlaywrightTimeoutError, PlaywrightError, Exception) as e:
         error_msg_overall = f"Playwright 処理全体で予期せぬエラーが発生しました: {type(e).__name__} - {e}"
         logger.error(error_msg_overall, exc_info=True) # スタックトレース付きログ
         overall_error_screenshot_path = None
         # エラー発生時のスクリーンショット (ページが存在すれば)
         if page and not page.is_closed():
              timestamp = time.strftime("%Y%m%d_%H%M%S")
              overall_error_ss_filename = f"error_overall_{timestamp}.png"
              overall_error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, overall_error_ss_filename)
              try:
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  await page.screenshot(path=overall_error_ss_path, full_page=True)
                  logger.info(f"全体エラー発生時のスクリーンショットを保存しました: {overall_error_ss_path}")
                  overall_error_screenshot_path = overall_error_ss_path
              except Exception as ss_e:
                  logger.error(f"全体エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
         # 最終結果リストに全体エラー情報を追加 (既に追加されていなければ)
         if not final_results or final_results[-1].get("status") != "error":
             error_details = {"step": "Overall", "status": "error", "message": str(e), "full_error": error_msg_overall}
             if overall_error_screenshot_path:
                 error_details["error_screenshot"] = overall_error_screenshot_path
             final_results.append(error_details)
         all_success = False # 全体エラーなので失敗扱い

    # --- クリーンアップ処理 ---
    finally:
        logger.info("クリーンアップ処理を開始します...")
        # --- ▼▼▼ 修正箇所 ▼▼▼ ---
        if context: # is_closed() チェックを削除
            try:
                await context.close()
                logger.info("ブラウザコンテキストを閉じました。")
            except Exception as context_close_e:
                # 既に閉じられている場合などのエラーは警告レベルに留める
                logger.warning(f"ブラウザコンテキストのクローズ中にエラーが発生しました (無視): {context_close_e}")
        # --- ▲▲▲ 修正箇所 ▲▲▲ ---
        else:
             logger.debug("ブラウザコンテキストは存在しません (既に閉じられたか、作成されませんでした)。")

        if browser and browser.is_connected():
            try: await browser.close(); logger.info("ブラウザを閉じました。")
            except Exception as browser_close_e: logger.error(f"ブラウザのクローズ中にエラーが発生しました: {browser_close_e}")
        else: logger.debug("ブラウザは接続されていないか、存在しません。")

        if playwright:
            try: await playwright.stop(); logger.info("Playwright を停止しました。")
            except Exception as playwright_stop_e: logger.error(f"Playwright の停止中にエラーが発生しました: {playwright_stop_e}")

        # イベントループのクリーンアップを促すための短い待機
        try: await asyncio.sleep(0.1)
        except Exception as sleep_e: logger.warning(f"クリーンアップ後の待機中にエラーが発生しました: {sleep_e}")

    logger.info("--- Playwright 自動化終了 (非同期) ---")
    return all_success, final_results


---


- フォルダ名: .
- ファイル名: playwright_helper_funcs.py
- 内容:
# --- ファイル: playwright_helper_funcs.py ---
"""
Playwrightに関連するヘルパー関数 (要素探索以外) を提供します。
例: ページテキスト取得、iframeセレクター生成など。
"""
import asyncio
import logging
import time
from playwright.async_api import (
    Page,
    Frame,
    Locator,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError
)
from typing import Tuple, Optional, Union
from urllib.parse import urljoin

import config
import utils # PDF関連の関数を使用するため

logger = logging.getLogger(__name__)


async def get_page_inner_text(context: BrowserContext, url: str, timeout: int) -> Tuple[bool, Optional[str]]:
    """
    指定されたURLに新しいページでアクセスし、ページのinnerTextを取得する。
    成功したかどうかとテキスト内容（またはエラーメッセージ）のタプルを返す。
    """
    page = None
    start_time = time.monotonic()
    # ページ遷移自体のタイムアウトも考慮
    page_access_timeout = max(int(timeout * 0.8), 15000) # アクションタイムアウトの80%か15秒の大きい方
    logger.info(f"URLからテキスト取得開始: {url} (タイムアウト: {page_access_timeout}ms)")
    try:
        page = await context.new_page()
        # ナビゲーションタイムアウトを設定 (ページアクセスタイムアウトの90%か10秒の大きい方)
        nav_timeout = max(int(page_access_timeout * 0.9), 10000)
        logger.debug(f"  Navigating to {url} with timeout {nav_timeout}ms")
        await page.goto(url, wait_until="load", timeout=nav_timeout)
        logger.debug(f"  Navigation to {url} successful.")

        # <body>要素が表示されるまで待機 (残り時間の50%か2秒の大きい方)
        remaining_time_for_body = page_access_timeout - (time.monotonic() - start_time) * 1000
        if remaining_time_for_body <= 0:
            raise PlaywrightTimeoutError(f"No time left to wait for body after navigation to {url}")
        body_wait_timeout = max(int(remaining_time_for_body * 0.5), 2000)
        logger.debug(f"  Waiting for body element with timeout {body_wait_timeout}ms")
        body_locator = page.locator('body')
        await body_locator.wait_for(state='visible', timeout=body_wait_timeout)
        logger.debug("  Body element is visible.")

        # innerText取得タイムアウト (残り時間の80%か1秒の大きい方)
        remaining_time_for_text = page_access_timeout - (time.monotonic() - start_time) * 1000
        if remaining_time_for_text <= 0:
            raise PlaywrightTimeoutError(f"No time left to get innerText from {url}")
        text_timeout = max(int(remaining_time_for_text * 0.8), 1000)

        logger.debug(f"  Getting innerText with timeout {text_timeout}ms")
        text = await body_locator.inner_text(timeout=text_timeout)
        elapsed = (time.monotonic() - start_time) * 1000
        logger.info(f"テキスト取得成功 ({url})。文字数: {len(text)} ({elapsed:.0f}ms)")
        # 取得したテキストを返す (stripして空白を除去)
        return True, text.strip() if text else ""
    except PlaywrightTimeoutError as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Timeout during processing {url} ({elapsed:.0f}ms). {e}"
        logger.warning(error_msg)
        # エラーメッセージを返す
        return False, error_msg
    except Exception as e:
        elapsed = (time.monotonic() - start_time) * 1000
        error_msg = f"Error: Failed to get text from {url} ({elapsed:.0f}ms) - {type(e).__name__}: {e}"
        logger.error(error_msg, exc_info=False)
        logger.debug(f"Detailed error getting text from {url}:", exc_info=True)
        # エラーメッセージを返す
        return False, error_msg
    finally:
        if page and not page.is_closed():
            try:
                await page.close()
                logger.debug(f"一時ページ ({url}) を閉じました。")
            except Exception as close_e:
                logger.warning(f"一時ページ ({url}) クローズ中にエラー (無視): {close_e}")


async def generate_iframe_selector_async(iframe_locator: Locator) -> Optional[str]:
    """
    iframe要素のLocatorから、特定しやすいセレクター文字列を生成する試み (id, name, src の順)。
    属性取得は短いタイムアウトで並行実行し、エラーは無視します。
    """
    try:
        # 属性取得を並行実行 (タイムアウト短め: 200ms)
        attrs = await asyncio.gather(
            iframe_locator.get_attribute('id', timeout=200),
            iframe_locator.get_attribute('name', timeout=200),
            iframe_locator.get_attribute('src', timeout=200),
            return_exceptions=True # エラーが発生しても処理を止めない
        )
        # 結果から例外を除外して値を取得
        iframe_id, iframe_name, iframe_src = [a if not isinstance(a, Exception) else None for a in attrs]

        # 優先度順にセレクターを生成
        if iframe_id:
            return f'iframe[id="{iframe_id}"]'
        if iframe_name:
            return f'iframe[name="{iframe_name}"]'
        if iframe_src:
            # srcは長すぎる場合があるので注意が必要だが、特定には役立つ場合がある
            return f'iframe[src="{iframe_src}"]'

    except Exception as e:
        # 属性取得中のエラーはデバッグレベルでログ記録し、無視
        logger.debug(f"iframe属性取得中にエラー（無視）: {e}")

    # 適切なセレクターが見つからなければNoneを返す
    return None


---


- フォルダ名: .
- ファイル名: playwright_launcher.py
- 内容:
# --- ファイル: playwright_launcher.py ---
"""
Playwrightの起動、初期設定、アクション実行の呼び出し、終了処理を行います。
"""
import asyncio
import logging
import os
import time
import traceback
import warnings
from playwright.async_api import (
    async_playwright,
    Page,
    BrowserContext,
    TimeoutError as PlaywrightTimeoutError,
    Error as PlaywrightError,
)
from playwright_stealth import stealth_async
from typing import List, Tuple, Dict, Any

import config
from playwright_actions import execute_actions_async # アクション実行関数をインポート

logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", category=ResourceWarning, message="unclosed transport") # Playwrightの既知の警告を抑制

async def run_playwright_automation_async(
        target_url: str,
        actions: List[Dict[str, Any]],
        headless_mode: bool = False,
        slow_motion: int = 100,
        default_timeout: int = config.DEFAULT_ACTION_TIMEOUT
    ) -> Tuple[bool, List[Dict[str, Any]]]:
    """
    Playwright を非同期で初期化し、指定されたURLにアクセス後、一連のアクションを実行します。
    ブラウザの起動、コンテキスト設定、ページ作成、アクション実行、クリーンアップを行います。
    実行全体の成否 (bool) と、各ステップの結果詳細のリスト (List[dict]) を返します。
    """
    logger.info("--- Playwright 自動化開始 (非同期) ---")
    all_success = False
    final_results: List[Dict[str, Any]] = []
    playwright = None
    browser = None
    context: Optional[BrowserContext] = None # Optional に変更
    page: Optional[Page] = None # Optional に変更

    try:
        playwright = await async_playwright().start()
        logger.info(f"ブラウザ起動 (Chromium, Headless: {headless_mode}, SlowMo: {slow_motion}ms)...")
        # 起動オプション (必要に応じて追加)
        launch_options = {
            "headless": headless_mode,
            "slow_mo": slow_motion,
            # "args": ["--disable-blink-features=AutomationControlled"] # Stealthで不要になる可能性
        }
        browser = await playwright.chromium.launch(**launch_options)
        logger.info("新しいブラウザコンテキストを作成します...")
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36', # 一般的なUA
            viewport={'width': 1920, 'height': 1080}, # 一般的な解像度
            locale='ja-JP', # 日本語ロケール
            timezone_id='Asia/Tokyo', # 日本時間
            # accept_downloads=True, # ファイルダウンロードを許可する場合
            java_script_enabled=True, # JavaScript有効
            # ページの読み込み戦略 (デフォルトは 'load')
            # navigation_timeout= ..., # ナビゲーション全体のタイムアウト (デフォルトは30秒)
            extra_http_headers={'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'} # Accept-Languageヘッダ
        )
        # デフォルトタイムアウト設定 (コンテキスト全体)
        effective_default_timeout = default_timeout if default_timeout else config.DEFAULT_ACTION_TIMEOUT
        context.set_default_timeout(effective_default_timeout)
        logger.info(f"コンテキストのデフォルトタイムアウトを {effective_default_timeout}ms に設定しました。")

        # --- Stealth モード適用 ---
        logger.info("Applying stealth mode to the context...")
        try:
            await stealth_async(context)
            logger.info("Stealth mode applied successfully.")
        except Exception as stealth_err:
             logger.warning(f"Failed to apply stealth mode: {stealth_err}")

        # APIリクエスト用のコンテキスト (PDFダウンロード等で使用)
        api_request_context = context.request

        logger.info("新しいページを作成します...")
        page = await context.new_page()

        # 最初のページへのナビゲーション (タイムアウトを長めに設定)
        initial_nav_timeout = max(effective_default_timeout * 3, 30000) # デフォルトの3倍か30秒の長い方
        logger.info(f"最初のナビゲーション: {target_url} (タイムアウト: {initial_nav_timeout}ms)...")
        # wait_until="load" は、load イベントが発火するまで待つ
        # 他に "domcontentloaded", "networkidle" などがある
        await page.goto(target_url, wait_until="load", timeout=initial_nav_timeout)
        logger.info("最初のナビゲーション成功。アクションの実行を開始します...")

        # --- アクション実行 (playwright_actions.pyの関数を呼び出し) ---
        all_success, final_results = await execute_actions_async(
            page, actions, api_request_context, effective_default_timeout
        )

        if all_success:
            logger.info("すべてのステップが正常に完了しました。")
        else:
            logger.error("自動化タスクの途中でエラーが発生しました。")

    # --- 全体的なエラーハンドリング ---
    except (PlaywrightTimeoutError, PlaywrightError, Exception) as e:
         error_msg_overall = f"Playwright 処理全体で予期せぬエラーが発生しました: {type(e).__name__} - {e}"
         logger.error(error_msg_overall, exc_info=True) # スタックトレース付きログ
         overall_error_screenshot_path = None
         # エラー発生時のスクリーンショット (ページが存在すれば)
         if page and not page.is_closed():
              timestamp = time.strftime("%Y%m%d_%H%M%S")
              overall_error_ss_filename = f"error_overall_{timestamp}.png"
              overall_error_ss_path = os.path.join(config.DEFAULT_SCREENSHOT_DIR, overall_error_ss_filename)
              try:
                  os.makedirs(config.DEFAULT_SCREENSHOT_DIR, exist_ok=True)
                  await page.screenshot(path=overall_error_ss_path, full_page=True, timeout=10000) # タイムアウト短め
                  logger.info(f"全体エラー発生時のスクリーンショットを保存しました: {overall_error_ss_path}")
                  overall_error_screenshot_path = overall_error_ss_path
              except Exception as ss_e:
                  logger.error(f"全体エラー発生時のスクリーンショット保存に失敗しました: {ss_e}")
         # 最終結果リストに全体エラー情報を追加 (既に追加されていなければ)
         if not final_results or (isinstance(final_results[-1].get("status"), str) and final_results[-1].get("status") != "error") :
             error_details = {
                 "step": "Overall Execution", # ステップ名を明確化
                 "status": "error",
                 "message": str(e),
                 "full_error": error_msg_overall,
                 "traceback": traceback.format_exc() # トレースバックも追加
             }
             if overall_error_screenshot_path:
                 error_details["error_screenshot"] = overall_error_screenshot_path
             final_results.append(error_details)
         all_success = False # 全体エラーなので失敗扱い

    # --- クリーンアップ処理 ---
    finally:
        logger.info("クリーンアップ処理を開始します...")
        # コンテキスト -> ブラウザ -> Playwright の順で閉じる
        if context: # コンテキストが存在する場合のみ閉じる
            try:
                await context.close()
                logger.info("ブラウザコンテキストを閉じました。")
            except Exception as context_close_e:
                # 既に閉じられている場合などのエラーは警告レベルに留める
                # PlaywrightError: Context closed << などは無視して良い
                if "closed" not in str(context_close_e).lower():
                    logger.warning(f"ブラウザコンテキストのクローズ中にエラーが発生しました (無視): {context_close_e}")
        else:
             logger.debug("ブラウザコンテキストは存在しません (既に閉じられたか、作成されませんでした)。")

        if browser and browser.is_connected():
            try:
                await browser.close()
                logger.info("ブラウザを閉じました。")
            except Exception as browser_close_e:
                logger.error(f"ブラウザのクローズ中にエラーが発生しました: {browser_close_e}")
        else:
             logger.debug("ブラウザは接続されていないか、存在しません。")

        if playwright:
            try:
                await playwright.stop()
                logger.info("Playwright を停止しました。")
            except Exception as playwright_stop_e:
                logger.error(f"Playwright の停止中にエラーが発生しました: {playwright_stop_e}")

        # イベントループのクリーンアップを促すための短い待機
        try:
            await asyncio.sleep(0.1)
        except Exception as sleep_e:
            logger.warning(f"クリーンアップ後の待機中にエラーが発生しました: {sleep_e}")

    logger.info("--- Playwright 自動化終了 (非同期) ---")
    return all_success, final_results


---


- フォルダ名: .
- ファイル名: README copy.md
- 内容:
# Web-Runner-mcp

![Web-Runner Logo](./Web-Runner.png)

* Effortless Web Automation with Playwright & JSON. *

## Overview

Streamline your web automation tasks! Web-Runner is a powerful yet user-friendly Python application built on Playwright that allows you to define and execute complex browser interactions using a simple JSON configuration. Forget writing boilerplate Playwright code – define your automation logic declaratively and let Web-Runner handle the rest.

It's perfect for web scraping (including PDF content!), automated testing, and automating repetitive online tasks without requiring extensive Playwright expertise.

## Why Web-Runner?

*   **Simplified Workflow:** Define your automation logic declaratively using our intuitive JSON format.
*   **Visual JSON Generator:** Use the included `json_generator.html` tool to visually build your automation steps and generate the required JSON input, making setup quick and easy.
*   **Robust Action Support:** Handles a wide range of browser interactions: clicks, text input, hovering, dropdown selection, scrolling, waiting for elements/page loads, and taking screenshots.
*   **Advanced Data Extraction:** Go beyond basic scraping. Extract `innerText`, `textContent`, `innerHTML`, specific element attributes (single or multiple), and automatically resolve relative URLs to absolute ones when getting `href` attributes.
*   **Intelligent iframe Handling:** Features smart, automatic iframe scope detection, attempting to find elements even within nested frames without requiring explicit `switch_to_iframe` commands in many common scenarios. (Manual switching is also supported).
*   **Unique PDF Text Extraction:** Automatically detects `.pdf` links (when extracting `href`), downloads the file, and extracts its text content, seamlessly integrating it into your results.
*   **Asynchronous Power:** Built with `asyncio` for efficient handling of network operations and parallel processing.
*   **Debugging Made Easy:** Provides detailed logging (`playwright_runner_async.log`) and automatically saves screenshots upon errors (`screenshots/` directory).

## Ideal For

*   Developers needing to quickly automate web interactions.
*   QA Engineers setting up browser tests.
*   Data Analysts and Researchers scraping web data, including from PDFs.
*   Anyone looking to automate repetitive online tasks.

## Getting Started

### Prerequisites

*   Python 3.8+
*   Playwright browsers installed (Run `playwright install` after installing the library)

### Installation

1.  Clone this repository:
    ```bash
    git clone https://github.com/your-username/web-runner.git # Replace with your repo URL
    cd web-runner
    ```
2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
    *(If you don't have a requirements.txt yet, list the command: `pip install playwright PyMuPDF`)*
3.  Install Playwright browsers:
    ```bash
    playwright install
    ```

### Usage

1.  **Create your actions JSON file:**
    *   Use the `json_generator.html` file in your browser to visually build the steps.
    *   Alternatively, manually create a JSON file (e.g., `my_task.json`) following this structure:
        ```json
        {
          "target_url": "https://example.com",
          "actions": [
            {
              "action": "input",
              "selector": "#search",
              "value": "Playwright"
            },
            {
              "action": "click",
              "selector": "button[type='submit']"
            },
            {
              "action": "get_text_content",
              "selector": "h1"
            }
            // Add more actions...
          ]
        }
        ```
2.  **Run the application:**
    ```bash
    python main.py --input my_task.json
    ```
    *   Use `--headless` to run without opening a browser window.
    *   Use `--slowmo <milliseconds>` (e.g., `--slowmo 500`) to slow down execution for observation.
3.  **Check the results:**
    *   The execution log will be printed to the console and saved to `playwright_runner_async.log`.
    *   The final extracted data and step results will be printed at the end.
    *   Any error screenshots will be saved in the `screenshots/` directory.

## Dependencies

*   [Playwright](https://playwright.dev/python/)
*   [PyMuPDF (fitz)](https://pymupdf.readthedocs.io/en/latest/)

*(You can list specific versions if needed, especially if you provide a `requirements.txt`)*

## Contributing

*(Optional: Add guidelines here if you welcome contributions)*
Contributions are welcome! Please feel free to submit a pull request or open an issue.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. 


---


- フォルダ名: .
- ファイル名: README.md
- 内容:
# Web-Runner-mcp: Advanced Web Browser Operation Protocol for AI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.12%2B-blue.svg)](https://www.python.org/)
<!-- Add/modify badges as needed -->

**Web-Runner-mcp** is a Python project designed to make Playwright's powerful browser automation capabilities easily accessible to AI agents and other applications through the standardized **Model Context Protocol (MCP)**.

![Web-Runner Logo](./Web-Runner.png)


## Table of Contents

*   [Overview](#overview)
*   [Why Web-Runner-mcp?](#why-web-runner-mcp)
*   [Key Features](#key-features)
    *   [Supported Actions](#supported-actions)
    *   [PDF Text Extraction](#pdf-text-extraction)
    *   [Error Handling](#error-handling)
*   [Usage](#usage)
    *   [1. Setup](#1-setup)
    *   [2. Starting the Server (SSE Mode Example)](#2-starting-the-server-sse-mode-example)
    *   [3. Creating JSON Data for Web-Runner](#3-creating-json-data-for-web-runner)
        *   [Step 1: Prepare the JSON Generator](#step-1-prepare-the-json-generator)
        *   [Step 2: Get CSS Selectors for Target Elements](#step-2-get-css-selectors-for-target-elements)
        *   [Step 3: Create Operation Steps in json_generator.html](#step-3-create-operation-steps-in-json_generatorhtml)
        *   [Step 4: Place the JSON File](#step-4-place-the-json-file)
    *   [4. Command-Line Execution (for Testing)](#4-command-line-execution-for-testing)
    *   [5. Running from the GUI Client](#5-running-from-the-gui-client)
    *   [6. Usage from AI Applications](#6-usage-from-ai-applications)
*   [JSON Format (Reference)](#json-format-reference)
*   [Comparison with Other Tools](#comparison-with-other-tools)
*   [Future Plans](#future-plans)
*   [Contributing](#contributing)
*   [License](#license)

---

## Overview

Information gathering and interaction with the web are essential for today's AI agents, but existing tools have limitations. While simple content retrieval or fetching search result lists is possible, tasks like interacting with login-required sites, handling pages rendered with complex JavaScript, navigating iframe structures, and processing PDF content remain challenging. Furthermore, reliably controlling low-level APIs like Playwright directly from Large Language Models (LLMs) presents a significant hurdle.

Web-Runner-mcp proposes a new approach to tackle these challenges.

Instead of instructing the LLM to perform individual browser operations, Web-Runner-mcp allows you to define a sequence of desired operations in a JSON format and pass it to an MCP server for execution. The current version executes these operations reliably based on the JSON file instructions, without direct LLM involvement in the browser control loop itself.

This might be a **"small revolution"** in how AI interacts with the web, opening doors to the deeper, more complex parts of the web that were previously inaccessible to AI.

## Why Web-Runner-mcp?

*   **Advanced Web Operations:**
    *   **Login:** Access and interact with websites requiring authentication.
    *   **PDF:** Download linked PDFs and extract their text content.
    *   **Iframe:** Explore and interact with elements within nested iframes (dynamic discovery).
    *   **Multiple Tabs/Pages:** Follow new pages opened by clicks.
    *   **Dynamic Content:** Wait for and interact with elements generated by JavaScript.
*   **Versatile Data Extraction:**
    *   Flexible text/HTML retrieval using `innerText`, `textContent`, `innerHTML`.
    *   Get specific attribute values using `getAttribute`.
    *   Efficient data collection from multiple elements using `getAllAttributes`, `getAllTextContents` (with dynamic iframe discovery).
*   **Declarative Operation Definition:**
    *   Describe the desired steps in JSON.
    *   Ensures reproducibility and simplifies debugging.
*   **MCP Compliance:**
    *   Standardized protocol enables integration with various MCP clients (Dify custom tools, Python AI agent frameworks, custom clients, etc.).
    *   Separates client and server concerns.
*   **Reliable Execution:**
    *   Stable browser operations powered by Playwright.
    *   Appropriate waiting mechanisms and error handling.

## Key Features

*   **MCP Server (`web_runner_mcp_server.py`):** Implemented in Python (based on `FastMCP`), exposes Web-Runner functionality as the `execute_web_runner` tool.
*   **Web-Runner Core (`playwright_handler.py`, `utils.py`, `config.py`):** Uses Playwright (async) to execute browser operations based on input JSON. Handles core logic, settings, utility functions, dynamic iframe discovery, and PDF processing.
*   **Web-Runner Standalone Execution (`main.py`):** An entry point for running Web-Runner directly from the command line without the MCP server (for debugging and unit testing).
*   **MCP Client Core (`web_runner_mcp_client_core.py`):** Provides the core function (`execute_web_runner_via_mcp`) for invoking the MCP server programmatically (e.g., from AI agents).
*   **GUI Client (`web_runner_mcp_client_GUI.py`):** A convenient graphical interface for selecting JSON files, running tasks manually, and launching the JSON generator.

### Supported Actions

*   `click`: Clicks an element.
*   `input`: Enters text into an element.
*   `hover`: Hovers over an element.
*   `get_inner_text`, `get_text_content`, `get_inner_html`: Gets text/HTML (single element).
*   `get_attribute`: Gets an attribute value (single element).
*   `get_all_attributes`, `get_all_text_contents`: Gets attribute values/text content as a list (multiple elements, searches within iframes).
*   `wait_visible`: Waits for an element to become visible.
*   `select_option`: Selects an option from a dropdown list.
*   `screenshot`: Saves a screenshot of the page or an element (server-side).
*   `scroll_page_to_bottom`, `scroll_to_element`: Performs scroll operations.
*   `wait_page_load`: Waits for the page to finish loading.
*   `sleep`: Pauses execution for a specified duration.
*   `switch_to_iframe`, `switch_to_parent_frame`: Moves focus between iframes (explicitly specified).

### PDF Text Extraction

Automatically downloads PDFs linked via `get_attribute(href=...)` or `get_all_attributes(href=...)` and includes the extracted text in the results.

### Error Handling

Records error information for each step, including the screenshot path (on the server's filesystem) if an error occurs.

## Usage

### 1. Setup

**(1) Clone the repository:**

```bash
git clone https://github.com/sinzy0925/web-runner-mcp.git
cd web-runner-mcp
```

**(2) Prepare Python environment (Python 3.12+ recommended):**
```bash
# Create a virtual environment (e.g., venv312)
python -m venv venv312
# Activate the virtual environment
# Windows PowerShell
.\venv312\Scripts\Activate
# Linux/macOS
source venv312/bin/activate
```

**(3) Install dependencies:**
Install using the requirements.txt file.
```bash
pip install -r requirements.txt
```

**(4) Install Playwright browsers:**
```bash
playwright install
```

### 2. Starting the Server (SSE Mode Example)
**Note: This mode has not been fully verified and might require adjustments.**
To allow access over the network (e.g., for Dify integration), start the server in SSE mode.

```bash
# Run web_runner_mcp_server.py directly
python web_runner_mcp_server.py --transport sse --host 0.0.0.0 --port 8000
```
*   Use `--host 0.0.0.0` to allow access from other machines. Use `127.0.0.1` (default) for local access only.
*   `--port 8000` specifies the port the server listens on.
*   Server logs are output to `web_runner_mcp_server.log` (default setting).

### 3. Creating JSON Data for Web-Runner
You can use the included `json_generator.html` to interactively create the JSON file in your browser.

#### Step 1: Prepare the JSON Generator
1. Open the `json_generator.html` file located in the project folder with your web browser (double-click).

#### Step 2: Get CSS Selectors for Target Elements
1. Open the target website you want to automate in a separate browser tab or window.
2. Open the developer tools on that page (usually F12 key or right-click > "Inspect"/"Inspect Element").
3. Click the element selection icon (↖) in the developer tools.
4. Click the element you want to interact with (button, input field, etc.) on the webpage.
5. In the developer tools, right-click the highlighted HTML element and select [Copy] > [Copy selector].

#### Step 3: Create Operation Steps in json_generator.html
1. Go back to the `json_generator.html` tab.
2. Enter the website's URL in "1. Target URL:".
3. In "2. Operation Steps", fill in the following:
    *   Target Element CSS Selector: Paste the selector you copied.
    *   Operation: Choose the desired action.
    *   Additional Parameters: Enter values if needed (e.g., `value`, `attribute_name`).
4. Click "Add Step" and repeat step 3 for all required actions.
5. Click "Generate JSON Data" to see the generated JSON.
6. Click "Download input.json" to save the JSON file.

#### Step 4: Place the JSON File
1. Move the downloaded JSON file into the `json/` folder within the project directory. You can rename the file as needed (e.g., `my_task.json`).

### 4. Command-Line Execution (for Testing)
You can test the Web-Runner directly from the command line using the core client function (`web_runner_mcp_client_core.py`) without the GUI. This is useful for verifying programmatic calls, like those from an AI agent.
1. Ensure your desired JSON file is in the `json/` folder (e.g., `tdnet.json`).
2. Run the following command in your activated terminal:
```bash
python web_runner_mcp_client_core.py --jsonfile json/tdnet.json --no-headless --slowmo 500
```
*   `--jsonfile`: Specifies the path to the JSON file to execute (default: `json/tdnet.json`).
*   `--no-headless`: Use this flag to display the browser during execution (default is visible). Use `--headless` to run in the background.
*   `--slowmo`: (Optional) Adds a delay (in milliseconds) between operations (e.g., `--slowmo 500`).
*   `--output`: (Optional) Specifies the path for the output file (default: `output_web_runner.txt`).

The execution results (successful data retrieval or error information) will be printed to the console in JSON format and also written to the specified output file.

### 5. Running from the GUI Client
For manual testing and debugging, the GUI client (`web_runner_mcp_client_GUI.py`) is convenient.
1. Run the following command in your activated terminal:
```bash
python web_runner_mcp_client_GUI.py
```
2. In the application window, select the desired JSON file from the dropdown list.
3. Click the "実行 ▶" (Run) button.
4. The execution results will be displayed in the text area below.
5. You can also click the "JSONジェネレーター" (JSON Generator) button to open `json_generator.html`.

### 6. Usage from AI Applications
To use Web-Runner-mcp from other Python scripts or AI agent frameworks, import and use the `execute_web_runner_via_mcp` function from `web_runner_mcp_client_core.py`.

```python
import asyncio
import json
import sys # Add sys import
# Ensure web_runner_mcp_client_core.py is in the import path
try:
    from web_runner_mcp_client_core import execute_web_runner_via_mcp
except ImportError:
    print("Error: web_runner_mcp_client_core.py not found.")
    # Error handling or path configuration needed
    sys.exit(1) # Example

async def run_task():
    input_data = {
        "target_url": "https://example.com",
        "actions": [
            {"action": "get_text_content", "selector": "h1"},
            {"action": "get_attribute", "selector": "img", "attribute_name": "src"}
        ]
        # Optionally specify timeouts etc.
        # "default_timeout_ms": 15000
    }
    # Execute in headless mode with 50ms slow motion
    success, result_or_error = await execute_web_runner_via_mcp(
        input_data, headless=True, slow_mo=50 # Specify headless, slow_mo
    )

    if success and isinstance(result_or_error, str):
        print("Task successful! Result (JSON):")
        try:
            result_dict = json.loads(result_or_error)
            print(json.dumps(result_dict, indent=2, ensure_ascii=False))
            # --- Process the results, potentially pass to an LLM ---
            # llm_prompt = f"Analyze the following website operation results:\n```json\n{result_or_error}\n```"
            # llm_response = await call_llm(llm_prompt)
        except json.JSONDecodeError:
            print("Error: Response from server is not valid JSON:")
            print(result_or_error)
    else:
        print("Task failed:")
        print(result_or_error) # Display error information (dictionary)
        # --- Process the error information, potentially pass to an LLM ---
        # error_prompt = f"Website operation failed. Error details:\n{result_or_error}\nInfer the cause."
        # llm_response = await call_llm(error_prompt)

if __name__ == "__main__":
    asyncio.run(run_task())
```

## JSON Format (Reference)
Refer to the JSON files provided in the `json/` folder for examples.
Here is the basic structure of the input JSON:
```json
{
  "target_url": "Starting URL (e.g., https://www.example.com)",
  "actions": [
    {
      "action": "Action name (e.g., click)",
      "selector": "CSS selector (required for element actions)",
      "value": "Input value, wait time, etc. (depends on action)",
      "attribute_name": "Attribute to get (for get_attribute actions)",
      "option_type": "Dropdown selection type (for select_option)",
      "option_value": "Dropdown selection value (for select_option)",
      "wait_time_ms": "Action-specific timeout (optional)",
      "iframe_selector": "Iframe selector (for switch_to_iframe)"
    },
    // ... other action steps ...
  ]
  // Options (can be specified when calling the tool)
  // "headless": true, // Overrides client's headless setting if provided
  // "slow_mo": 100,   // Overrides client's slow_mo setting if provided
  // "default_timeout_ms": 15000 // Overrides the default action timeout
}
```

## Comparison with Other Tools
*   **General Web Scraping Libraries (BeautifulSoup, Scrapy):** Excellent for parsing static HTML, but struggle with or cannot handle JavaScript execution, logins, complex user interactions, iframes, and PDFs. Web-Runner-mcp, being Playwright-based, handles these advanced operations.
*   **Playwright-MCP:** Exposes Playwright's low-level API directly as MCP tools. Highly flexible, but requires complex prompt engineering and state management for reliable control from LLMs. Web-Runner-mcp offers a more declarative and reliable interface by defining operation sequences in JSON.
*   **Simple Web Fetching Tools (e.g., URL content fetchers):** Easy for getting content from a single URL, but incapable of multi-step operations or interactions. Web-Runner-mcp executes multi-step workflows.

## Future Plans
*   **LLM-Powered JSON Generation:** Integrate functionality to automatically generate Web-Runner JSON from natural language instructions.
*   **Expanded Action Support:** Add support for more Playwright features (e.g., file uploads, cookie manipulation).
*   **Official Dify Custom Tool Support:** Stabilize the HTTP/SSE interface aiming for potential registration in the Dify marketplace.
*   **Enhanced Error Handling and Recovery:** Implement more detailed error analysis and potentially automatic retry/recovery mechanisms.

## Contributing
Bug reports, feature suggestions, and pull requests are welcome! Please see CONTRIBUTING.md for details (to be created if not present).

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


---


- フォルダ名: .
- ファイル名: testapp.py
- 内容:
import time
import random
from playwright.sync_api import sync_playwright, Page, expect
from playwright_stealth import stealth_sync # playwright-stealthをインポート

def human_like_delay(min_seconds=0.5, max_seconds=1.5):
    """人間らしいランダムな遅延を生成"""
    time.sleep(random.uniform(min_seconds, max_seconds))

def run(page: Page):
    """指定されたページでGoogle検索とクリック操作を実行"""
    search_term = "あああ"
    search_box_selector = ".gLFyf"
    #first_result_selector = "#rso > div:nth-child(1) > div.A6K0A > div > div > div.kb0PBd.ieodic.jGGQ5e > div > div:nth-child(2) > div > div > span > a"
    first_result_selector = "#rso > div:nth-child(3) > div > div > div.kb0PBd.A9Y9g.jGGQ5e > div > div:nth-child(2) > div > div > span > a"

    print("1. Googleにアクセスします...")
    page.goto("https://www.google.co.jp/", wait_until="networkidle")
    human_like_delay(1, 2)

    print(f"2. 検索ボックス ({search_box_selector}) を探しています...")
    search_box = page.locator(search_box_selector)
    expect(search_box).to_be_visible(timeout=10000)

    print("3. 検索ボックスをクリック（より人間らしく）...")
    search_box.click()
    human_like_delay(0.3, 0.8)

    print(f"4. '{search_term}' を人間のように入力します...")
    search_box.type(search_term, delay=random.uniform(80, 250))
    human_like_delay(0.5, 1.0)

    print("5. Enterキーを押します...")
    search_box.press("Enter")

    print("6. 検索結果が表示されるのを待ちます...")
    page.wait_for_selector(first_result_selector, state="visible", timeout=15000)
    human_like_delay(1, 2.5)

    print(f"7. 最初の結果 ({first_result_selector}) を探しています...")
    first_result_link = page.locator(first_result_selector)
    expect(first_result_link).to_be_visible(timeout=10000)

    print("8. 結果リンクの上にマウスカーソルを移動（より人間らしく）...")
    try:
        first_result_link.hover()
        human_like_delay(0.4, 0.9)
    except Exception as e:
        print(f"  警告: ホバー中にエラーが発生しました: {e}。クリックは試行します。")

    print("9. 最初の結果をクリックします...")
    first_result_link.click()

    print("10. ページ遷移を待ちます...")
    page.wait_for_load_state("networkidle", timeout=20000)
    print("   新しいページがロードされました。")
    human_like_delay(1.5, 3)

    print("操作完了！")


# --- メイン処理 ---
with sync_playwright() as p:
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36" # 例

    browser = p.chromium.launch(headless=True,
                                 args=["--start-maximized"],
                                 slow_mo=random.uniform(50, 150)
                                )
    context = browser.new_context(
        user_agent=user_agent,
        viewport={'width': 1920, 'height': 1080},
        locale='ja-JP',
        timezone_id='Asia/Tokyo',
        no_viewport=True
    )

    page = context.new_page()

    # --- ここで stealth_sync を適用 ---
    print("Stealth機能を適用します...")
    stealth_sync(page)
    # ------------------------------------

    try:
        run(page)
    except Exception as e:
        print(f"エラーが発生しました: {e}")
        try:
            page.screenshot(path="error_screenshot.png")
            print("エラー発生時のスクリーンショットを 'error_screenshot.png' として保存しました。")
        except Exception as se:
            print(f"スクリーンショットの保存中にエラーが発生しました: {se}")
    finally:
        print("ブラウザを閉じます...")
        human_like_delay(2, 4)
        browser.close()


---


- フォルダ名: .
- ファイル名: utils.py
- 内容:
# --- ファイル: utils.py (修正版) ---
"""
JSON読み込み、PDF処理、ロギング設定などの汎用ヘルパー関数。
Playwrightに直接依存しない関数群。
"""
import json
import logging
import os
import sys
import asyncio
import time
import fitz  # PyMuPDF
from playwright.async_api import APIRequestContext, TimeoutError as PlaywrightTimeoutError # download_pdf_async のため必要
from typing import Optional, Dict, Any, List
from urllib.parse import urljoin

import config

logger = logging.getLogger(__name__)

def setup_logging_for_standalone(log_file_path: str = config.LOG_FILE):
    """Web-Runner単体実行用のロギング設定を行います。"""
    # 既存のハンドラをすべて削除 (他のライブラリが追加したハンドラも消す)
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)

    # 出力ディレクトリがなければ作成
    log_dir = os.path.dirname(log_file_path)
    if log_dir and not os.path.exists(log_dir):
        try:
            os.makedirs(log_dir, exist_ok=True)
        except Exception as e:
            print(f"警告: ログディレクトリの作成に失敗しました ({log_dir}): {e}", file=sys.stderr)

    # 新しいハンドラを設定 (ファイルとコンソール)
    handlers = [logging.StreamHandler()] # まずコンソールハンドラ
    try:
        # ファイルハンドラを追加（エラー発生時はコンソールのみ）
        file_handler = logging.FileHandler(log_file_path, encoding='utf-8', mode='a') # 追記モード
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
        handlers.append(file_handler)
    except Exception as e:
        print(f"警告: ログファイル '{log_file_path}' の設定に失敗しました: {e}", file=sys.stderr)

    logging.basicConfig(
        level=logging.INFO, # INFOレベル以上を記録
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', # ログフォーマット
        handlers=handlers
    )
    # Playwrightの冗長なログを抑制 (必要に応じて調整)
    logging.getLogger('playwright').setLevel(logging.WARNING)
    logger.info(f"Standalone ロガー設定完了。ログファイル: {log_file_path if len(handlers) > 1 else 'コンソールのみ'}")

def load_input_from_json(filepath: str) -> Dict[str, Any]:
    """指定されたJSONファイルから入力データを読み込む。"""
    logger.info(f"入力ファイル '{filepath}' の読み込みを開始します...")
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # 必須キーのチェック
        if "target_url" not in data or not data["target_url"]:
            raise ValueError("JSONファイルに必須キー 'target_url' が存在しないか、値が空です。")
        if "actions" not in data or not isinstance(data["actions"], list):
            raise ValueError("JSONファイルに必須キー 'actions' が存在しないか、リスト形式ではありません。")
        if not data["actions"]:
             logger.warning(f"入力ファイル '{filepath}' の 'actions' リストが空です。")

        logger.info(f"入力ファイル '{filepath}' を正常に読み込みました。")
        return data
    except FileNotFoundError:
        logger.error(f"入力ファイルが見つかりません: {filepath}")
        raise # エラーを再送出
    except json.JSONDecodeError as e:
        logger.error(f"JSON形式のエラーです ({filepath}): {e}")
        raise
    except ValueError as ve:
        logger.error(f"入力データの形式が不正です ({filepath}): {ve}")
        raise
    except Exception as e:
        logger.error(f"入力ファイルの読み込み中に予期せぬエラーが発生しました ({filepath}): {e}", exc_info=True)
        raise

def extract_text_from_pdf_sync(pdf_data: bytes) -> Optional[str]:
    """PDFのバイトデータからテキストを抽出する (同期的)。エラー時はエラーメッセージ文字列を返す。"""
    doc = None
    try:
        logger.info(f"PDFデータ (サイズ: {len(pdf_data)} bytes) からテキスト抽出を開始します...")
        doc = fitz.open(stream=pdf_data, filetype="pdf")
        text_parts = []
        logger.info(f"PDFページ数: {len(doc)}")
        for page_num in range(len(doc)):
            page_start_time = time.monotonic()
            try:
                page = doc.load_page(page_num)
                # テキスト抽出 (ソートして論理的な順序に)
                page_text = page.get_text("text", sort=True)
                if page_text:
                    text_parts.append(page_text.strip())
                # else:
                #     logger.debug(f"ページ {page_num + 1}/{len(doc)} からテキストは抽出されませんでした。")
                page_elapsed = (time.monotonic() - page_start_time) * 1000
                logger.debug(f"ページ {page_num + 1} 処理完了 ({page_elapsed:.0f}ms)。")
            except Exception as page_e:
                logger.warning(f"ページ {page_num + 1} の処理中にエラー: {page_e}")
                text_parts.append(f"--- Error processing page {page_num + 1}: {page_e} ---")

        full_text = "\n--- Page Separator ---\n".join(text_parts)
        # 空白行を除去して整形
        cleaned_text = '\n'.join([line.strip() for line in full_text.splitlines() if line.strip()])
        logger.info(f"PDFテキスト抽出完了。総文字数 (整形後): {len(cleaned_text)}")
        # テキストが全く抽出できなかった場合もNoneではなく空文字列を返すか、あるいはその旨を示すメッセージを返すのが良いかもしれない
        return cleaned_text if cleaned_text else "(No text extracted from PDF)"
    except fitz.fitz.TryingToReadFromEmptyFileError: # fitz.fitz... PyMuPDF 1.24+
         logger.error("PDF処理エラー: ファイルデータが空または破損しています。")
         return "Error: PDF data is empty or corrupted."
    except fitz.fitz.FileDataError as e: # fitz.fitz...
         logger.error(f"PDF処理エラー (PyMuPDF FileDataError): {e}", exc_info=False) # トレースバックは不要な場合も
         return f"Error: PDF file data error - {e}"
    except RuntimeError as e:
        # PyMuPDFの他のランタイムエラー（メモリ不足など）
        logger.error(f"PDF処理エラー (PyMuPDF RuntimeError): {e}", exc_info=True)
        return f"Error: PDF processing failed (PyMuPDF RuntimeError) - {e}"
    except Exception as e:
        logger.error(f"PDFテキスト抽出中に予期せぬエラーが発生しました: {e}", exc_info=True)
        return f"Error: Unexpected error during PDF text extraction - {e}"
    finally:
        if doc:
            try:
                doc.close()
                logger.debug("PDFドキュメントを閉じました。")
            except Exception as close_e:
                # クローズエラーは警告レベルに留める
                logger.warning(f"PDFドキュメントのクローズ中にエラーが発生しました (無視): {close_e}")

async def download_pdf_async(api_request_context: APIRequestContext, url: str) -> Optional[bytes]:
    """指定されたURLからPDFを非同期でダウンロードし、バイトデータを返す。失敗時はNoneを返す。"""
    logger.info(f"PDFを非同期でダウンロード中: {url} (Timeout: {config.PDF_DOWNLOAD_TIMEOUT}ms)")
    try:
        # 一般的なブラウザに近いヘッダーを設定
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            'Accept': 'application/pdf,text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd', # 圧縮を受け入れる
            'Accept-Language': 'ja-JP,ja;q=0.9,en-US;q=0.8,en;q=0.7'
        }
        # リクエスト実行 (fail_on_status_code=False で 4xx/5xx でもエラーにしない)
        response = await api_request_context.get(url, headers=headers, timeout=config.PDF_DOWNLOAD_TIMEOUT, fail_on_status_code=False)

        # ステータスコード確認
        if not response.ok:
            logger.error(f"PDFダウンロード失敗 ({url}) - Status: {response.status} {response.status_text}")
            try:
                # エラーレスポンスのボディをデバッグログに出力 (最初の500文字)
                error_body = await response.text(timeout=5000) # ボディ読み取りにもタイムアウト
                logger.debug(f"エラーレスポンスボディ (一部): {error_body[:500]}")
            except Exception as body_err:
                logger.warning(f"エラーレスポンスボディの読み取り中にエラーが発生しました: {body_err}")
            return None # 失敗時はNoneを返す

        # Content-Type確認 (小文字化して比較)
        content_type = response.headers.get('content-type', '').lower()
        if 'application/pdf' not in content_type:
            logger.warning(f"レスポンスのContent-TypeがPDFではありません ({url}): '{content_type}'。ダウンロードは続行しますが、後続処理で失敗する可能性があります。")
            # ここでNoneを返すか、続行するかは要件による
            # return None

        # レスポンスボディ取得
        body = await response.body()
        if not body:
             logger.warning(f"PDFダウンロード成功 ({url}) Status: {response.status} ですが、レスポンスボディが空です。")
             return None
        logger.info(f"PDFダウンロード成功 ({url})。サイズ: {len(body)} bytes")
        return body # 成功時はバイトデータを返す

    except PlaywrightTimeoutError:
        logger.error(f"PDFダウンロード中にタイムアウトが発生しました ({url})。設定タイムアウト: {config.PDF_DOWNLOAD_TIMEOUT}ms")
        return None
    except Exception as e:
        logger.error(f"PDF非同期ダウンロード中に予期せぬエラーが発生しました ({url}): {e}", exc_info=True)
        return None

def write_results_to_file(results: List[Dict[str, Any]], filepath: str):
    """実行結果を指定されたファイルに書き込む。"""
    logger.info(f"実行結果を '{filepath}' に書き込みます...")
    try:
        # 出力ディレクトリが存在しない場合は作成
        output_dir = os.path.dirname(filepath)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
            logger.info(f"出力ディレクトリ '{output_dir}' を作成しました。")

        with open(filepath, "w", encoding="utf-8") as file:
            file.write("--- Web Runner 実行結果 ---\n\n")
            for i, res in enumerate(results):
                step_num = res.get('step', i + 1)
                action_type = res.get('action', 'Unknown')
                status = res.get('status', 'Unknown')
                selector = res.get('selector') # セレクター情報取得

                file.write(f"--- Step {step_num}: {action_type} ({status}) ---\n")
                if selector: # セレクターがあれば表示
                    file.write(f"Selector: {selector}\n")
                if res.get('iframe_selector'): # iframeセレクターがあれば表示
                    file.write(f"IFrame Selector (for switch): {res.get('iframe_selector')}\n")
                if res.get('required_state'): # 要素探索時の状態指定があれば表示
                    file.write(f"Required Element State: {res.get('required_state')}\n")

                if status == "error":
                     # エラーメッセージと詳細情報を書き込む
                     file.write(f"Message: {res.get('message')}\n")
                     # full_error が message と異なる場合のみ詳細として出力
                     if res.get('full_error') and res.get('full_error') != res.get('message'):
                          file.write(f"Details: {res.get('full_error')}\n")
                     if res.get('error_screenshot'):
                          file.write(f"Screenshot: {res.get('error_screenshot')}\n")
                     # トレースバック情報があれば出力 (デバッグに有用)
                     if res.get('traceback'):
                         file.write(f"Traceback:\n{res.get('traceback')}\n")

                elif status == "success":
                    # 成功時の詳細情報を pop しながら書き込む (元の辞書を変更しないようにコピー)
                    details_to_write = res.copy()
                    # 共通情報を削除
                    for key in ['step', 'status', 'action', 'selector', 'iframe_selector', 'required_state']:
                        details_to_write.pop(key, None)

                    # --- アクションタイプに応じた整形出力 ---
                    if action_type == 'get_all_attributes':
                        attr_name = details_to_write.pop('attribute', 'N/A')
                        url_list = details_to_write.pop('url_list', None)
                        pdf_texts = details_to_write.pop('pdf_texts', None)
                        scraped_texts = details_to_write.pop('scraped_texts', None)
                        attr_list = details_to_write.pop('attribute_list', None)

                        file.write(f"Requested Attribute/Content: {attr_name}\n")

                        # 結果リストの最大長を取得
                        list_lengths = [len(lst) for lst in [url_list, pdf_texts, scraped_texts, attr_list] if lst is not None]
                        max_len = max(list_lengths) if list_lengths else 0

                        if max_len > 0:
                            file.write(f"Results ({max_len} items found):\n")
                            for idx in range(max_len):
                                file.write(f"  [{idx+1}]\n")
                                # 各リストから安全に値を取得
                                current_url = url_list[idx] if url_list and idx < len(url_list) else None
                                pdf_content = pdf_texts[idx] if pdf_texts and idx < len(pdf_texts) else None
                                scraped_content = scraped_texts[idx] if scraped_texts and idx < len(scraped_texts) else None
                                attr_content = attr_list[idx] if attr_list and idx < len(attr_list) else None

                                if current_url is not None:
                                     file.write(f"    URL: {current_url}\n")

                                # コンテンツや属性値を出力
                                content_written = False
                                if pdf_content is not None:
                                    prefix = "PDF Content"
                                    if isinstance(pdf_content, str) and pdf_content.startswith("Error:"):
                                        file.write(f"      -> {prefix} (Error): {pdf_content}\n")
                                    elif pdf_content == "(No text extracted from PDF)":
                                        file.write(f"      -> {prefix}: (No text extracted)\n")
                                    else:
                                        file.write(f"      -> {prefix} (Length: {len(pdf_content or '')}):\n")
                                        indented_content = "\n".join(["        " + line for line in str(pdf_content).splitlines()])
                                        file.write(indented_content + "\n")
                                    content_written = True
                                if scraped_content is not None: # pdf と scraped は通常排他だが両方出力
                                    prefix = "Page Content"
                                    if isinstance(scraped_content, str) and scraped_content.startswith("Error"):
                                        file.write(f"      -> {prefix} (Error): {scraped_content}\n")
                                    else:
                                        file.write(f"      -> {prefix} (Length: {len(scraped_content or '')}):\n")
                                        indented_content = "\n".join(["        " + line for line in str(scraped_content).splitlines()])
                                        file.write(indented_content + "\n")
                                    content_written = True
                                if attr_content is not None:
                                     # href, pdf, content 以外の汎用属性の場合
                                     file.write(f"      -> Attribute '{attr_name}' Value: {attr_content}\n")
                                     content_written = True

                                # if not content_written and current_url is not None:
                                #     file.write("      -> (No specific content/attribute requested or found for this item)\n")

                        else: # max_len == 0
                             file.write("Results: (No items found matching the selector)\n")

                    elif action_type == 'get_all_text_contents':
                        text_list_result = details_to_write.pop('text_list', [])
                        if isinstance(text_list_result, list):
                            valid_texts = [str(text) for text in text_list_result if text is not None]
                            file.write(f"Result Text List ({len(valid_texts)} items):\n")
                            if valid_texts:
                                file.write('\n'.join(f"- {text}" for text in valid_texts) + "\n")
                            else:
                                file.write("(No text content found)\n")
                        else:
                             file.write("Result Text List: (Invalid format received)\n")

                    elif action_type == 'get_text_content' or action_type == 'get_inner_text':
                        text = details_to_write.pop('text', None)
                        file.write(f"Result Text:\n{text}\n")
                    elif action_type == 'get_inner_html':
                        html = details_to_write.pop('html', None)
                        file.write(f"Result HTML:\n{html}\n") # HTMLはそのまま出力
                    elif action_type == 'get_attribute':
                        attr_name = details_to_write.pop('attribute', ''); attr_value = details_to_write.pop('value', None)
                        file.write(f"Result Attribute ('{attr_name}'): {attr_value}\n")
                        pdf_text = details_to_write.pop('pdf_text', None)
                        if pdf_text:
                             prefix = "Extracted PDF Text"
                             if isinstance(pdf_text, str) and pdf_text.startswith("Error:"):
                                 file.write(f"{prefix} (Error): {pdf_text}\n")
                             elif pdf_text == "(No text extracted from PDF)":
                                 file.write(f"{prefix}: (No text extracted)\n")
                             else:
                                 file.write(f"{prefix}:\n{pdf_text}\n")
                    elif action_type == 'screenshot':
                         filename = details_to_write.pop('filename', None)
                         if filename: file.write(f"Screenshot saved to: {filename}\n")
                    elif action_type == 'click':
                         if details_to_write.get('new_page_opened'):
                              file.write(f"New page opened: {details_to_write.get('new_page_url')}\n")
                         else:
                              file.write("New page did not open within timeout.\n")
                         # 不要なキーを削除
                         details_to_write.pop('new_page_opened', None)
                         details_to_write.pop('new_page_url', None)

                    # 残りの詳細情報（汎用）を書き込む
                    if details_to_write:
                        file.write("Other Details:\n")
                        for key, val in details_to_write.items():
                             file.write(f"  {key}: {val}\n")

                elif status == "skipped" or status == "warning":
                    file.write(f"Message: {res.get('message', 'No message provided.')}\n")
                else: # Unknown status or other cases
                     file.write(f"Raw Data: {res}\n") # 不明な場合は生データを書き出す

                file.write("\n") # ステップ間の空行

        logger.info(f"結果の書き込みが完了しました: '{filepath}'")
    except IOError as e:
        logger.error(f"結果ファイル '{filepath}' の書き込み中にIOエラーが発生しました: {e}")
    except Exception as e:
        logger.error(f"結果の処理またはファイル書き込み中に予期せぬエラーが発生しました: {e}", exc_info=True)


---


- フォルダ名: .
- ファイル名: web_runner_mcp_client_core.py
- 内容:
# --- ファイル: web_runner_mcp_client_core.py (ファイル出力修正版) ---

import asyncio
import sys
import json
from pathlib import Path
import anyio
import platform
import traceback
from typing import Optional, Dict, Any, Tuple, Union, List
import argparse

# MCP クライアントライブラリ
from mcp import ClientSession, StdioServerParameters, types as mcp_types
from mcp.client.stdio import stdio_client

# --- ▼▼▼ 追加 ▼▼▼ ---
# 設定ファイルとユーティリティ関数をインポート
try:
    import config
    import utils # ★★★ utils モジュールをインポート ★★★
    DEFAULT_OUTPUT_FILE = Path(config.MCP_CLIENT_OUTPUT_FILE)
except ImportError:
    print("Warning: config.py or utils.py not found. Using default output filename './output_web_runner.txt'")
    DEFAULT_OUTPUT_FILE = Path("./output_web_runner.txt")
    # utils がない場合は、ファイル書き込み部分でエラーになる可能性がある
    utils = None # プレースホルダ
# --- ▲▲▲ 追加 ▲▲▲ ---


# 定数
SERVER_SCRIPT = Path("./web_runner_mcp_server.py")
DEFAULT_SLOW_MO = 0

# --- コア関数: Web-RunnerをMCP経由で実行 ---
async def execute_web_runner_via_mcp(
    input_json_data: Dict[str, Any],
    headless: bool = False, # デフォルトをFalse (表示) に変更
    slow_mo: int = DEFAULT_SLOW_MO
) -> Tuple[bool, Union[str, Dict[str, Any]]]:
    """
    指定されたJSONデータをWeb-Runner MCPサーバーに送信し、実行結果を取得する。
    """
    print("--- Executing Web Runner via MCP ---")
    print(f"Input data (type: {type(input_json_data)}): {str(input_json_data)[:200]}...")
    print(f"Headless: {headless}, SlowMo: {slow_mo}")

    if not SERVER_SCRIPT.exists():
        error_msg = f"Error: Server script not found at {SERVER_SCRIPT}"
        print(error_msg)
        return False, {"error": error_msg}

    # --- サーバーに渡す引数を構築 ---
    tool_arguments = {
        "input_args": {
            "target_url": input_json_data.get("target_url"),
            "actions": input_json_data.get("actions", []),
            "headless": headless,
            "slow_mo": slow_mo,
            "default_timeout_ms": input_json_data.get("default_timeout_ms")
        }
    }
    if not tool_arguments["input_args"]["target_url"] or not tool_arguments["input_args"]["actions"]:
         error_msg = "Error: 'target_url' or 'actions' missing in input_json_data."
         print(error_msg)
         return False, {"error": error_msg}

    print("Preparing server parameters...")
    server_params = StdioServerParameters(
        command=sys.executable,
        args=[str(SERVER_SCRIPT), "--transport", "stdio", "--log-level", "INFO"],
    )
    print(f"Server command: {sys.executable} {SERVER_SCRIPT} --transport stdio --log-level INFO")

    session: Optional[ClientSession] = None
    try:
        print("Connecting to server via stdio_client...")
        async with stdio_client(server_params) as streams:
            print("DEBUG: stdio_client context entered.")
            read_stream, write_stream = streams
            print("DEBUG: Got streams from stdio_client.")
            print("Creating ClientSession...")
            async with ClientSession(read_stream, write_stream) as session:
                print("DEBUG: ClientSession context entered.")
                print("Initializing session...")
                await session.initialize()
                print("DEBUG: Initialization complete.")

                print("Calling 'execute_web_runner' tool...")
                print(f"DEBUG: Calling tool with arguments: {str(tool_arguments)[:500]}...")

                tool_result: mcp_types.CallToolResult = await session.call_tool(
                    name="execute_web_runner",
                    arguments=tool_arguments
                )
                print("DEBUG: Tool call finished.")

                if tool_result.isError:
                    print("--- Tool Execution Error ---")
                    error_content = "Unknown error format received from server."
                    if tool_result.content and isinstance(tool_result.content[0], mcp_types.TextContent):
                        error_content = tool_result.content[0].text
                        print(f"Received error details:\n{error_content}")
                        try:
                           error_data = json.loads(error_content)
                           if "JSON: " in error_content:
                               json_part = error_content.split("JSON: ", 1)[1]
                               try: error_data = json.loads(json_part)
                               except json.JSONDecodeError: pass
                           return False, {"error": "MCP tool execution failed", "details": error_data}
                        except json.JSONDecodeError:
                           return False, {"error": "MCP tool execution failed", "raw_details": error_content}
                    else:
                        print(error_content)
                        return False, {"error": error_content}
                else:
                    print("--- Tool Execution Success ---")
                    if tool_result.content and isinstance(tool_result.content[0], mcp_types.TextContent):
                        result_json_string = tool_result.content[0].text
                        return True, result_json_string
                    else:
                        print("No content received from server.")
                        return False, {"error": "No content received from server"}

    except Exception as e:
        print(f"--- An Exception Occurred During MCP Communication ---")
        error_msg = f"{type(e).__name__}: {e}"
        print(error_msg)
        print("--- Traceback ---")
        traceback.print_exc()
        return False, {"error": f"MCP communication error: {error_msg}"}
    finally:
        print("--- Web Runner via MCP Finished ---")


# --- このファイル単体でテストするための実行部分 ---
async def main():
    """テスト用のJSONファイルを読み込んでコア関数を呼び出し、結果をファイルに出力"""
    parser = argparse.ArgumentParser(description="Test Web-Runner MCP Client Core")
    parser.add_argument(
        "--jsonfile",
        type=Path,
        default=Path("./json/tdnet.json"), # デフォルトをtdnet.jsonにしてみる
        help="Path to the input JSON file for testing."
    )
    parser.add_argument(
        '--headless',
        action=argparse.BooleanOptionalAction,
        default=False, # デフォルトはブラウザ表示
        help="Run browser in headless mode."
    )
    parser.add_argument(
        "--slowmo",
        type=int,
        default=DEFAULT_SLOW_MO,
        help=f"Slow motion delay in milliseconds (default: {DEFAULT_SLOW_MO})."
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT_FILE,
        help=f"Path to the output file (default: {DEFAULT_OUTPUT_FILE})."
    )
    args = parser.parse_args()
    test_json_file_path: Path = args.jsonfile
    output_file_path: Path = args.output
    slow_mo_value: int = args.slowmo

    print(f"Loading input JSON from: {test_json_file_path}")
    if not test_json_file_path.exists():
        print(f"Error: Test JSON file not found at {test_json_file_path}")
        return

    try:
        with open(test_json_file_path, 'r', encoding='utf-8') as f:
            test_input = json.load(f)
        print("Input JSON loaded successfully.")
    except Exception as e:
        print(f"Error loading JSON file: {e}")
        return

    success, result_or_error = await execute_web_runner_via_mcp(
        test_input,
        headless=args.headless,
        slow_mo=slow_mo_value
    )

    # ファイル書き込み処理
    print(f"\nWriting result to: {output_file_path}")
    if success and isinstance(result_or_error, str):
        try:
            result_data_list = json.loads(result_or_error)
            if isinstance(result_data_list, list) and utils: # ★★★ utils がインポートできているか確認 ★★★
                 utils.write_results_to_file(result_data_list, str(output_file_path))
            elif not utils:
                 print("Error: Cannot write results because 'utils' module failed to import.")
                 with open(output_file_path, 'w', encoding='utf-8') as f:
                     f.write("--- Execution Succeeded but Result Writing Failed (utils missing) ---\n")
                     f.write(result_or_error)
            else:
                 print("Error: Result JSON from server is not a list.")
                 with open(output_file_path, 'w', encoding='utf-8') as f:
                      f.write("--- Execution Failed ---\nReceived invalid result format (not a list):\n")
                      f.write(result_or_error)
        except json.JSONDecodeError:
            error_msg = f"Error: Received non-JSON success result:\n{result_or_error}"
            print(error_msg)
            with open(output_file_path, 'w', encoding='utf-8') as f:
                 f.write(error_msg)
        except Exception as write_e:
             print(f"Error writing result to file {output_file_path}: {write_e}")
             traceback.print_exc()
    else: # success is False
        print("\n--- Final Result (Error) ---")
        formatted_error = json.dumps(result_or_error, indent=2, ensure_ascii=False)
        print(formatted_error)
        with open(output_file_path, 'w', encoding='utf-8') as f:
            f.write(f"--- Execution Failed ---\n{formatted_error}")


if __name__ == "__main__":
    if platform.system() == "Windows":
        pass

    try:
        anyio.run(main)
    except Exception as e:
        print(f"Error running anyio task: {e}")
        traceback.print_exc()


---


- フォルダ名: .
- ファイル名: web_runner_mcp_client_GUI.py
- 内容:
# --- ファイル: web_runner_mcp_client_GUI.py (コピーボタン追加版) ---

import sys
import os
import json
import asyncio
import platform
import traceback
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Any, Union

# --- GUIライブラリ ---
from PySide6.QtWidgets import (
    QApplication, QMainWindow, QVBoxLayout, QHBoxLayout, QWidget,
    QComboBox, QPushButton, QPlainTextEdit, QLabel, QDialog, QMessageBox,
    QCheckBox, QSpinBox
)
from PySide6.QtCore import (
    Qt, QThread, Signal, Slot, QUrl, QObject
)
# --- ▼▼▼ QClipboard をインポート ▼▼▼ ---
from PySide6.QtGui import QClipboard
# --- ▲▲▲ QClipboard をインポート ▲▲▲ ---
from PySide6.QtWebEngineWidgets import QWebEngineView
from PySide6.QtWebChannel import QWebChannel

# --- 実績のあるコア関数をインポート ---
try:
    from web_runner_mcp_client_core import execute_web_runner_via_mcp
except ImportError:
    print("Error: web_runner_mcp_client_core.py not found or cannot be imported.")
    print("Please ensure web_runner_mcp_client_core.py is in the same directory.")
    sys.exit(1)

# --- utils, config のインポート ---
try:
    import config
    import utils
    # --- ▼▼▼ configからファイルパスを取得 ▼▼▼ ---
    DEFAULT_OUTPUT_FILE = Path(config.MCP_CLIENT_OUTPUT_FILE)
    # --- ▲▲▲ configからファイルパスを取得 ▲▲▲ ---
except ImportError:
    print("Warning: config.py or utils.py not found. Using default output filename './output/web_runner_mcp.txt'")
    DEFAULT_OUTPUT_FILE = Path("./output/web_runner_mcp.txt")
    utils = None

# --- 定数 ---
JSON_FOLDER = Path("./json")
GENERATOR_HTML = Path("./json_generator.html")

# --- MCP通信を行うワーカースレッド (変更なし) ---
class McpWorker(QThread):
    result_ready = Signal(str)
    error_occurred = Signal(object)
    status_update = Signal(str)

    def __init__(self, json_input: Dict[str, Any], headless: bool, slow_mo: int):
        super().__init__()
        self.json_input = json_input
        self.headless = headless
        self.slow_mo = slow_mo
        self._is_running = True

    def run(self):
        print("DEBUG: McpWorker.run started")
        self.status_update.emit("MCPタスク実行中...")
        success = False
        result_or_error: Union[str, Dict[str, Any]] = {"error": "Worker execution failed unexpectedly."}
        try:
            import anyio
            success, result_or_error = anyio.run(
                execute_web_runner_via_mcp,
                self.json_input,
                self.headless,
                self.slow_mo
            )
            print(f"DEBUG: execute_web_runner_via_mcp finished. Success: {success}")

            if success and isinstance(result_or_error, str):
                self.result_ready.emit(result_or_error)
            elif not success and isinstance(result_or_error, dict):
                self.error_occurred.emit(result_or_error)
            elif not success and isinstance(result_or_error, str):
                 self.error_occurred.emit({"error": "Received string error", "raw_details": result_or_error})
            else:
                 self.error_occurred.emit({"error": "Unexpected result format from core function", "result": str(result_or_error)})
        except Exception as e:
            err_msg = f"MCPワーカー実行エラー: {type(e).__name__}: {e}\n{traceback.format_exc()}"
            print(f"ERROR in McpWorker.run: {err_msg}")
            self.error_occurred.emit({"error": "Exception in McpWorker", "details": err_msg})
        finally:
            self._is_running = False
            print("DEBUG: McpWorker.run finished")

    def stop_worker(self):
        print("DEBUG: Requesting McpWorker to stop (flag set).")
        self._is_running = False


# --- GeneratorDialog クラス (変更なし) ---
class GeneratorDialog(QDialog):
    json_generated = Signal(str)
    class Bridge(QObject):
        receiveJsonSignal = Signal(str)
        @Slot(str)
        def receiveJsonFromHtml(self, jsonString):
            self.receiveJsonSignal.emit(jsonString)
    def __init__(self, html_path: Path, parent=None):
        super().__init__(parent)
        self.setWindowTitle("JSON Generator")
        self.setGeometry(200, 200, 900, 700)
        layout = QVBoxLayout(self)
        self.webview = QWebEngineView()
        layout.addWidget(self.webview)
        self.bridge = self.Bridge(self)
        self.channel = QWebChannel(self.webview.page())
        self.webview.page().setWebChannel(self.channel)
        self.channel.registerObject("pyBridge", self.bridge)
        if html_path.exists():
            file_url = QUrl.fromLocalFile(str(html_path.resolve()))
            script = """
                 <script src="qrc:///qtwebchannel/qwebchannel.js"></script>
                 <script>
                     document.addEventListener('DOMContentLoaded', function() {
                         if (typeof QWebChannel === 'undefined') { console.error('qwebchannel.js did not load'); return; }
                         new QWebChannel(qt.webChannelTransport, function(channel) {
                             window.pyBridge = channel.objects.pyBridge;
                             console.log('Python Bridge (pyBridge) initialized.');
                             const originalGenerateJsonData = window.generateJsonData;
                             window.generateJsonData = function() {
                                 originalGenerateJsonData();
                                 setTimeout(() => {
                                     const jsonElement = document.getElementById('generated-json');
                                     const jsonString = jsonElement ? jsonElement.textContent : null;
                                     if (jsonString && !jsonString.startsWith('JSON') && !jsonString.startsWith('入力エラー')) {
                                         if (window.pyBridge && window.pyBridge.receiveJsonFromHtml) {
                                             window.pyBridge.receiveJsonFromHtml(jsonString);
                                         } else { console.error('Python bridge not available.'); }
                                     } else { console.log('No valid JSON to send.'); }
                                 }, 100);
                             };
                         });
                     });
                 </script>
             """
            self.webview.page().loadFinished.connect(lambda ok: self.webview.page().runJavaScript(script) if ok else None)
            self.webview.setUrl(file_url)
        else:
            error_label = QLabel(f"Error: HTML file not found at\n{html_path}")
            layout.addWidget(error_label)
        self.bridge.receiveJsonSignal.connect(self.on_json_received_from_html)

    @Slot(str)
    def on_json_received_from_html(self, json_string):
        self.json_generated.emit(json_string)
        self.accept()

    def closeEvent(self, event):
        page = self.webview.page()
        if page:
            if hasattr(self, 'channel') and self.channel:
                 self.channel.deregisterObject("pyBridge")
            self.webview.setPage(None)
        super().closeEvent(event)


# --- メインウィンドウ ---
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Web-Runner MCP Client (Core Utilized)")
        # ウィンドウサイズを少し広げる場合
        self.setGeometry(100, 100, 850, 650)

        self.mcp_worker: Optional[McpWorker] = None
        self.generator_dialog: Optional[GeneratorDialog] = None

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # --- 上部のファイル選択・実行ボタンなど ---
        top_layout = QHBoxLayout()
        self.json_selector = QComboBox()
        self.refresh_button = QPushButton("🔄 更新")
        self.generator_button = QPushButton("JSONジェネレーター")
        self.run_button = QPushButton("実行 ▶")
        top_layout.addWidget(QLabel("実行するJSON:"))
        top_layout.addWidget(self.json_selector, 1)
        top_layout.addWidget(self.refresh_button)
        top_layout.addWidget(self.generator_button)
        top_layout.addWidget(self.run_button)
        main_layout.addLayout(top_layout)

        # --- オプション設定のレイアウト ---
        options_layout = QHBoxLayout()
        self.headless_checkbox = QCheckBox("ヘッドレスモードで実行")
        self.headless_checkbox.setChecked(False)
        self.headless_checkbox.setToolTip("チェックするとブラウザ画面を表示せずにバックグラウンドで実行します。")
        options_layout.addWidget(self.headless_checkbox)

        options_layout.addWidget(QLabel("SlowMo (ms):"))
        self.slowmo_spinbox = QSpinBox()
        self.slowmo_spinbox.setRange(0, 30000)
        self.slowmo_spinbox.setValue(0)
        self.slowmo_spinbox.setSingleStep(100)
        self.slowmo_spinbox.setToolTip("各Playwright操作間の遅延時間(ミリ秒)。デバッグ時に便利です。")
        options_layout.addWidget(self.slowmo_spinbox)

        # --- ▼▼▼ コピーボタン追加 ▼▼▼ ---
        # ファイル名をボタンテキストに表示 (パスが長い場合は調整が必要かも)
        copy_button_text = f"コピー ({os.path.join('output', DEFAULT_OUTPUT_FILE.name)})" # 例: output/ファイル名
        self.copy_button = QPushButton(copy_button_text)
        self.copy_button.setToolTip(f"結果ファイル ({DEFAULT_OUTPUT_FILE}) の内容をクリップボードにコピーします。")
        options_layout.addWidget(self.copy_button)
        # --- ▲▲▲ コピーボタン追加 ▲▲▲ ---

        options_layout.addStretch() # ボタンの後にスペーサーを追加
        main_layout.addLayout(options_layout)

        # --- 結果表示エリア ---
        self.result_display = QPlainTextEdit()
        self.result_display.setReadOnly(True)
        self.result_display.setPlaceholderText("ここに実行結果が表示されます...")
        main_layout.addWidget(self.result_display, 1) # 縦方向に伸縮

        # --- ステータスラベル ---
        self.status_label = QLabel("アイドル")
        main_layout.addWidget(self.status_label)

        # --- シグナルとスロットの接続 ---
        self.refresh_button.clicked.connect(self.populate_json_files)
        self.generator_button.clicked.connect(self.open_generator)
        self.run_button.clicked.connect(self.run_mcp)
        # --- ▼▼▼ コピーボタンのシグナル接続 ▼▼▼ ---
        self.copy_button.clicked.connect(self.copy_output_to_clipboard)
        # --- ▲▲▲ コピーボタンのシグナル接続 ▲▲▲ ---

        # --- 初期設定 ---
        JSON_FOLDER.mkdir(exist_ok=True)
        # output ディレクトリもなければ作成
        DEFAULT_OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
        self.populate_json_files()
        self.run_button.setStyleSheet("background-color: #28a745; color: white;")

    def populate_json_files(self):
        # ... (変更なし) ...
        self.json_selector.clear()
        try:
            json_files = sorted([f.name for f in JSON_FOLDER.glob("*.json") if f.is_file()])
            if json_files:
                self.json_selector.addItems(json_files)
                self.status_label.setText(f"{len(json_files)}個のJSONファイルを検出")
                self.run_button.setEnabled(True)
            else:
                self.json_selector.addItem("JSONファイルが見つかりません")
                self.status_label.setText(f"'{JSON_FOLDER}'フォルダにJSONファイルがありません")
                self.run_button.setEnabled(False)
        except Exception as e:
            self.show_error_message(f"JSONファイルの読み込みエラー: {e}")
            self.run_button.setEnabled(False)

    def open_generator(self):
        # ... (変更なし) ...
         if not GENERATOR_HTML.exists():
              self.show_error_message(f"エラー: {GENERATOR_HTML} が見つかりません。")
              return
         if self.generator_dialog is None or not self.generator_dialog.isVisible():
             self.generator_dialog = GeneratorDialog(GENERATOR_HTML, self)
             self.generator_dialog.json_generated.connect(self.paste_generated_json)
             self.generator_dialog.show()
         else:
             self.generator_dialog.raise_()
             self.generator_dialog.activateWindow()

    @Slot(str)
    def paste_generated_json(self, json_string):
        # ... (変更なし) ...
        self.result_display.setPlaceholderText("JSONジェネレーターからJSONが入力されました。\n内容を確認し、必要であればファイルに保存して選択、または直接実行してください。")
        try:
             parsed_json = json.loads(json_string)
             formatted_json = json.dumps(parsed_json, indent=2, ensure_ascii=False)
             self.result_display.setPlainText(formatted_json)
             self.status_label.setText("JSONジェネレーターからJSONを取得しました")
        except json.JSONDecodeError:
              self.show_error_message("ジェネレーターから無効なJSONを受け取りました。")
              self.result_display.setPlainText(json_string)

    def run_mcp(self, json_data: Optional[Dict[str, Any]] = None):
        # ... (変更なし) ...
        if self.mcp_worker and self.mcp_worker.isRunning():
            self.show_error_message("現在、別のタスクを実行中です。")
            return

        input_source = ""
        selected_json_input = None
        if json_data:
            selected_json_input = json_data
            input_source = "ジェネレーターからのJSON"
            self.result_display.clear()
            self.result_display.setPlaceholderText("ジェネレーターからのJSONで実行中...")
        else:
            selected_file = self.json_selector.currentText()
            if not selected_file or selected_file == "JSONファイルが見つかりません":
                self.show_error_message("実行するJSONファイルを選択してください。")
                return
            json_path = JSON_FOLDER / selected_file
            if not json_path.exists():
                 self.show_error_message(f"エラー: 選択されたファイル '{selected_file}' が見つかりません。")
                 self.populate_json_files()
                 return
            input_source = f"ファイル '{selected_file}'"
            self.result_display.clear()
            self.result_display.setPlaceholderText(f"'{selected_file}' を実行中...")
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    selected_json_input = json.load(f)
            except Exception as e:
                self.show_error_message(f"JSONファイルの読み込み/パースエラー ({selected_file}): {e}")
                self.status_label.setText("エラー")
                return

        self.status_label.setText(f"{input_source} で実行開始...")
        self.run_button.setEnabled(False)
        self.refresh_button.setEnabled(False)
        self.generator_button.setEnabled(False)
        self.headless_checkbox.setEnabled(False)
        self.slowmo_spinbox.setEnabled(False)
        self.copy_button.setEnabled(False) # コピーボタンも実行中は無効化

        headless_mode = self.headless_checkbox.isChecked()
        slow_mo_value = self.slowmo_spinbox.value()

        self.mcp_worker = McpWorker(selected_json_input, headless_mode, slow_mo_value)
        self.mcp_worker.result_ready.connect(self.display_result)
        self.mcp_worker.error_occurred.connect(self.display_error)
        self.mcp_worker.status_update.connect(self.update_status)
        self.mcp_worker.finished.connect(self.task_finished)
        self.mcp_worker.start()

    # --- ▼▼▼ コピー処理用スロット関数 ▼▼▼ ---
    @Slot()
    def copy_output_to_clipboard(self):
        """結果ファイルの内容をクリップボードにコピーする。"""
        output_filepath = DEFAULT_OUTPUT_FILE
        # output ディレクトリが存在しない場合は作成を試みる
        try:
            output_filepath.parent.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            print(f"Warning: Could not create output directory {output_filepath.parent}: {e}")

        if not output_filepath.exists():
            self.show_error_message(f"エラー: 結果ファイルが見つかりません。\nパス: {output_filepath}")
            self.status_label.setText("コピー失敗: ファイルなし")
            return

        try:
            with open(output_filepath, 'r', encoding='utf-8') as f:
                file_content = f.read()

            clipboard = QApplication.instance().clipboard()
            if clipboard is None:
                self.show_error_message("エラー: クリップボードにアクセスできません。")
                self.status_label.setText("コピー失敗: クリップボードエラー")
                return

            clipboard.setText(file_content)
            self.status_label.setText(f"'{output_filepath.name}' の内容をクリップボードにコピーしました。")
            # 必要であれば情報メッセージを表示
            # QMessageBox.information(self, "コピー完了", f"'{output_filepath.name}' の内容をクリップボードにコピーしました。")

        except IOError as e:
            self.show_error_message(f"エラー: 結果ファイルの読み込みに失敗しました。\nエラー: {e}")
            self.status_label.setText("コピー失敗: 読み込みエラー")
        except Exception as e:
            self.show_error_message(f"予期せぬエラーが発生しました。\nエラー: {e}")
            self.status_label.setText("コピー失敗: 不明なエラー")
            traceback.print_exc() # デバッグ用にトレースバックを出力
    # --- ▲▲▲ コピー処理用スロット関数 ▲▲▲ ---


    @Slot(str)
    def display_result(self, result_json_string: str):
        # ... (変更なし) ...
        display_text = ""
        result_data_list_for_file = None
        try:
             result_data_list = json.loads(result_json_string)
             if not isinstance(result_data_list, list):
                 raise TypeError("Result data is not a list.")
             result_data_list_for_file = result_data_list

             display_text += "--- Web Runner Execution Result ---\n\n"
             display_text += f"Overall Status: Success\n\n"

             for i, step_result in enumerate(result_data_list):
                step_num = step_result.get('step', i + 1)
                action_type = step_result.get('action', 'Unknown')
                status = step_result.get('status', 'Unknown')

                display_text += f"--- Step {step_num}: {action_type} ({status}) ---\n"

                if status == "success":
                    details_to_write = {k: v for k, v in step_result.items() if k not in ['step', 'status', 'action']}
                    if 'selector' in details_to_write:
                        display_text += f"Selector: {details_to_write.pop('selector')}\n"
                    if action_type == 'get_all_attributes':
                        attr_name = details_to_write.pop('attribute', 'N/A')
                        if 'url_list' in details_to_write: # 'url_list' キーをチェック
                            url_list = details_to_write.pop('url_list', []) # 'url_list' を取得
                            if url_list:
                                display_text += "Result (URL List):\n" + '\n'.join(f"- {str(item)}" for item in url_list if item is not None) + "\n"
                        elif 'attribute_list' in details_to_write:
                             attr_list = details_to_write.pop('attribute_list', [])
                             if attr_list:
                                 display_text += f"Result (Attribute List for '{attr_name}'):\n" + '\n'.join(f"- {str(item)}" for item in attr_list if item is not None) + "\n"
                        if 'pdf_texts' in details_to_write:
                             pdf_texts = details_to_write.pop('pdf_texts', [])
                             valid_pdf_texts = [t for t in pdf_texts if t and isinstance(t, str)]
                             if valid_pdf_texts:
                                 display_text += "Extracted PDF Texts:\n" + '\n\n--- Next PDF Text ---\n\n'.join(valid_pdf_texts) + '\n'
                        if 'scraped_texts' in details_to_write:
                             scraped_texts = details_to_write.pop('scraped_texts', [])
                             if scraped_texts:
                                 display_text += "Scraped Page Texts:\n"
                                 display_text += '\n\n--- Next Page Text ---\n\n'.join(str(t) if t is not None else '(No text or Error)' for t in scraped_texts) + '\n'
                    elif action_type == 'get_all_text_contents':
                        text_list_result = details_to_write.pop('text_list', [])
                        if isinstance(text_list_result, list):
                            valid_texts = [str(text).strip() for text in text_list_result if text is not None and str(text).strip()]
                            if valid_texts:
                                display_text += "Result Text List:\n" + '\n'.join(f"- {text}" for text in valid_texts) + "\n"
                    elif action_type in ['get_text_content', 'get_inner_text'] and 'text' in details_to_write:
                        display_text += f"Result Text:\n{details_to_write.pop('text', '')}\n"
                    elif action_type == 'get_inner_html' and 'html' in details_to_write:
                        display_text += f"Result HTML:\n{details_to_write.pop('html', '')}\n"
                    elif action_type == 'get_attribute':
                        attr_name = details_to_write.pop('attribute', ''); attr_value = details_to_write.pop('value', None)
                        display_text += f"Result Attribute ('{attr_name}'): {attr_value}\n"
                        if 'pdf_text' in details_to_write:
                            display_text += f"Extracted PDF Text:\n{details_to_write.pop('pdf_text', '')}\n"
                    if details_to_write:
                        display_text += "Other Details:\n"
                        for key, val in details_to_write.items():
                            display_text += f"  {key}: {val}\n"
                elif status == "error":
                    if step_result.get('selector'): display_text += f"Selector: {step_result.get('selector')}\n"
                    display_text += f"Message: {step_result.get('message')}\n"
                    if step_result.get('full_error'): display_text += f"Details: {step_result.get('full_error')}\n"
                    if step_result.get('error_screenshot'): display_text += f"Screenshot: {step_result.get('error_screenshot')}\n"
                else:
                    display_text += f"Message: {step_result.get('message', 'No details')}\n"
                display_text += "\n"

             self.result_display.setPlainText(display_text)
             self.status_label.setText("実行成功")

             if utils and result_data_list_for_file:
                 try:
                     utils.write_results_to_file(result_data_list_for_file, str(DEFAULT_OUTPUT_FILE))
                     print(f"Result also written to {DEFAULT_OUTPUT_FILE}")
                 except Exception as write_e:
                      print(f"Error writing results to file: {write_e}")

        except (json.JSONDecodeError, TypeError) as e:
             error_msg = f"サーバーからの応答の処理中にエラー ({type(e).__name__}):\n{result_json_string}"
             self.result_display.setPlainText(error_msg)
             self.status_label.setText("警告: 不正な応答")
             print(error_msg)

    @Slot(object)
    def display_error(self, error_info: Union[str, Dict[str, Any]]):
        # ... (変更なし) ...
        error_message = "不明なエラー"
        if isinstance(error_info, dict):
            try: error_message = json.dumps(error_info, indent=2, ensure_ascii=False)
            except Exception: error_message = str(error_info)
        elif isinstance(error_info, str):
            error_message = error_info
        self.result_display.setPlainText(f"エラーが発生しました:\n\n{error_message}")
        self.status_label.setText("エラー発生")
        # エラー時にもファイルに書き込み試行
        try:
            with open(DEFAULT_OUTPUT_FILE, 'w', encoding='utf-8') as f:
                 f.write(f"--- Execution Failed ---\n{error_message}")
            print(f"Error details written to {DEFAULT_OUTPUT_FILE}")
        except Exception as write_e:
            print(f"Error writing error details to file: {write_e}")
        # エラーメッセージボックス表示は削除（冗長なため）
        # self.show_error_message(error_message)


    @Slot(str)
    def update_status(self, status: str):
        # ... (変更なし) ...
        self.status_label.setText(status)

    @Slot()
    def task_finished(self):
        # ... (変更なし) ...
        print("DEBUG: task_finished slot called.")
        self.run_button.setEnabled(True)
        self.refresh_button.setEnabled(True)
        self.generator_button.setEnabled(True)
        self.headless_checkbox.setEnabled(True)
        self.slowmo_spinbox.setEnabled(True)
        self.copy_button.setEnabled(True) # コピーボタンも再度有効化
        if not self.status_label.text().startswith("エラー"):
            self.status_label.setText("アイドル")
        self.mcp_worker = None

    def show_error_message(self, message: str):
        # ... (変更なし) ...
        QMessageBox.critical(self, "エラー", message)

    def closeEvent(self, event):
        # ... (変更なし) ...
        print("Close event triggered.")
        if self.mcp_worker and self.mcp_worker.isRunning():
            print("Stopping MCP worker thread...")
            self.mcp_worker.stop_worker()
            if not self.mcp_worker.wait(3000):
                 print("Warning: Worker thread did not stop gracefully.")
        if self.generator_dialog and self.generator_dialog.isVisible():
            self.generator_dialog.close()
        print("Exiting client application.")
        event.accept()

# --- アプリケーション実行 ---
if __name__ == "__main__":
    # WindowsでのAnyIOポリシー設定 (必要に応じて)
    # if platform.system() == "Windows":
    #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())


---


- フォルダ名: .
- ファイル名: web_runner_mcp_server.py
- 内容:
# --- ファイル: web_runner_mcp_server.py (修正版) ---

import json
import logging # logging をインポート
import traceback # 詳細なエラー出力用
from typing import Any, Dict, List, Literal, Union

# MCP SDK と Pydantic をインポート
from mcp.server.fastmcp import Context, FastMCP
from mcp.server.fastmcp.exceptions import ToolError
from mcp.server.fastmcp.utilities.logging import configure_logging # MCPのログ設定関数
from pydantic import BaseModel, Field, HttpUrl

# --- ▼▼▼ 修正 ▼▼▼ ---
# 分割した Web-Runner のコア関数と設定をインポート
try:
    import config # 設定値を参照するため
    import utils  # ロギング設定などに使う可能性
    # playwright_handler -> playwright_launcher をインポート
    from playwright_launcher import run_playwright_automation_async # メインの実行関数
except ImportError as import_err:
    logging.critical(f"致命的エラー: Web-Runnerの必須モジュール (config, utils, playwright_launcher) のインポートに失敗しました: {import_err}")
    logging.critical("config.py, utils.py, playwright_launcher.py が同じディレクトリにあるか、PYTHONPATHに含まれているか確認してください。")
    import sys
    sys.exit(1)
# --- ▲▲▲ 修正 ▲▲▲ ---

# --- ロガー取得 ---
logger = logging.getLogger(__name__)

# --- 入力スキーマ定義 (変更なし) ---
class ActionStep(BaseModel):
    action: str = Field(..., description="実行するアクション名 (例: 'click', 'input', 'get_text_content')")
    selector: str | None = Field(None, description="アクション対象のCSSセレクター (要素操作アクションの場合)")
    iframe_selector: str | None = Field(None, description="iframeを対象とする場合のCSSセレクター (switch_to_iframeの場合)")
    value: str | float | int | bool | None = Field(None, description="入力する値 (input) や待機時間 (sleep)、スクリーンショットファイル名など")
    attribute_name: str | None = Field(None, description="取得する属性名 (get_attribute, get_all_attributesの場合)")
    option_type: Literal['value', 'index', 'label'] | None = Field(None, description="ドロップダウン選択方法 (select_optionの場合)")
    option_value: str | int | None = Field(None, description="選択する値/インデックス/ラベル (select_optionの場合)")
    wait_time_ms: int | None = Field(None, description="このアクション固有の最大待機時間 (ミリ秒)。省略時はdefault_timeout_msが使われる。")

class WebRunnerInput(BaseModel):
    target_url: Union[HttpUrl, str] = Field(..., description="自動化を開始するWebページのURL (文字列も許容)")
    actions: List[ActionStep] = Field(..., description="実行するアクションステップのリスト", min_length=1)
    headless: bool = Field(True, description="ヘッドレスモードで実行するかどうか (デフォルトはTrue)") # MCP経由ではTrueがデフォルトで良さそう
    slow_mo: int = Field(0, description="各操作間の待機時間 (ミリ秒)", ge=0)
    default_timeout_ms: int | None = Field(None, description=f"デフォルトのアクションタイムアウト(ミリ秒)。省略時はサーバー設定 ({config.DEFAULT_ACTION_TIMEOUT}ms) が使われる。")

# --- FastMCP サーバーインスタンス作成 (変更なし) ---
mcp = FastMCP(
    name="WebRunnerServer",
    instructions="Webサイトの自動操作とデータ抽出を実行するサーバーです。URLと一連のアクションを指定してください。",
    dependencies=["playwright", "PyMuPDF", "fitz", "playwright-stealth"] # 依存関係にstealth追加
)

# --- MCPツール定義 (修正: インポート元変更) ---
@mcp.tool()
async def execute_web_runner(
    input_args: WebRunnerInput,
    ctx: Context
) -> str:
    """
    指定されたURLとアクションリストに基づいてWebブラウザ自動化タスクを実行し、
    結果をJSON文字列として返します。
    """
    await ctx.info(f"Received task for URL: {input_args.target_url} with {len(input_args.actions)} actions.")
    await ctx.debug(f"Input arguments (raw): {input_args.model_dump()}") # Pydantic v2

    try:
        target_url_str = str(input_args.target_url) # URLを文字列に変換
        # アクションリストを辞書のリストに変換
        actions_list = [step.model_dump(exclude_none=True) for step in input_args.actions]
        # 有効なデフォルトタイムアウトを決定
        effective_default_timeout = input_args.default_timeout_ms if input_args.default_timeout_ms is not None else config.DEFAULT_ACTION_TIMEOUT
        await ctx.info(f"Using effective default timeout: {effective_default_timeout}ms")

        await ctx.debug(f"Calling playwright_launcher.run_playwright_automation_async with:")
        await ctx.debug(f"  target_url='{target_url_str}'")
        await ctx.debug(f"  actions_count={len(actions_list)}")
        await ctx.debug(f"  headless_mode={input_args.headless}")
        await ctx.debug(f"  slow_motion={input_args.slow_mo}")
        await ctx.debug(f"  default_timeout={effective_default_timeout}")

        # --- ▼▼▼ 修正 ▼▼▼ ---
        # playwright_handler -> playwright_launcher のコア関数を呼び出す
        success, results = await run_playwright_automation_async(
            target_url=target_url_str,
            actions=actions_list,
            headless_mode=input_args.headless,
            slow_motion=input_args.slow_mo,
            default_timeout=effective_default_timeout
        )
        # --- ▲▲▲ 修正 ▲▲▲ ---

        # 結果をJSON文字列に変換 (エラー時も含む)
        # ensure_ascii=False で日本語がエスケープされないようにする
        results_json = json.dumps(results, indent=2, ensure_ascii=False)
        await ctx.debug(f"Task finished. Success: {success}. Results JSON (first 500 chars): {results_json[:500]}...")

        if success:
            await ctx.info("Task completed successfully.")
            return results_json
        else:
            # 失敗した場合、ToolErrorを送出するが、そのメッセージに結果JSONを含める
            await ctx.error("Task failed. Returning error information via ToolError.")
            # ToolErrorのメッセージにJSONを含めることで、クライアント側で詳細を確認できるようにする
            raise ToolError(f"Web-Runner task failed. Details in JSON content: {results_json}")

    except ImportError as e:
         # サーバー起動時のインポートエラーは上で処理されるはずだが、念のため
         err_msg = f"Server configuration error: Failed to load core Web-Runner module ({e})"
         await ctx.error(err_msg)
         raise ToolError(err_msg)
    except Exception as e:
        # 予期せぬエラーが発生した場合
        error_traceback = traceback.format_exc()
        await ctx.error(f"Unhandled exception during Web-Runner execution: {type(e).__name__} - {e}")
        await ctx.error(f"Traceback:\n{error_traceback}")
        # クライアントにはエラーが発生したことと、サーバーログを確認するよう促すメッセージを含むエラー情報を返す
        error_result = [{
            "step": "MCP Tool Execution",
            "status": "error",
            "message": f"Unhandled server error occurred: {type(e).__name__}. Please check server logs for details.",
            "error_type": type(e).__name__,
            "raw_error": str(e)
        }]
        error_json = json.dumps(error_result, indent=2, ensure_ascii=False)
        raise ToolError(f"Unhandled server error during execution. Details: {error_json}")

# --- サーバー起動設定 (変更なし) ---
if __name__ == "__main__":
    import typer

    cli_app = typer.Typer()

    @cli_app.command()
    def main(
        transport: str = typer.Option(
            "stdio", "--transport", "-t",
            help="Transport protocol (stdio or sse)",
        ),
        host: str = typer.Option(
            "127.0.0.1", "--host", help="Host for SSE server"
        ),
        port: int = typer.Option(
            8000, "--port", "-p", help="Port for SSE server"
        ),
        log_level: str = typer.Option(
            "INFO", "--log-level", help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)"
        )
    ):
        """Web-Runner MCP Server"""
        transport_lower = transport.lower()
        if transport_lower not in ["stdio", "sse"]:
            print(f"エラー: 無効なトランスポートタイプ '{transport}'。'stdio' または 'sse' を指定してください。", file=sys.stderr)
            raise typer.Exit(code=1)

        log_level_upper = log_level.upper()
        valid_log_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if log_level_upper not in valid_log_levels:
            print(f"エラー: 無効なログレベル '{log_level}'。{valid_log_levels} のいずれかを指定してください。", file=sys.stderr)
            raise typer.Exit(code=1)

        # --- MCPログ設定 (ファイル出力有効化) ---
        mcp.settings.log_level = log_level_upper # type: ignore
        configure_logging(mcp.settings.log_level)

        # ファイルハンドラを追加
        try:
            # 出力ディレクトリがなければ作成
            log_dir = os.path.dirname(config.MCP_SERVER_LOG_FILE)
            if log_dir and not os.path.exists(log_dir):
                os.makedirs(log_dir, exist_ok=True)

            file_handler = logging.FileHandler(config.MCP_SERVER_LOG_FILE, encoding='utf-8', mode='a') # 追記モード
            # フォーマットを少し詳細に
            file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - [%(process)d:%(threadName)s] %(name)s - %(message)s')
            file_handler.setFormatter(file_formatter)
            # ルートロガーに追加することで、すべてのロガーの出力がファイルに行くようにする
            logging.getLogger().addHandler(file_handler)
            # ルートロガーのレベルも設定 (これが全体の閾値になる)
            logging.getLogger().setLevel(log_level_upper)
            logger.info(f"ファイルロギングを有効化しました: {config.MCP_SERVER_LOG_FILE}")
        except Exception as log_file_err:
             logger.error(f"ファイルロギングの設定に失敗しました ({config.MCP_SERVER_LOG_FILE}): {log_file_err}")

        logger.info(f"MCPロガーを設定しました。レベル: {log_level_upper}")
        # --- ▲▲▲ MCPログ設定 (ファイル出力有効化) ▲▲▲ ---

        logger.info(f"Web-Runner MCP サーバーを {transport_lower} トランスポートで起動します...")
        if transport_lower == "sse":
             mcp.settings.host = host
             mcp.settings.port = port
             logger.info(f"SSEサーバーが http://{host}:{port} で待機します")
        # MCPサーバーを実行
        mcp.run(transport=transport_lower) # type: ignore

    # Typerアプリケーションを実行
    cli_app()


---


- フォルダ名: .\json
- ファイル名: cw_text.json
- 内容:
{
  "target_url": "https://crowdworks.jp/public/jobs/search?category_id=228&order=new&page=1",
  "actions": [
    {
      "action": "wait_visible",
      "selector": "li[data-v-d4b91500]"
    },
    {
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "attribute_name": "href"
    },
    {
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "attribute_name": "content"
    },
    {
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "attribute_name": "pdf"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: cw_url.json
- 内容:
{
  "target_url": "https://crowdworks.jp/public/jobs/search?category_id=228&order=new&page=1",
  "actions": [
    {
      "action": "wait_visible",
      "selector": "li[data-v-d4b91500]",
      "wait_time_ms": 10000
    },
    {
      "action": "get_all_attributes",
      "selector": "li a.wB71r",
      "wait_time_ms": 5000,
      "attribute_name": "href"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_domein2company1.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "action": "input",
      "selector": "#APjFqb",
      "value": "meisenjp.com　会社概要"
    },
    {
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "content"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_domein2company2.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "action": "input",
      "selector": "#APjFqb",
      "value": "bil.jp　会社概要"
    },
    {
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "action": "get_all_attributes",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000,
      "attribute_name": "content"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_inner-text.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "action": "input",
      "selector": "#APjFqb",
      "value": "経済"
    },
    {
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "action": "click",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 5000
    },
    {
      "action": "get_inner_text",
      "selector": "body",
      "wait_time_ms": 5000
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_urls.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "action": "input",
      "memo": "入力",
      "selector": "#APjFqb",
      "wait_time_ms": 3000,
      "value": "bil.jp　会社概要"
    },
    {
      "action": "click",
      "memo": "Google検索ボタン　クリック",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 3000
    },
    {
      "action": "get_all_attributes",
      "memo": "全てのcontent取得",
      "selector": "#rso div.kb0PBd.A9Y9g.jGGQ5e span a",
      "wait_time_ms": 3000,
      "attribute_name": "href"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: google_yahooFinance.json
- 内容:
{
  "target_url": "https://www.google.com/",
  "actions": [
    {
      "memo": "入力",
      "action": "input",
      "selector": "#APjFqb",
      "value": "yahoo ファイナンス"
    },
    {
      "memo": "検索ボタン　クリック",
      "action": "click",
      "selector": "body > div.L3eUgb > div.o3j99.ikrT4e.om7nvf > form > div:nth-child(1) > div.A8SBwf > div.FPdoLc.lJ9FBc > center > input.gNO89b",
      "wait_time_ms": 5000
    },
    {
      "memo": "検索結果の１件目　クリック",
      "action": "click",
      "selector": "#rso > div.MjjYud > div > div > div > div > div > div > div > div:nth-child(1) > div:nth-child(2) > div > div > span > a",
      "wait_time_ms": 3000
    },
    {
      "memo": "yahoo ファイナンスの検索ボックスに9501と入力",
      "action": "input",
      "selector": "#search > form > input",
      "value": "9501"
    },
    {
      "memo": "検索をクリック",
      "action": "click",
      "selector": "#search > form > button"
    },
    {
      "memo": "時系列をクリック",
      "action": "click",
      "selector": "#stk_info > li:nth-child(7) > a"
    },
    {
      "action": "get_inner_text",
      "selector": "#root > main > div > div.Column__rMa8 > div.Column__main__XuqD > div:nth-child(3) > section.StocksEtfReitPriceHistory__26aY.StocksEtfReitPriceHistory--price__h40V.StocksContents__stockHistory__2P-X > div > table"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: pmda_inner-text.json
- 内容:
{
  "target_url": "https://www.pmda.go.jp/PmdaSearch/iyakuSearch/",
  "actions": [
    {
      "action": "input",
      "selector": "#txtName",
      "value": "パキシル"
    },
    {
      "action": "click",
      "selector": "#ContentMainArea > div > div > p:nth-child(2) > span:nth-child(2) > input[type=image]"
    },
    {
      "action": "click",
      "selector": "#ResultList > tbody > tr.TrColor01 > td:nth-child(4) > div > a:nth-child(2)"
    },
    {
      "action": "get_inner_text",
      "selector": "#ResultSet > div:nth-child(2)"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: qiita_text.json
- 内容:
{
  "target_url": "https://qiita.com/",
  "actions": [
    {
      "action": "get_all_text_contents",
      "selector": "article h2 a"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: sakai_inner-text.json
- 内容:
{
  "target_url": "https://duckduckgo.com/",
  "actions": [
    {
      "action": "input",
      "selector": "#searchbox_input",
      "value": "堺市　個人事業主"
    },
    {
      "action": "click",
      "selector": "#searchbox_homepage > div > div.searchbox_searchbox__bfbmv > div > button.iconButton_button__A_Uiu.searchbox_searchButton__LxebD > svg"
    },
    {
      "action": "click",
      "selector": "#r1-0 > div.ikg2IXiCD14iVX7AdZo1 > h2 > a"
    },
    {
      "action": "get_inner_text",
      "selector": "#basebgwrapall > div > div"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_pdf.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)"
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_attributes",
      "selector": "tr td.title a",
      "attribute_name": "pdf"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_text.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "wait_time_ms": 5000,
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_all_text_contents",
      "selector": "tr td.title a"
    }
  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_url.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)"
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_inner_text",
      "selector": "#maintable > tbody > tr:nth-child(1) > td.title > a"
    },
    {
      "action": "get_all_attributes",
      "selector": ".title a",
      "attribute_name": "href"
    }

  ]
}


---


- フォルダ名: .\json
- ファイル名: tdnet_url_pdf.json
- 内容:
{
  "target_url": "https://www.release.tdnet.info/index.html",
  "actions": [
    {
      "action": "click",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)"
    },
    {
      "action": "select_option",
      "selector": "#searchmenu > form > dl > dd:nth-child(2) > select:nth-child(1)",
      "option_type": "index",
      "option_value": 7
    },
    {
      "action": "input",
      "selector": "#freewordtxt",
      "value": "不動産"
    },
    {
      "action": "click",
      "selector": "#searchbtn > img"
    },
    {
      "action": "get_inner_text",
      "selector": "#maintable > tbody > tr:nth-child(1) > td.title > a"
    },
    {
      "action": "get_all_attributes",
      "selector": ".title a",
      "attribute_name": "href"
    },
    {
      "action": "get_all_attributes",
      "selector": "tr td.title a",
      "attribute_name": "pdf"
    }

  ]
}